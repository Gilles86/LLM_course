{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNiLQP5YC4n5R6EHtWUX1eC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 6:</h2>|<h1>Intervention (causal) mech interp<h1>|\n","|<h2>Section:</h2>|<h1>How to modify activations<h1>|\n","|<h2>Lecture:</h2>|<h1><b>Activation manipulation: Code implementations<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"_gPy1MwYgrhi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6NPsr5B0nv52"},"outputs":[],"source":["from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","import torch\n","\n","model = GPT2LMHeadModel.from_pretrained('gpt2')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","model.eval()"]},{"cell_type":"code","source":[],"metadata":{"id":"U8gopy6jnWbf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# some text to process\n","tokens = tokenizer.encode('I wish coffee would taste like chocolate.',return_tensors='pt')\n","\n","# the token we'll modify\n","tokenizer.decode(tokens[0,4])"],"metadata":{"id":"2RqxT-L_CxuU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"mAoKTPa2EoWw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hook demo 1 (doesn't work :P )"],"metadata":{"id":"0Z0nNwSvIo2u"}},{"cell_type":"code","source":["# initialize activations dictionary\n","activations = {}\n","\n","\n","def implant_hook(layer_number):\n","  def hook(module, input, output):\n","\n","    # -- GOAL: split into QKV then modify in-place\n","    # split the output into QKV (each is [B,S,E])\n","    q,k,v = output.split(model.config.hidden_size, dim=2)\n","\n","    # zero-out Q activations for token index 4\n","    q[:,4,:10] = 0\n","    # -- the above line crashes, b/c pytorch doesn't allow in-place editing\n","\n","    # Recombine the modified q with k and v\n","    QKV = torch.cat([q,k,v],dim=2)\n","\n","    # store the activations\n","    activations['qkv'] = output\n","\n","    # output the QKV matrix so it replaces the original\n","    return QKV\n","\n","  return hook\n","\n","\n","\n","layer2modify = 3\n","hookHandle = model.transformer.h[layer2modify].attn.c_attn.register_forward_hook(implant_hook(layer2modify))"],"metadata":{"id":"AVfMuAdeCxrb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# push the tokens through the model\n","model(tokens)"],"metadata":{"id":"EXvuXpSviGz6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hookHandle.remove()"],"metadata":{"id":"fug7NR07i246"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"F8JXHDTbTlS2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hook demo 2 (works but might require careful indexing)"],"metadata":{"id":"MM7MHg6yTlP1"}},{"cell_type":"code","source":["# initialize activations dictionary\n","activations = {}\n","\n","\n","def implant_hook(layer_number):\n","  def hook(module, input, output):\n","\n","    # this works (though you'd need to index carefully to access K or V)\n","    output[:,4,:10] = 0\n","\n","    # store the activations\n","    activations['qkv'] = output\n","\n","    # output the QKV matrix so it replaces the original\n","    return output\n","\n","  return hook\n","\n","\n","\n","layer2modify = 3\n","hookHandle = model.transformer.h[layer2modify].attn.c_attn.register_forward_hook(implant_hook(layer2modify))"],"metadata":{"id":"5tHVX8wmH-DI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# push the tokens through the model\n","model(tokens)\n","activations"],"metadata":{"id":"Luh4i0UiidW-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["activations['qkv'][:,:,:10]"],"metadata":{"id":"ugYZnyq2mC_v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hookHandle.remove()"],"metadata":{"id":"Cl9M7N_6ifyV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DORtmRPzInll"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hook demo 3 (works b/c of out-of-place instead of in-place operations)"],"metadata":{"id":"v8Mvo96sInio"}},{"cell_type":"code","source":["# initialize activations dictionary\n","activations = {}\n","\n","\n","def implant_hook(layer_number):\n","  def hook(module, input, output):\n","\n","    # -- GOAL: split into QKV then modify a copy of q\n","    # split the output into QKV (each is [B,S,E])\n","    q,k,v = output.split(model.config.hidden_size, dim=2)\n","\n","    # zero-out Q activations for token index 4\n","    q_copy = q.clone() # copy of q -- not a slice, so no in-place operations\n","    q_copy[:,4,:10] = 0 # static manipulation\n","\n","    # recombine the modified q with k and v\n","    QKV = torch.cat([q_copy,k,v],dim=2)\n","\n","    # store the activations\n","    activations['qkv'] = QKV\n","\n","    # output the QKV matrix so it replaces the original\n","    return QKV\n","\n","  return hook\n","\n","\n","\n","layer2modify = 3\n","hookHandle = model.transformer.h[layer2modify].attn.c_attn.register_forward_hook(implant_hook(layer2modify))"],"metadata":{"id":"Mc1XpXjHInbE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model(tokens)\n","activations"],"metadata":{"id":"NdSuydmOCxof"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# confirmation\n","activations['qkv'][0,4,:]"],"metadata":{"id":"OEiRtEFbIIPM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# remove the hook\n","hookHandle.remove()"],"metadata":{"id":"wXTtygIuZdhs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-hIeXIpaZde1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hook demo 4: cache all layers and manipulate only one"],"metadata":{"id":"5nwFUNlHZdb1"}},{"cell_type":"code","source":["# initialize activations dictionary\n","activations = {}\n","\n","\n","def implant_hook(layer_number):\n","  def hook(module, input, output):\n","\n","    # modify the activation only for this layer\n","    if layer_number==3:\n","      output[:,4,:10] = 0\n","\n","    # store the activations\n","    activations[f'qkv_{layer_number}'] = output\n","\n","    # output the QKV matrix so it replaces the original (unchanged for non-target layers)\n","    return output\n","\n","  return hook\n","\n","\n","handles = []\n","for layeri in range(12):\n","  h = model.transformer.h[layeri].attn.c_attn.register_forward_hook(implant_hook(layeri))\n","  handles.append(h) # get all the handles for later removal"],"metadata":{"id":"H26Iwia6ZdZM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["handles"],"metadata":{"id":"NKtmY5xubXxy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# push through the model\n","model(tokens)\n","activations.keys()"],"metadata":{"id":"XKIfVrZJbXvJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# confirm\n","for i in range(12):\n","  firstQs = activations[f'qkv_{i}'][0,4,:5].detach()\n","  print(f'Q acts from layer {i:2}:',firstQs)"],"metadata":{"id":"3dXTy-PjbXsM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# remove all handles\n","for h in handles:\n","  h.remove()"],"metadata":{"id":"b-guX3QfbXpz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cbirfB4sbXkQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hook demo 5: Dynamic manipulation"],"metadata":{"id":"iQ2H11pXdgbK"}},{"cell_type":"code","source":["# initialize activations dictionary\n","activations = {}\n","q2replace = torch.zeros(10)\n","\n","def implant_hook(layer_number):\n","  def hook(module, input, output):\n","\n","    # replace with a variable name\n","    output[:,4,:10] = q2replace\n","\n","    activations['qkv'] = output\n","    return output\n","  return hook\n","\n","layer2modify = 3\n","hookHandle = model.transformer.h[layer2modify].attn.c_attn.register_forward_hook(implant_hook(layer2modify))"],"metadata":{"id":"omJPLRFJdgYT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model(tokens)\n","activations['qkv'][0,4,:15].detach()"],"metadata":{"id":"2FFAhxI3dgVk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# make a new replacement\n","q2replace = torch.linspace(-1,.7,10)\n","\n","model(tokens)\n","activations['qkv'][0,4,:15].detach()"],"metadata":{"id":"CU3npX5rfn0i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hookHandle.remove()"],"metadata":{"id":"e7AgkeLafnyM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fn2f9FAHfnvv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hook demo 6: More flexibility with dictionary"],"metadata":{"id":"tzSiuBCAfntI"}},{"cell_type":"code","source":["# initialize activations dictionary\n","activations = {}\n","\n","# dictionary of replacements\n","act_replacements = {\n","    3 : torch.zeros(8),\n","    8 : torch.arange(5)\n","    }\n","\n","\n","def implant_hook(layer_number):\n","  def hook(module, input, output):\n","\n","    # modify the activation if this layer has a key in the dictionary\n","    if layer_number in act_replacements.keys():\n","      newdata = act_replacements[layer_number]\n","      output[:,4,:len(newdata)] = newdata\n","\n","    # store the activations\n","    activations[f'qkv_{layer_number}'] = output\n","\n","    # output the QKV matrix so it replaces the original (unchanged for non-target layers)\n","    return output\n","\n","  return hook\n","\n","\n","handles = []\n","for layeri in range(12):\n","  h = model.transformer.h[layeri].attn.c_attn.register_forward_hook(implant_hook(layeri))\n","  handles.append(h) # get all the handles for later removal"],"metadata":{"id":"Y83gY6jdhT8V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# confirm\n","model(tokens)\n","for i in range(12):\n","  firstQs = activations[f'qkv_{i}'][0,4,:8].detach()\n","  print(f'Q acts from layer {i:2}:\\n ',firstQs)"],"metadata":{"id":"bu1q-oWOfnqh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# remove one replacement\n","del act_replacements[8]\n","\n","# add another\n","act_replacements[11] = torch.tensor([1,2,3])\n","\n","act_replacements"],"metadata":{"id":"1aCc4zhJmUGo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# try again\n","model(tokens)\n","for i in range(12):\n","  firstQs = activations[f'qkv_{i}'][0,4,:8].detach()\n","  print(f'Q acts from layer {i:2}:\\n ',firstQs)"],"metadata":{"id":"1KhZ93LpQon5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# remove all handles\n","for h in handles:\n","  h.remove()"],"metadata":{"id":"I-lP64khhQp-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for k,i in act_replacements.items():\n","  print(f'key {k} has values {i}')"],"metadata":{"id":"G4tD83W1jMgC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GrYvAOawhQaV"},"execution_count":null,"outputs":[]}]}