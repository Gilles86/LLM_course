{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyOQicCYTARDI5nMoKWGN9+l"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Algq7B3TWT_S"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 6:</h2>|<h1>Intervention (causal) mech interp<h1>|\n","|<h2>Section:</h2>|<h1>Modifying MLP<h1>|\n","|<h2>Lecture:</h2>|<h1><b>Statistical criteria to lesion MLP neurons<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"dVdgcMR4IljT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RuKeB769HOkN"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","from matplotlib.gridspec import GridSpec\n","\n","import scipy.stats as stats\n","from statsmodels.stats.multitest import fdrcorrection\n","\n","import torch\n","import torch.nn.functional as F\n","\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":["from transformers import BertTokenizer, BertForMaskedLM\n","\n","# Load pre-trained BERT model and tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n","model.eval()"],"metadata":{"id":"83A8PoVGRFj-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nneurons = model.bert.encoder.layer[4].intermediate.dense.weight.shape[0]\n","nneurons, model.bert.encoder.layer[4].intermediate"],"metadata":{"id":"jqTjLQ3NrqHj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5jWDecMYNTzh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part 1: Get MLP t-values for him-vs-her"],"metadata":{"id":"YI_EkZGRHaXr"}},{"cell_type":"code","source":["# dictionary to store the mlp activations\n","mlp_values = {}\n","\n","def implant_hook(layer_number):\n","  def hook(module, input, output):\n","    mlp_values[f'L{layer_number}'] = output.detach().numpy() # detach from the computational graph\n","  return hook\n","\n","\n","# surgery ;)\n","whichlayer = 9\n","handle = model.bert.encoder.layer[whichlayer].intermediate.dense.register_forward_hook(implant_hook(whichlayer))"],"metadata":{"id":"pQ6zFv8PY4B4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"E1IwRC6lI-oM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Forward pass and get activations"],"metadata":{"id":"BHcZCWR2I-lF"}},{"cell_type":"code","source":["# generated by Claude.ai\n","sentences = [\n","    \"I saw him at the market.\",\n","    \"She gave him the book.\",\n","    \"They asked him for advice.\",\n","    \"We invited him to dinner.\",\n","    \"The dog followed him home.\",\n","    \"They asked him to join.\",\n","    \"He saw him at the park yesterday.\",\n","    \"Did you give him your address?\",\n","    \"I haven't seen him in ages.\",\n","    \"I told him the truth.\",\n","    \"They congratulated him on his success.\",\n","    \"She recognized him immediately.\",\n","    \"The teacher praised him for his work.\",\n","    \"I met him last summer.\",\n","    \"The child hugged him tightly.\",\n","    \"They warned him about the danger.\",\n","    \"She drove him to the airport.\",\n","    \"We waited for him for hours.\",\n","    \"The cat scratched him accidentally.\",\n","    \"They surprised him with a gift.\",\n","    \"She called him on the phone.\",\n","    \"The jury found him not guilty.\",\n","    \"I remembered him from school.\",\n","    \"They elected him as president.\",\n","    \"She forgave him for his mistake.\",\n","    \"The police questioned him yesterday.\",\n","    \"I helped him with his homework.\",\n","    \"They spotted him in the crowd.\",\n","    \"She visited him in the hospital.\",\n","    \"The manager promoted him last week.\",\n","    \"I trusted him completely.\",\n","    \"They respected him for his honesty.\",\n","    \"She taught him how to swim.\",\n","    \"The bird attacked him suddenly.\",\n","    \"I greeted him warmly.\",\n","    \"They supported him through difficult times.\",\n","    \"She ignored him at the party.\",\n","    \"The judge sentenced him to community service.\",\n","    \"I photographed him during the event.\",\n","    \"They believed him despite the evidence.\",\n","    \"She surprised him on his birthday.\",\n","    \"The guard stopped him at the entrance.\",\n","    \"I missed him terribly.\",\n","    \"They watched him leave the building.\",\n","    \"She accompanied him to the concert.\",\n","    \"The crowd cheered him enthusiastically.\",\n","    \"I described him to the police.\",\n","    \"They thanked him for his help.\",\n","    \"She admired him for his courage.\",\n","    \"The committee nominated him for the award.\",\n","    \"I married him last spring.\",\n","    \"They informed him about the changes.\",\n","    \"She introduced him to the parents.\",\n","    \"The author based the character on him.\",\n","\n","## same sentences but with \"her\"\n","\n","    \"I saw her at the market.\",\n","    \"She gave her the book.\",\n","    \"They asked her for advice.\",\n","    \"We invited her to dinner.\",\n","    \"The dog followed her home.\",\n","    \"They asked her to join.\",\n","    \"He saw her at the park yesterday.\",\n","    \"Did you give her your address?\",\n","    \"I haven't seen her in ages.\",\n","    \"I told her the truth.\",\n","    \"They congratulated her on his success.\",\n","    \"She recognized her immediately.\",\n","    \"The teacher praised her for his work.\",\n","    \"I met her last summer.\",\n","    \"The child hugged her tightly.\",\n","    \"They warned her about the danger.\",\n","    \"She drove her to the airport.\",\n","    \"We waited for her for hours.\",\n","    \"The cat scratched her accidentally.\",\n","    \"They surprised her with a gift.\",\n","    \"She called her on the phone.\",\n","    \"The jury found her not guilty.\",\n","    \"I remembered her from school.\",\n","    \"They elected her as president.\",\n","    \"She forgave her for his mistake.\",\n","    \"The police questioned her yesterday.\",\n","    \"I helped her with his homework.\",\n","    \"They spotted her in the crowd.\",\n","    \"She visited her in the hospital.\",\n","    \"The manager promoted her last week.\",\n","    \"I trusted her completely.\",\n","    \"They respected her for his honesty.\",\n","    \"She taught her how to swim.\",\n","    \"The bird attacked her suddenly.\",\n","    \"I greeted her warmly.\",\n","    \"They supported her through difficult times.\",\n","    \"She ignored her at the party.\",\n","    \"The judge sentenced her to community service.\",\n","    \"I photographed her during the event.\",\n","    \"They believed her despite the evidence.\",\n","    \"She surprised her on his birthday.\",\n","    \"The guard stopped her at the entrance.\",\n","    \"I missed her terribly.\",\n","    \"They watched her leave the building.\",\n","    \"She accompanied her to the concert.\",\n","    \"The crowd cheered her enthusiastically.\",\n","    \"I described her to the police.\",\n","    \"They thanked her for his help.\",\n","    \"She admired her for his courage.\",\n","    \"The committee nominated her for the award.\",\n","    \"I married her last spring.\",\n","    \"They informed her about the changes.\",\n","    \"She introduced her to the parents.\",\n","    \"The author based the character on her.\"\n","]\n","\n","# indices of him/her sentences\n","him_sentences = np.arange(len(sentences)//2)\n","her_sentences = np.arange(len(sentences)//2,len(sentences))\n","\n","print(f'There are {len(sentences)} sentences.')"],"metadata":{"id":"oqdAP54II-ht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"b4FPftBucXrh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# identify the target token\n","target_token_him = tokenizer.encode('him',add_special_tokens=False)[0]\n","target_token_her = tokenizer.encode('her',add_special_tokens=False)[0]\n","print(f'The target token indices are {target_token_him} and {target_token_her}\\n')\n","\n","# tokenize\n","tokens = tokenizer(sentences,padding=True,return_tensors='pt')"],"metadata":{"id":"fYPkVigeOv47"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokens"],"metadata":{"id":"GTWCnORaa_24"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JGs7C-adPhDN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Forward pass and get the activations"],"metadata":{"id":"mfoQcUcLPl58"}},{"cell_type":"code","source":["with torch.no_grad():\n","  model(**tokens)\n","\n","handle.remove()\n","\n","mlp_values[f'L{whichlayer}'].shape"],"metadata":{"id":"YAMzPriHL7SD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# histogram bin edges\n","binedges = np.linspace(-10,10,101)\n","\n","plt.figure(figsize=(10,4))\n","y,_ = np.histogram(mlp_values[f'L{whichlayer}'].flatten(),binedges)\n","plt.plot(binedges[:-1],y,linewidth=2,label='Pre-gelu')\n","\n","y,_ = np.histogram(F.gelu(torch.tensor(mlp_values[f'L{whichlayer}'].flatten())),binedges)\n","plt.plot(binedges[:-1],y,linewidth=2,label='Post-gelu')\n","\n","plt.legend()\n","plt.gca().set(xlim=binedges[[0,-1]],xlabel='Activation value',ylabel='Count',yscale='log')\n","plt.show()"],"metadata":{"id":"j8acoQAgWteX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loop through sentences to get target activations\n","\n","acts = np.zeros((len(sentences),mlp_values[f'L{whichlayer}'].shape[2]))\n","\n","for senti in range(len(sentences)):\n","\n","  # find the index of either of the target tokens\n","  targBool = np.isin(tokens['input_ids'][senti].numpy(),[target_token_him,target_token_her])\n","  targidx = np.where(targBool)[0]\n","\n","  # reminder: the np.where() code works fine here b/c each sentence contains exactly one occurrance of the target\n","  # see other code files for multiple target words per sentence.\n","\n","  # then get the activation\n","  acts[senti,:] = mlp_values[f'L{whichlayer}'][senti,targidx,:]\n","\n","acts.shape"],"metadata":{"id":"IG2NYyxvWtUp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3n8ZMz1ok-Uu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# t-test and find significant neurons via FDR (correction for multiple comparisons)\n","tres = stats.ttest_1samp(acts[:54,:]-acts[54:,:],popmean=0,axis=0)\n","issig = tres.pvalue < fdrcorrection(tres.pvalue)[0]\n","\n","himNeurons = issig & (tres.statistic>0)\n","herNeurons = issig & (tres.statistic<0)\n","\n","plt.figure(figsize=(10,5))\n","plt.plot(np.where(~issig)[0],tres.statistic[~issig],'rx',alpha=.4,label='Non-sig.')\n","plt.plot(np.where(himNeurons)[0],tres.statistic[himNeurons],'ks',markerfacecolor=[.7,.9,.7,.5],label='him > her')\n","plt.plot(np.where(herNeurons)[0],tres.statistic[herNeurons],'ks',markerfacecolor=[.9,.7,.7,.5],label='her > him')\n","\n","plt.legend()\n","plt.gca().set(xlim=[-1,nneurons],xlabel='MLP expansion neurons',ylabel='T-value',\n","              title=f'{himNeurons.sum()} \"him\" neurons and {herNeurons.sum()} \"her\" neurons')\n","plt.show()"],"metadata":{"id":"D1F5r62TWtRR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"YEw3Ou0nWtOH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part 2: Confirm BERT can make accurate predictions"],"metadata":{"id":"Fr48LXRAWtLE"}},{"cell_type":"code","source":["texts = [ 'Robert helped Lucy with her project, and she thanked him for his hard work.',\n","          'Robert helped Lucy with [MASK] project, and she thanked him for his hard work.',\n","          'Robert helped Lucy with her project, and she thanked [MASK] for his hard work.' ]\n","\n","# tokenize\n","tokens = tokenizer(texts,return_tensors='pt')\n","tokens"],"metadata":{"id":"quAcxaQxhklO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# find indices of [MASK]\n","mask_idx_her = torch.where(tokens['input_ids'][1] == tokenizer.mask_token_id)[0].item()\n","mask_idx_him = torch.where(tokens['input_ids'][2] == tokenizer.mask_token_id)[0].item()\n","\n","print(f'Masks are at indices {mask_idx_her} and {mask_idx_him}')"],"metadata":{"id":"rXaX6d6RAuft"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():\n","  out = model(**tokens)\n","\n","logits = out.logits.detach().numpy()\n","logits.shape"],"metadata":{"id":"RU38n2SnWtH9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_logits = np.zeros((3,2,2))\n","\n","for senti in range(3):\n","  target_logits[senti,0,:] = logits[senti,mask_idx_her,[target_token_her,target_token_him]]\n","  target_logits[senti,1,:] = logits[senti,mask_idx_him,[target_token_her,target_token_him]]\n","\n","target_logits"],"metadata":{"id":"GZh5E5_tWtBc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,4))\n","\n","for i in range(3):\n","  plt.bar(np.array([-.1,.1])+i*1.5,target_logits[i,0,:],width=.2,facecolor=[[.9,.7,.9],[.7,.9,.9]],edgecolor='k')\n","  plt.bar(np.array([-.1,.1])+i*1.5+.5,target_logits[i,1,:],width=.2,facecolor=[[.9,.7,.9],[.7,.9,.9]],edgecolor='k')\n","\n","# create the bar labels\n","basetxt = 'her :: him     her :: him\\n----------------+----------------\\nher token   ||   him token'\n","xticklabels = [ basetxt + '\\n\\n|__________$\\\\bf{Clean}$_________|',\n","                basetxt + '\\n\\n|_______$\\\\bf{HER\\; mask}$_______|',\n","                basetxt + '\\n\\n|_______$\\\\bf{HIM\\; mask}$_______|' ]\n","\n","plt.gca().set(xticks=np.arange(.25,3.5,1.5),xticklabels=xticklabels,ylabel='Logits')\n","plt.show()"],"metadata":{"id":"QsCvUrpdpGyl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CeYwsFsjWs-B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part 3: Manipulate \"him\" and \"her\" neurons in MLP"],"metadata":{"id":"Am4TmiarWs6T"}},{"cell_type":"code","source":["def implant_hook(layer_number):\n","  def ablation_hook(module, input, output):\n","    output[1,mask_idx_her,herNeurons] = 0\n","    output[2,mask_idx_him,himNeurons] = 0\n","    return output\n","  return ablation_hook\n","\n","# question: should we hook into intermediate or intermediate.dense?\n","handle = model.bert.encoder.layer[whichlayer].intermediate.register_forward_hook(implant_hook(whichlayer))\n"],"metadata":{"id":"8aviMiRSn2Yc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():\n","  out = model(**tokens)\n","\n","handle.remove()\n","logitsZero = out.logits.detach().numpy()\n","logitsZero.shape"],"metadata":{"id":"0gnLylyztdkU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["target_logitsZ = np.zeros((3,2,2))\n","\n","for senti in range(3):\n","  target_logitsZ[senti,0,:] = logitsZero[senti,mask_idx_her,[target_token_her,target_token_him]]\n","  target_logitsZ[senti,1,:] = logitsZero[senti,mask_idx_him,[target_token_her,target_token_him]]\n","\n","target_logitsZ"],"metadata":{"id":"8nykC36itdkV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = plt.figure(figsize=(13,5))\n","gs = GridSpec(1,3,figure=fig)\n","ax0 = fig.add_subplot(gs[:2])\n","ax1 = fig.add_subplot(gs[2])\n","\n","deltaLogits = target_logits - target_logitsZ\n","\n","for i in range(3):\n","  ax0.bar(np.array([-.1,.1])+i*1.5,deltaLogits[i,0,:],width=.2,facecolor=[[.9,.7,.9],[.7,.9,.9]],edgecolor='k')\n","  ax0.bar(np.array([-.1,.1])+i*1.5+.5,deltaLogits[i,1,:],width=.2,facecolor=[[.9,.7,.9],[.7,.9,.9]],edgecolor='k')\n","\n","ax0.axhline(0,color='k',linewidth=.2)\n","ax0.set(xticks=np.arange(.25,3.5,1.5),xticklabels=xticklabels,ylabel='$\\Delta$ logits',\n","        title=f'$\\Delta$ from clean (ablation in layer {whichlayer})')\n","\n","ax1.plot(target_logits.flatten(),target_logitsZ.flatten(),'ko',markerfacecolor=[.7,.9,.9,.6],markersize=10)\n","ax1.set(xlabel='Clean logits',ylabel='Ablation logits')\n","ax1.grid(linewidth=.4)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"GqIgUuzbn2bb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xBncWPz9Ws0t"},"execution_count":null,"outputs":[]}]}