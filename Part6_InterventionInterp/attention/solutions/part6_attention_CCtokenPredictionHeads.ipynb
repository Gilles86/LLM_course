{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyOcacYrir4JxzhoD0paBDOJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 6:</h2>|<h1>Intervention (causal) mech interp<h1>|\n","|<h2>Section:</h2>|<h1>Interfering with attention <h1>|\n","|<h2>Lecture:</h2>|<h1><b>CodeChallenge: Token prediction after head ablations<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">udemy.com/course/dulm_x/?couponCode=202509</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"_gPy1MwYgrhi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6NPsr5B0nv52"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","from matplotlib.gridspec import GridSpec\n","\n","from tqdm import tqdm\n","\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","import torch\n","import torch.nn.functional as F\n","\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":[],"metadata":{"id":"PPLDxIujCnTK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 1: Model, hook, tokens"],"metadata":{"id":"S_JBf3BvCnQS"}},{"cell_type":"code","source":["model = GPT2LMHeadModel.from_pretrained('gpt2')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","model = model.to(device)\n","model.eval()"],"metadata":{"id":"m5QXl5irtjBh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# some useful variables\n","nheads = model.config.n_head\n","n_emb = model.config.n_embd\n","head_dim = model.config.n_embd // nheads"],"metadata":{"id":"HZ6DyuqKtkyu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def implant_hook(layer_number):\n","  def hook4attn(module,input):\n","\n","    # print some useful information\n","    # print(len(input),type(input),input[0].shape)\n","\n","    # modify the activation only for this layer\n","    if (layer_number==layer2ablate) & (head2ablate in range(0,nheads)):\n","\n","      # reshape so we can index heads\n","      head_tensor = input[0].view(nbatches,ntokens,nheads,head_dim)\n","\n","      # specify the value to replace\n","      if replaceWithZeros == True:\n","        value2replace = 0\n","      else:\n","        value2replace = head_tensor[:,:,head2ablate,:].mean()\n","        global observedHeadMean\n","        observedHeadMean = value2replace\n","\n","      # then replace\n","      head_tensor[:,:,head2ablate,:] = value2replace\n","\n","      # print confirmation\n","      # print(f'Zeroed out L{layer_number}, H{head2ablate}')\n","\n","      # reshape back to tensor\n","      head_tensor = head_tensor.view(nbatches,ntokens,n_emb)\n","\n","      # return a tuple matching the original\n","      input = (head_tensor,*input[1:])\n","\n","    return input\n","  return hook4attn\n","\n","\n","handles = []\n","for layeri in range(model.config.n_layer):\n","  h = model.transformer.h[layeri].attn.c_proj.register_forward_pre_hook(implant_hook(layeri))\n","  handles.append(h)"],"metadata":{"id":"Iy0kVnQztkvz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokens = tokenizer.encode('Berlin is the capital of',return_tensors='pt')\n","nbatches,ntokens = tokens.shape\n","tokens = tokens.to(device)\n","\n","for i in range(ntokens):\n","  print(f'Token position {i:2} is index {tokens[0,i]} and is \"{tokenizer.decode(tokens[0,i])}\"')"],"metadata":{"id":"qvvEHGz9tksP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# target and semantically related nontarget\n","nontarget_idx = tokenizer.encode(' France')[0]\n","target_idx = tokenizer.encode(' Germany')[0]\n","\n","# confirm single-tokens\n","nontarget_idx,target_idx"],"metadata":{"id":"yBcAXDnWEKpF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"czPntE-oES19"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2: Confirm accuracy and get clean logits"],"metadata":{"id":"vO-xoXMqESzZ"}},{"cell_type":"code","source":["layer2ablate = 1000\n","head2ablate = 1000\n","\n","with torch.no_grad():\n","  out = model(tokens)\n","\n","# calculate softmax probability in percent\n","sm_clean = 100 * F.softmax(out.logits[0,-1,:],dim=-1).detach().cpu().numpy()"],"metadata":{"id":"aktYlZw3wrp7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10,4))\n","\n","# all the log-sm values\n","plt.plot(np.log(sm_clean/100),'k.',markersize=2,alpha=.3)\n","\n","# the target and nontarget values\n","plt.plot(target_idx,np.log(sm_clean[target_idx]/100),'gs',label='Germany')\n","plt.plot(nontarget_idx,np.log(sm_clean[nontarget_idx]/100),'ro',label='France')\n","\n","# make the graph look pretty :D\n","plt.gca().set(xlabel='Vocab elements',ylabel='Log softmax',xlim=[0,model.config.vocab_size])\n","plt.title(f'Predicted next token is \"{tokenizer.decode(np.argmax(sm_clean))}\"')\n","plt.legend()\n","\n","plt.show()"],"metadata":{"id":"vlIIvcC7tkpK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5uGtLMFmtklw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 3: Zero-out attention heads for all token indices"],"metadata":{"id":"t2RPBEtECytS"}},{"cell_type":"code","source":["replaceWithZeros = True"],"metadata":{"id":"PmBRWsW-HTbx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resultsZero = np.zeros((model.config.n_layer,nheads,3))\n","\n","# loop over layers and heads\n","for layer2ablate in tqdm(range(model.config.n_layer),desc='Layers...'):\n","  for head2ablate in range(nheads):\n","\n","    # forward pass\n","    with torch.no_grad():\n","      out = model(tokens)\n","\n","    # softmax\n","    sm = 100 * F.softmax(out.logits[0,-1,:],dim=-1).detach().cpu().numpy()\n","\n","    # sm logits for target and nontarget\n","    resultsZero[layer2ablate,head2ablate,0] = sm[target_idx]\n","    resultsZero[layer2ablate,head2ablate,1] = sm[nontarget_idx]\n","\n","    # and the predicted next token\n","    resultsZero[layer2ablate,head2ablate,2] = np.argmax(sm)"],"metadata":{"id":"l07sNt7htkip"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig,axs = plt.subplots(1,2,figsize=(10,4))\n","\n","clim = 5\n","\n","h = axs[0].imshow(resultsZero[:,:,0].T - sm_clean[target_idx],vmin=-clim,vmax=clim,cmap=mpl.cm.plasma,aspect='auto')\n","axs[0].set(xlabel='Layer',ylabel='Head',yticks=range(0,nheads,2),title='%$\\Delta$ in prob. for target word')\n","fig.colorbar(h,ax=axs[0],pad=.01)\n","\n","h = axs[1].imshow(resultsZero[:,:,1].T - sm_clean[nontarget_idx],vmin=-clim,vmax=clim,cmap=mpl.cm.plasma,aspect='auto')\n","axs[1].set(xlabel='Layer',ylabel='Head',yticks=range(0,nheads,2),title='%$\\Delta$ in prob. for non-target word')\n","fig.colorbar(h,ax=axs[1],pad=.01)\n","\n","plt.suptitle('Change in token selection probability from clean model',fontweight='bold')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"ojMdlVejOGQB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["u,c = np.unique(resultsZero[:,:,2],return_counts=True)\n","for ui,ci in zip(u,c):\n","  print(f'In {ci}/{c.sum()} runs, the model selected token \"{tokenizer.decode(int(ui))}\"')"],"metadata":{"id":"voQIYDffI76s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"llSLlyGw1EAx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 4: Repeat with head mean imputation"],"metadata":{"id":"Zka0lkRdIm67"}},{"cell_type":"code","source":["replaceWithZeros = False"],"metadata":{"id":"hEFRzP9wIxTO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["resultsMean = np.zeros((model.config.n_layer,nheads,4))\n","\n","# loop over layers and heads\n","for layer2ablate in tqdm(range(model.config.n_layer),desc='Layers...'):\n","  for head2ablate in range(nheads):\n","\n","    # forward pass\n","    with torch.no_grad():\n","      out = model(tokens)\n","\n","    # log-softmax\n","    sm = 100 * F.softmax(out.logits[0,-1,:],dim=-1).detach().cpu().numpy()\n","\n","    # log-sm logits for target and nontarget\n","    resultsMean[layer2ablate,head2ablate,0] = sm[target_idx]\n","    resultsMean[layer2ablate,head2ablate,1] = sm[nontarget_idx]\n","\n","    # the empirical mean value that was imputed\n","    resultsMean[layer2ablate,head2ablate,2] = observedHeadMean\n","\n","    # and the predicted next token\n","    resultsMean[layer2ablate,head2ablate,3] = np.argmax(sm)\n"],"metadata":{"id":"pLeOW9bDItDG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig,axs = plt.subplots(1,2,figsize=(10,4))\n","\n","clim = 5\n","\n","h = axs[0].imshow(resultsMean[:,:,0].T - sm_clean[target_idx],vmin=-clim,vmax=clim,cmap=mpl.cm.plasma,aspect='auto')\n","axs[0].set(xlabel='Layer',ylabel='Head',yticks=range(0,nheads,2),\n","           title='%$\\Delta$ in prob. for target word')\n","fig.colorbar(h,ax=axs[0],pad=.01)\n","\n","h = axs[1].imshow(resultsMean[:,:,1].T - sm_clean[nontarget_idx],vmin=-clim,vmax=clim,cmap=mpl.cm.plasma,aspect='auto')\n","axs[1].set(xlabel='Layer',ylabel='Head',yticks=range(0,nheads,2),\n","           title='%$\\Delta$ in prob. for non-target word')\n","fig.colorbar(h,ax=axs[1],pad=.01)\n","\n","plt.suptitle('Change in token selection probability from clean model',fontweight='bold')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"1HB5WVsvItDG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["u,c = np.unique(resultsMean[:,:,3],return_counts=True)\n","for ui,ci in zip(u,c):\n","  print(f'In {ci}/{c.sum()} runs, the model selected token \"{tokenizer.decode(int(ui))}\"')"],"metadata":{"id":"hosww27_1D73"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# head-averaged activations\n","fig,axs = plt.subplots(1,2,figsize=(12,5))\n","\n","axs[0].plot(resultsMean[:,:,2].flatten(),'ko',markerfacecolor=[.9,.7,.7,.6])\n","axs[0].set(xlabel='Heads $\\\\times$ layer (index)',ylabel='Head mean',title='As scatter plot')\n","\n","h = axs[1].imshow(resultsMean[:,:,2].T,vmin=-.05,vmax=.05,cmap=mpl.cm.plasma,aspect='auto')\n","axs[1].set(xlabel='Layer',ylabel='Head',yticks=range(0,nheads,2),title='As image')\n","fig.colorbar(h,ax=axs[1],pad=.02,fraction=.05)\n","\n","plt.suptitle('Head activation averages',fontweight='bold')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"q_-6y5jS1Dq8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"X2IV-v341D47"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 5: Comparisons"],"metadata":{"id":"73cmCZ3oPocv"}},{"cell_type":"code","source":["# setup the figure\n","fig = plt.figure(figsize=(13,4))\n","gs  = GridSpec(1,3,figure=fig)\n","axs = [ fig.add_subplot(gs[:2]) , fig.add_subplot(gs[-1]) ]\n","\n","\n","### histograms\n","nbins = 20\n","\n","y,x = np.histogram(resultsZero[:,:,0].flatten() - sm_clean[target_idx],nbins)\n","axs[0].plot(x[:-1],y,'.-',linewidth=2,markersize=10,label='Zero target')\n","\n","y,x = np.histogram(resultsMean[:,:,0].flatten() - sm_clean[target_idx],nbins)\n","axs[0].plot(x[:-1],y,'.-',linewidth=2,markersize=10,label='Mean target')\n","\n","y,x = np.histogram(resultsZero[:,:,1].flatten() - sm_clean[nontarget_idx],nbins)\n","axs[0].plot(x[:-1],y,linewidth=2,label='Zero nontarget')\n","\n","y,x = np.histogram(resultsMean[:,:,1].flatten() - sm_clean[nontarget_idx],nbins)\n","axs[0].plot(x[:-1],y,linewidth=2,label='Mean nontarget')\n","\n","axs[0].set(xlabel='Token probability ($\\Delta$ from clean model)',ylabel='Count',ylim=[-1,None],\n","           title='Histograms of $\\Delta$ softmax')\n","axs[0].legend(fontsize=15)\n","\n","\n","# difference heat map\n","h = axs[1].imshow(resultsMean[:,:,0].T - resultsZero[:,:,0].T,vmin=-1,vmax=1,cmap=mpl.cm.plasma,aspect='auto')\n","axs[1].set(xlabel='Layer',ylabel='Head',yticks=range(0,nheads,2),title='$\\Delta$ target: (mean - zero)')\n","fig.colorbar(h,ax=axs[1],pad=.02,fraction=.05)\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"5nHg26111D2U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3J-RMtP-yXzE"},"execution_count":null,"outputs":[]}]}