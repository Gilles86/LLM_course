{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyMAFByIUptcDyJrXfxjgqHl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"q4V_8g5aP6J7"},"outputs":[],"source":[]},{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 6:</h2>|<h1>Intervention (causal) mech interp<h1>|\n","|<h2>Section:</h2>|<h1>Interfering with attention<h1>|\n","|<h2>Lecture:</h2>|<h1><b>Attention head patching in IOI<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"vEQLNzgMunaD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6NPsr5B0nv52"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","import torch\n","\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":[],"metadata":{"id":"hTWsybWmZJe-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import the model and create tokens"],"metadata":{"id":"ny-nH3gniySB"}},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","model = GPT2LMHeadModel.from_pretrained('gpt2').to(device)\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","\n","n_layers = model.config.n_layer\n","model.eval()"],"metadata":{"id":"pFyxDs3UaDiw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_A = 'When Sam and Sally went to the park, Sam gave a gift to'\n","text_B = 'When Sam and Sally went to the park, Sally gave a gift to'\n","\n","target_A = tokenizer.encode(' Sam')[0]\n","target_B = tokenizer.encode(' Sally')[0]\n","\n","tokensA = tokenizer.encode(text_A,return_tensors='pt').to(device)\n","tokensB = tokenizer.encode(text_B,return_tensors='pt').to(device)"],"metadata":{"id":"iKaNCGyPunU1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NqZsbWmnyR5v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Get clean attention vectors from \"A\""],"metadata":{"id":"mpYaYrB9-PmN"}},{"cell_type":"code","source":["# some useful variables\n","nbatches,ntokens = tokensA.shape\n","\n","nheads = model.config.n_head\n","nlayers = model.config.n_layer\n","n_emb = model.config.n_embd\n","head_dim = model.config.n_embd // nheads"],"metadata":{"id":"zxToX7P2-lwV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["head_acts_A = {}\n","\n","def hook4attn_acts(layer_number):\n","  def hook(module,input):\n","\n","    # reshape for indexing convenience\n","    head_tensor = input[0].view(nbatches,ntokens,nheads,head_dim)\n","\n","    # and store\n","    head_acts_A[f'L{layer_number}'] = head_tensor\n","  return hook\n","\n","\n","handles = []\n","for layeri in range(nlayers):\n","  h = model.transformer.h[layeri].attn.c_proj.register_forward_pre_hook(hook4attn_acts(layeri))\n","  handles.append(h)"],"metadata":{"id":"ERTDO0Ea-XCJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fdJt6gb_-PjX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Get \"clean\" data on texts (no patching)"],"metadata":{"id":"NNhsbhTxjVoz"}},{"cell_type":"code","source":["with torch.no_grad():\n","  outA = model(tokensA)\n","\n","# remove the hooks to avoid overwriting head_acts_A\n","for h in handles: h.remove()\n","\n","# now run tokensB without the hooks\n","with torch.no_grad():\n","  outB = model(tokensB)"],"metadata":{"id":"vgUVkKNounSL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logitDiff_A = outA.logits[0,-1,target_A] - outA.logits[0,-1,target_B]\n","logitDiff_B = outB.logits[0,-1,target_A] - outB.logits[0,-1,target_B]\n","\n","print(f'Logit difference for text \"A\": {logitDiff_A:6.3f}')\n","print(f'Logit difference for text \"B\": {logitDiff_B:6.3f}')"],"metadata":{"id":"8EAYrp4okirZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check the activations\n","head_acts_A.keys(), head_acts_A['L4'].shape"],"metadata":{"id":"AAxlWm-r_Ra8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"eT34F4ZEa1l1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initializations\n","logitDiffs = np.zeros(n_layers)\n","head_acts_B = {}\n","\n","\n","# loop over layers\n","for layeri in range(n_layers):\n","\n","\n","  # patch this layer and one head\n","  def hook2patch(module,input):\n","\n","    # reshape to index heads\n","    head_tensor = input[0].reshape(nbatches,ntokens,nheads,head_dim).clone()\n","\n","    # patch (replace all tokens and heads, with those from tokensA)\n","    head_tensor = head_acts_A[f'L{layeri}']\n","\n","    # get the attention head activations for methodological confirmation\n","    head_acts_B[f'L{layeri}'] = head_tensor\n","\n","    # reshape back to tensor\n","    head_tensor = head_tensor.reshape(nbatches,ntokens,n_emb)\n","\n","    # return a tuple matching the original\n","    input = (head_tensor,*input[1:])\n","\n","    return input\n","\n","  # implant the hook\n","  handle = model.transformer.h[layeri].attn.c_proj.register_forward_pre_hook(hook2patch)\n","\n","  # forward pass with hook\n","  with torch.no_grad(): outB = model(tokensB)\n","\n","  # remove the hook\n","  handle.remove()\n","\n","  # now for the logit-difference test\n","  logitDiffs[layeri] = outB.logits[0,-1,target_A] - outB.logits[0,-1,target_B]\n"],"metadata":{"id":"A-4XyKOC96jh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Fl21Hz_XNwRg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Confirm the patching"],"metadata":{"id":"jLpdqoI8Nwor"}},{"cell_type":"code","source":["head_acts_B.keys(), head_acts_B['L4'].shape"],"metadata":{"id":"U7C65UiZ96dx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8,4))\n","\n","plt.plot(head_acts_A['L7'][0,10,11,:].cpu(),'ko',markerfacecolor=[.7,.9,.7],markersize=8,label='Original from \"A\"')\n","plt.plot(head_acts_B['L7'][0,10,11,:].cpu(),'rx',markersize=10,label='Patched into \"B\"')\n","\n","plt.legend()\n","plt.gca().set(xlabel='Attention head dimension',ylabel='Activation value')\n","plt.show()"],"metadata":{"id":"xr-2lasN96au"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wk9VIuuoNwly"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Visualize the patching results"],"metadata":{"id":"S3juiLUFNwPD"}},{"cell_type":"code","source":["# visualization\n","plt.figure(figsize=(11,4))\n","\n","# plot the logit differences for the \"clean\" runs (no patching)\n","plt.axhline(logitDiff_A.cpu(),color='b',label='Clean \"A\"')\n","plt.axhline(logitDiff_B.cpu(),color='r',label='Clean \"B\"')\n","\n","# then for the experiment results\n","plt.plot(logitDiffs,'ko',markerfacecolor=[.9,.7,.9],markersize=10,label='A patched to B')\n","\n","# the dividing line\n","plt.axhline(0,linestyle='--',color='gray',linewidth=.5)\n","plt.text(0,.1,'Prefer \"Sam\"',fontsize=12,va='bottom')\n","plt.text(0,-.1,'Prefer \"Sally\"',fontsize=12,va='top')\n","\n","plt.gca().set(xlabel='Transformer block',ylabel='Logit difference',title='Reversing logit bias towards target-Sam')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"EfEeQBrE96gd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"W6tGZzXjH7D2"},"execution_count":null,"outputs":[]}]}