{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyO8KwLus9LRFE6wES6Z0RcS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 2:</h2>|<h1>Large language models<h1>|\n","|<h2>Section:</h2>|<h1>Fine-tune pretrained models<h1>|\n","|<h2>Lecture:</h2>|<h1><b>CodeGen for code completion<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">udemy.com/course/dulm_x/?couponCode=202509</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"NW8VdUsWAxgG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"N6_UeqNSZhCH"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","\n","# GPU\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","source":[],"metadata":{"id":"rXCWZxIgqD4c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import and inspect the CodeGen model"],"metadata":{"id":"20NAkByVqD1x"}},{"cell_type":"code","source":["# Model source:\n","# https://huggingface.co/Salesforce/codegen-350M-mono\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","tokenizer = AutoTokenizer.from_pretrained('Salesforce/codegen-350M-mono')\n","\n","model = AutoModelForCausalLM.from_pretrained('Salesforce/codegen-350M-mono').to(device)"],"metadata":{"id":"Chy4Qa9mZhqi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model"],"metadata":{"id":"lHfLR87RqCQr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"l1Jl-Hg3qCNw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Check out the tokenizer"],"metadata":{"id":"ZlYzHmiMqPiU"}},{"cell_type":"code","source":["# A bit about their tokenizer\n","print(f'Tokenizer has {tokenizer.vocab_size:,} tokens.\\nA few random tokens:\\n')\n","\n","for i in range(30):\n","  # generate a random token\n","  randtok = torch.randint(tokenizer.vocab_size,(1,))\n","  print(f'Token {randtok[0]:5} is \"{tokenizer.decode(randtok)}\"')"],"metadata":{"id":"mWre9N6hPf2G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"e7FPvccFALDU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Generate a response to some code input"],"metadata":{"id":"VIriQOWyaRmT"}},{"cell_type":"code","source":["text = 'for i in range(10):'\n","input_ids = tokenizer(text, return_tensors='pt').input_ids.to(device)\n","\n","generated_ids = model.generate(input_ids, max_length=222, temperature=1.4, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n","print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))"],"metadata":{"id":"C_maXXsEtlri"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aX9hiRx2Zhni"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import git-calc files and tokenize"],"metadata":{"id":"31vBDPouZhkl"}},{"cell_type":"code","source":["import os\n","import subprocess\n","import nbformat\n","\n","# download the repo\n","repo_url = 'https://github.com/mikexcohen/Calculus_book.git'\n","repo_dir = 'Calculus_book'\n","subprocess.run(['git','clone',repo_url,repo_dir])\n","\n","# initialize a list for all tokens\n","all_tokens = []\n","\n","\n","## find all .ipynb files\n","for root, dirs, files in os.walk(repo_dir):\n","  for file in files:\n","    if file.endswith('.ipynb'):\n","\n","      # load and process notebooks\n","      # print(f'Processing notebook: {os.path.join(root, file)}')\n","      with open(os.path.join(root, file),'r',encoding='utf-8') as f:\n","\n","        # parse the notebook structure\n","        nb_data = nbformat.read(f,as_version=4)\n","\n","        # gather all code cells into a single string\n","        code_cells = []\n","        for cell in nb_data['cells']:\n","          if cell['cell_type'] == 'code': # this cell contains code\n","            code_cells.append(cell['source']) # the actual code in this cell\n","\n","        # join code cells\n","        all_code = '\\n'.join(code_cells)\n","\n","        # tokenize and add to the list of all tokens\n","        all_tokens += tokenizer(all_code)['input_ids']\n","\n","# check the final dataset size\n","print(f'\\n\\nTraining data contains {len(all_tokens):,} tokens, of which {len(set(all_tokens)):,} are unique.')"],"metadata":{"id":"RrhJNrHqZhh8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RV80pHb3XjV1"},"execution_count":null,"outputs":[]}]}