{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyME9VQGwLWSEnxDkmaJjq2A"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 2:</h2>|<h1>Large language models<h1>|\n","|<h2>Section:</h2>|<h1>Pretrain LLMs<h1>|\n","|<h2>Lecture:</h2>|<h1><b>Weight initializations<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">udemy.com/course/dulm_x/?couponCode=202509</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"gZ_reUKGCTtS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QSHpATORsWx_"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","# vector plots\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":[],"metadata":{"id":"dRekbftisYDs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create some weights matrices\n","weights = {\n","    'norm'   : nn.Linear(50,50),\n","    'xavier' : nn.Linear(50,50),\n","    'kaiming': nn.Linear(50,50),\n","}"],"metadata":{"id":"JpjBVVA_sYAF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# default weights distributions\n","\n","plt.figure(figsize=(8,4))\n","for name,W in weights.items():\n","\n","  # get the distribution and visualize\n","  y,x = np.histogram(W.weight.detach().flatten(),bins=40)\n","  plt.plot(x[:-1],y,label=name+' (pre-init)')\n","\n","plt.legend()\n","plt.gca().set(xlabel='Weight value',ylabel='Count',title='Histograms before initialization')\n","plt.show()"],"metadata":{"id":"zpB-eRvfsX9E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# normal distribution\n","torch.nn.init.normal_(weights['norm'].weight, mean=0, std=3)\n","\n","# Xavier distribution\n","torch.nn.init.xavier_normal_(weights['xavier'].weight)\n","\n","# Kaiming distribution\n","torch.nn.init.kaiming_uniform_(weights['kaiming'].weight);"],"metadata":{"id":"d3zgYbrdsX5w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-initializations weights distributions\n","\n","plt.figure(figsize=(8,4))\n","for name,W in weights.items():\n","\n","  # get the distribution and plot it\n","  y,x = np.histogram(W.weight.detach().flatten(),bins=40)\n","  plt.plot(x[:-1],y,label=name+' (post-init)')\n","\n","plt.legend()\n","plt.gca().set(xlabel='Weight value',ylabel='Count',title='Histograms after initialization')\n","plt.show()"],"metadata":{"id":"aZccGTUMsX2c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9I3K9f-TsXgW"},"execution_count":null,"outputs":[]}]}