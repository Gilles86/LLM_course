{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyOUm/V3YFQlOQNn5w6WcGXL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 2:</h2>|<h1>Large language models<h1>|\n","|<h2>Section:</h2>|<h1>Pretrain LLMs<h1>|\n","|<h2>Lecture:</h2>|<h1><b>Create custom loss functions<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">udemy.com/course/dulm_x/?couponCode=202509</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"F1tcEQ2tCXDl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wYMflaqxicT_"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","\n","# vector plots\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":[],"metadata":{"id":"0mkBOgpTo3kp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Check the pytorch loss functions"],"metadata":{"id":"wkNfSWJyo3hz"}},{"cell_type":"code","source":["nn.NLLLoss??"],"metadata":{"id":"8OD4wEc2hoJy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QRDbhlHho6aq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create and test custom loss functions"],"metadata":{"id":"vAwo1FhchoGL"}},{"cell_type":"code","source":["# general form for a loss function (actually a class)\n","class myLoss_L1(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","  def forward(self,yHat,y):\n","\n","    # L1 loss\n","    l = torch.mean( torch.abs(yHat-y) )\n","\n","    # correlation error (just as an example possibilities)\n","    #l = 1 - torch.corrcoef(yHat,y)\n","\n","    return l\n","\n","\n","class myLoss_L2(nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","\n","  def forward(self,yHat,y):\n","\n","    # mean-squared error\n","    l = torch.mean( (yHat-y)**2 )\n","    return l"],"metadata":{"id":"7uNb3Ri0hoDB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create intances of the loss classes\n","lossfun1 = myLoss_L1()\n","lossfun2 = myLoss_L2()\n","\n","# test values\n","predicted_value = torch.tensor(2.)\n","target_value = 5\n","\n","# report\n","print(f'Model output = {predicted_value}')\n","print(f'target value = {target_value}\\n')\n","print(f'L1 loss: {lossfun1(predicted_value,target_value)}')\n","print(f'L2 loss: {lossfun2(predicted_value,target_value)}')"],"metadata":{"id":"vP0wR1EIhn_6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5icbpVVpnXii"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Demonstrate in a simple example"],"metadata":{"id":"aP_zDMpmnXfu"}},{"cell_type":"code","source":["# initialize weight value\n","w1 = torch.tensor([2.], requires_grad=True)\n","w2 = torch.tensor([2.], requires_grad=True)\n","\n","# target value\n","target = torch.tensor([3.])\n","\n","# create the optimizers\n","learningrate = .05\n","optimizer1 = torch.optim.SGD([w1],lr=learningrate)\n","optimizer2 = torch.optim.SGD([w2],lr=learningrate)\n","\n","# number of training iterations\n","numIters = 50\n","\n","# initialize results matrices\n","all_losses  = np.zeros((2,numIters))\n","all_weights = np.zeros((2,numIters+1))\n","all_weights[:,0] = w1.item()\n","\n","\n","# training loop\n","for i in range(numIters):\n","\n","  ## train weight w1\n","  optimizer1.zero_grad()\n","  loss1 = lossfun1(w1,target)\n","  loss1.backward()\n","  optimizer1.step()\n","\n","  # store the losses and updated weight value\n","  all_losses[0,i] = loss1.item()\n","  all_weights[0,i+1] = w1.item()\n","\n","\n","\n","  ## train weight w2\n","  optimizer2.zero_grad()\n","  loss2 = lossfun2(w2,target)\n","  loss2.backward()\n","  optimizer2.step()\n","\n","  # store the losses and updated weight value\n","  all_losses[1,i] = loss2.item()\n","  all_weights[1,i+1] = w2.item()\n"],"metadata":{"id":"fxee3N_Nhn9C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_,axs = plt.subplots(1,2,figsize=(12,4))\n","\n","# plot the losses\n","axs[0].plot(range(1,numIters+1),all_losses[0,:],'ko-',linewidth=.5,markerfacecolor=[.7,.7,.9],label='L1 loss')\n","axs[0].plot(range(1,numIters+1),all_losses[1,:],'ks-',linewidth=.5,markerfacecolor=[.7,.9,.7],label='L2 loss')\n","\n","# plot the weight\n","axs[1].plot(range(0,numIters+1),all_weights[0,:],'ko-',linewidth=.5,markerfacecolor=[.7,.7,.9],label='L1 loss')\n","axs[1].plot(range(0,numIters+1),all_weights[1,:],'ks-',linewidth=.5,markerfacecolor=[.7,.9,.7],label='L2 loss')\n","axs[1].axhline(target,linestyle='--',color=[.7,.7,.7],zorder=-10,label='Target')\n","\n","\n","# add legends\n","axs[0].legend()\n","axs[1].legend()\n","\n","# stylize the plots\n","axs[0].set(title='Losses',ylabel='loss',xlabel='Training epoch')\n","axs[1].set(title='Weight',ylabel='Weight value',xlabel='Training epoch')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"l0-CUYUGhn5p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"P3RXgqsrhnwS"},"execution_count":null,"outputs":[]}]}