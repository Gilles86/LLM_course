{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPxg/HO+7yGYmxiW6XJvz9U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 2:</h2>|<h1>Large language models<h1>|\n","|<h2>Section:</h2>|<h1>Build a GPT<h1>|\n","|<h2>Lecture:</h2>|<h1><b>CodeChallenge: More softmax explorations<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"pm7h4Gk76Qph"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"],"metadata":{"id":"UGFJ3W-qYBiO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ETa10iGe6YRj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 1: Repeated softmaxification"],"metadata":{"id":"P-vnViQb6YRj"}},{"cell_type":"code","source":["# create some random softmax values\n","x = np.linspace(0,1,20)\n","U = np.exp(x) / np.sum(np.exp(x))\n","\n","num_repeats = 8\n","Ustd = np.zeros(num_repeats)\n","\n","# colors for the dots\n","colors = plt.cm.turbo(np.linspace(.1,.9,num_repeats))\n","\n","# plot\n","_,axs = plt.subplots(1,2,figsize=(12,4))\n","for r in range(num_repeats):\n","\n","  # plot the pdist\n","  axs[0].plot(x,U,'o',color=colors[r],markerfacecolor=colors[r],label=f'Iteration {r+1}')\n","\n","  # get the standard deviation\n","  Ustd[r] = np.std(U)\n","\n","  # re-calculate softmax\n","  U = np.exp(U) / np.sum(np.exp(U))\n","\n","\n","# plot the variance\n","axs[1].plot(range(1,num_repeats+1),np.log(Ustd),'ks',markerfacecolor=[.9,.7,.7],markersize=10)\n","axs[1].set(xlabel='Softmax iteration',ylabel='Log standard deviation',title='Impact of softmaxing on variability')\n","\n","axs[0].legend(fontsize=8)\n","axs[0].set(xlabel='Raw data',ylabel='Softmax prob.',title='Softmaxed data')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"xQdE1Ihi6YRj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# why repeated softmax suppresses variability\n","\n","N = [4,10,100]\n","\n","# plot\n","plt.figure(figsize=(5,5))\n","\n","for n in N:\n","\n","  # the data (e.g., token logits)\n","  x = np.linspace(0,1,n)\n","\n","  # softmax the data\n","  smx = np.exp(x) / np.exp(x).sum()\n","\n","  # plot\n","  plt.plot(x,smx,'-s',linewidth=2,markerfacecolor='w',label=f'N = {n}')\n","\n","\n","# make sure the axes are the same!\n","plt.legend()\n","plt.gca().set(xlim=[-.02,1.02],ylim=[-.02,1.02],xlabel='x',ylabel='Softmax(x)')\n","plt.show()"],"metadata":{"id":"7Avp5wV5wbjM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"l_lylQYn99wa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2: Impact of range and temperature on softmax distribution"],"metadata":{"id":"YQhicrrS6YRj"}},{"cell_type":"code","source":["temps  = [ .5,1,3 ]\n","bounds = [ .4,1,5 ]\n","\n","colors = 'brk'\n","shapes = 'so^'\n","\n","_,axs = plt.subplots(2,3,figsize=(12,6))\n","\n","for bndi in range(3):\n","\n","  logits = torch.linspace(-bounds[bndi],bounds[bndi],100)\n","  logits = torch.cat((logits,torch.tensor([6])))\n","\n","  for ti in range(3):\n","\n","    # calculate softmax with this temperature\n","    T = temps[ti]\n","    sm = torch.exp(logits/T) / torch.exp(logits/T).sum()\n","\n","    # plot the same data twice (scaling later)\n","    for ii in range(2):\n","      axs[ii,bndi].plot(logits[:-1],sm[:-1],linestyle='none',markerfacecolor=colors[ti],\n","                        marker=shapes[ti],markeredgecolor=colors[ti],markersize=4,label=f'Temp = {T}')\n","      axs[ii,bndi].plot(logits[-1],sm[-1],markerfacecolor=colors[ti],\n","                        markeredgecolor=colors[ti],marker=shapes[ti],markersize=8)\n","\n","\n","# axis settings for top-row graphs to highlight the impact on smaller values\n","for a in axs[1,:]:\n","  a.set(xlim=[-bounds[-1],6.6],ylim=[-.02,1.03],xlabel='Model output (logits)',ylabel='Softmax probabilities')\n","  a.legend(loc='upper left')\n","\n","# axis settings for bottom-row graphs to show probs up to 1\n","for a in axs[0,:]:\n","  a.set(xlim=[-bounds[-1],6.6],ylim=[-.0002,sm[-2]],xlabel='Model output (logits)',ylabel='Softmax probabilities')\n","  a.legend(loc='upper left')\n","\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"nUByizf-yzvT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2qBlSyRl6YRm"},"execution_count":null,"outputs":[]}]}