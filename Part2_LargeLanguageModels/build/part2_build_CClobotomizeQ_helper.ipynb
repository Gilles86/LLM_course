{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyMHeBFz2X1W6dz0fDRxevLC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 2:</h2>|<h1>Large language models<h1>|\n","|<h2>Section:</h2>|<h1>Build a GPT<h1>|\n","|<h2>Lecture:</h2>|<h1><b>CodeChallenge HELPER: Do we really need Q?<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"TVkoFMbcakr9"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoModelForCausalLM,GPT2Tokenizer"],"metadata":{"id":"aoocnKDi-2RN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"I2-HnHoIcZR8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 1: Import GPT2 and push a copy to the GPU"],"metadata":{"id":"7ggE8IvecZPN"}},{"cell_type":"code","source":["# load SMALL pretrained GPT-2 model and tokenizer\n","gpt2_orig =  # this one won't be modified\n","gpt2      =\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"],"metadata":{"id":"bHKfbxSx-B5Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# use GPU\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"metadata":{"id":"ynnauiqZcdIT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# push the model to the GPU\n"],"metadata":{"id":"zYhueTdXc8nm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# generate some input\n","x = torch.tensor(tokenizer.encode('Hello, how are you today?'))\n","\n","# note: make sure 'x' has batch as the first dimension!"],"metadata":{"id":"KTNsXfyIDvaa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### on the CPU\n","torch.manual_seed(42) # seed the rng\n","out = gpt2_orig.generate()\n","print(tokenizer.decode(out[0].tolist()))"],"metadata":{"id":"cdP8pZ22-2GR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### on the GPU\n","torch.manual_seed(42) # seed the rng\n","\n","print(tokenizer.decode(out[0].tolist()))\n","\n","# Note: some differences between CPU and GPU are expected due to differential rounding/precision errors\n","#       but the rng seed is different on the GPU and CPU"],"metadata":{"id":"Im6kOumzdG23"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"f0tdpZWnbFwX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# FYI, use this code to copy the original parameters onto a modified model\n","gpt2.load_state_dict( gpt2_orig.state_dict() )"],"metadata":{"id":"KgK7OBTrgKSZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"etBFgmhvgKNW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2: Replace one Q matrix"],"metadata":{"id":"zRv22iGHgKKN"}},{"cell_type":"code","source":["# size of Q matrix\n","n_emb = gpt2.transformer.wte.weight.shape[1]\n","sizeOfQ = gpt2.transformer.h[0].attn.c_attn.weight[:,:n_emb].shape\n","sizeOfQ"],"metadata":{"id":"H-dH2GWcbFtZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get the matrix\n","q =\n","\n","# create noise with matching statistics\n","mean = q.mean()\n","std  =\n","noise =\n","\n","# replace the values in q\n","# gpt2 dot something dot etc = noise\n","\n","#q.data.copy_(noise); # this also works..."],"metadata":{"id":"Cij8RAfXjkf5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# confirm that the weights really have changed...\n","print(gpt2.transformer.h[0].attn.c_attn.weight[:10,1])\n","print(gpt2_orig.transformer.h[0].attn.c_attn.weight[:10,1])"],"metadata":{"id":"n3ng8mcHjkdi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### re-run on the GPU\n","torch.manual_seed(42) # seed the rng\n","\n","print(tokenizer.decode(out[0].tolist()))"],"metadata":{"id":"6YYKTAWcK9nc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bsQEgHP2jkXW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 3: Successively lobotomize the model :("],"metadata":{"id":"mxp9mHpcjkUg"}},{"cell_type":"code","source":["# reset the model to its original parameters\n","gpt2.load_state_dict( gpt2_orig.state_dict() )"],"metadata":{"id":"tUZarKPLLnMl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model output pre-changes\n","print('** Using all original Q values:')\n","x = torch.tensor(tokenizer.encode('I went to the market to buy')).unsqueeze(0)\n","\n","print(tokenizer.decode(out[0].tolist()))\n","\n","\n","# loop over all transformer heads, replace Q, and give the same input\n","for hidx in range():\n","\n","  print(f'\\n\\n** Now replacing Q{hidx} with noise:')\n","\n","  # get the matrix\n","  q =\n","\n","  # create noise with matching statistics\n","\n","  noise =\n","\n","  # replace the values in q\n","\n","\n","  # generate the output and print\n",""],"metadata":{"id":"PD-WWImeaxgU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tjrXzUhCaxMm"},"execution_count":null,"outputs":[]}]}