{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPtbZ2tX/RmyqEaiFxsmBjq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 2:</h2>|<h1>Large language models<h1>|\n","|<h2>Section:</h2>|<h1>Build a GPT<h1>|\n","|<h2>Lecture:</h2>|<h1><b>Inspecting OpenAI's GPT2<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"mc4CQP5L-HGR"}},{"cell_type":"code","source":["import torch\n","from transformers import AutoModelForCausalLM,GPT2Tokenizer\n","\n","!pip install torchinfo # not installed by default in colab\n","from torchinfo import summary"],"metadata":{"id":"aoocnKDi-2RN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load SMALL pretrained GPT2 model and tokenizer\n","gpt2 = AutoModelForCausalLM.from_pretrained('gpt2')\n","\n","# import larger GPT2 models\n","# gpt2med   = AutoModelForCausalLM.from_pretrained('gpt2-medium')\n","# gpt2large = AutoModelForCausalLM.from_pretrained('gpt2-large')\n","# gpt2xl    = AutoModelForCausalLM.from_pretrained('gpt2-xl')\n","\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"],"metadata":{"id":"bHKfbxSx-B5Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# see what's in the model\n","gpt2"],"metadata":{"id":"gHOv-Gpp-2Oi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check out one of the attention heads\n","gpt2.transformer.h[3].attn"],"metadata":{"id":"qZraJK_C-2Lb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print some parameter names\n","for name,mat in gpt2.named_parameters():\n","  print(f'{name:>40} is of size: {mat.shape}')"],"metadata":{"id":"lO42AOum-2Am"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# some additional useful info\n","gpt2.config"],"metadata":{"id":"8rOqGxgogoHH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"imFH74sg-2I6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Summary of model and parameters"],"metadata":{"id":"HRN5w_R8wdGh"}},{"cell_type":"code","source":["# need some data to pass through\n","x = torch.tensor(tokenizer.encode('Hello, how are you today?')).unsqueeze(0)\n","\n","summary(gpt2, input_data=x, col_names=['input_size','output_size','num_params'])"],"metadata":{"id":"Sc5MAbeNFB5P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KTNsXfyIDvaa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Generate some text"],"metadata":{"id":"48b2gcGPwfxE"}},{"cell_type":"code","source":["# torch.manual_seed(42) # seed the rng\n","out = gpt2.generate(x,temperature=1.,do_sample=True,max_length=100,\n","                    pad_token_id=tokenizer.eos_token_id)\n","print(tokenizer.decode(out[0].tolist()))"],"metadata":{"id":"cdP8pZ22-2GR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rG2YjRYiDvX_"},"execution_count":null,"outputs":[]}]}