{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1oDaogKfz9gQYSAyQT-uF9xRI3EdrtokO","timestamp":1742125747860}],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 2:</h2>|<h1>Large language models<h1>|\n","|<h2>Section:</h2>|<h1>Build a GPT<h1>|\n","|<h2>Lecture:</h2>|<h1><b>Softmax (and temperature): math, numpy, and pytorch<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"_SQ6Gob_SSQV"}},{"cell_type":"code","metadata":{"id":"2TD8IyfBGXiY"},"source":["# import libraries\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","\n","# vector plots\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KDIqnFKcykSM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Implementation in numpy"],"metadata":{"id":"MhEd0v45ykPD"}},{"cell_type":"code","metadata":{"id":"vmjUxlEqGbDu"},"source":["# the list of numbers\n","z = [1,2,3]\n","\n","# compute the softmax result\n","num = np.exp(z)\n","den = np.sum( np.exp(z) )\n","sigma = num / den\n","\n","print(sigma)\n","print(np.sum(sigma))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sOug_tPzHY1y"},"source":["# repeat with some random integers\n","z = np.random.randint(-5,high=15,size=25)\n","print(z)\n","\n","# compute the softmax result\n","num = np.exp(z)\n","den = np.sum( num )\n","sigma = num / den\n","\n","# compare\n","plt.plot(z,sigma,'ko')\n","plt.xlabel('Original number (z)')\n","plt.ylabel('Softmaxified $\\sigma$')\n","# plt.yscale('log')\n","plt.title('$\\sum\\sigma$ = %g' %np.sum(sigma))\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"g8S2xB5By6y6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jDIYW2bKHxXB"},"source":["# Using pytorch"]},{"cell_type":"code","source":["zTorch = torch.tensor(z,dtype=torch.float64)\n","\n","# using a function\n","F.softmax(zTorch)#,dim=-1)"],"metadata":{"id":"nMluoPkty8LC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6Fr3DDlJzpCx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Adding \"temperature\""],"metadata":{"id":"gEyoz--W4L5A"}},{"cell_type":"code","source":["# list of temperatures to use (T = 1/beta)\n","temperatures = [ 1, 2, 10 ]\n","\n","rawscores = torch.linspace(-5,15,35)\n","shapes = 'osd'\n","\n","_,axs = plt.subplots(1,2,figsize=(12,4))\n","for temp,s in zip(temperatures,shapes):\n","\n","  # scale the scores by temperature\n","  heatedScores = rawscores / temp\n","\n","  # and plot\n","  axs[0].plot(rawscores,F.softmax(heatedScores,dim=0),f'{s}-',alpha=.7,label=r'$T=%g$'%temp)\n","  axs[1].plot(rawscores,F.log_softmax(heatedScores,dim=0),f'{s}-',alpha=.7,label=r'$T=%g$'%temp)\n","\n","\n","axs[0].legend()\n","axs[0].set(xlabel='Raw scores', ylabel='Probability',title='Regular softmax')\n","axs[1].legend()\n","axs[1].set(xlabel='Raw scores', ylabel='Log probability',title='Log-softmax')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"YPykeYNp4ODj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Rx32oSaJ4Lto"},"execution_count":null,"outputs":[]}]}