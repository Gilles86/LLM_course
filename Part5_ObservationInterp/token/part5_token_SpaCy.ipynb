{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyMi8KCofpgSbkMEvHMYaG1e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 5:</h2>|<h1>Observation (non-causal) mech interp<h1>|\n","|<h2>Section:</h2>|<h1>Investigating token embeddings<h1>|\n","|<h2>Lecture:</h2>|<h1><b>Parts of speech with SpaCy library<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">udemy.com/course/dulm_x/?couponCode=202509</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"oyiLKMV3dROe"}},{"cell_type":"code","source":["# https://spacy.io/\n","import spacy\n","\n","nlp = spacy.load('en_core_web_sm')\n","txt = 'This is a very happy sentence that I will use to explore the spacy library.'\n","\n","dir( nlp(txt) )"],"metadata":{"id":"kiiXIPSy79rJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"adrFfqUt3l2v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# split the text into words and print the part of speech (pos)\n","for word in txt.split():\n","  n = nlp(word)\n","  print(f'\"{word}\" is a {n[0].pos_}')"],"metadata":{"id":"VhELLN1q4A3F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# more accurate to tokenize the sentence\n","for token in nlp(txt):\n","  print(f'\"{token.text}\" is a {token.pos_}')"],"metadata":{"id":"PUycND5jnAZG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yw015XbD79l_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Part of speech from tokenized text"],"metadata":{"id":"gnaVHoQB7dZx"}},{"cell_type":"code","source":["# import gpt2 tokenizer\n","from transformers import AutoModelForCausalLM, GPT2Tokenizer\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"],"metadata":{"id":"Ezu7JY1820iw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tokenize the text\n","tokens = tokenizer.encode(txt)\n","\n","for t in tokens:\n","  toktxt = tokenizer.decode([t])\n","  print(f'Token \"{toktxt}\" is a {nlp(toktxt)[0].pos_}')"],"metadata":{"id":"tUx_XtiQ20gG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# try again...\n","for t in tokens:\n","  toktxt = tokenizer.decode([t]).strip()\n","  print(f'Token \"{toktxt}\" is a {nlp(toktxt)[0].pos_}')"],"metadata":{"id":"W9XgpeWm20dh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yEwQS-f_AgPr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Try with text generated by GPT2"],"metadata":{"id":"x-tniqjTAgMs"}},{"cell_type":"code","source":["model = AutoModelForCausalLM.from_pretrained('gpt2')\n","model.eval();"],"metadata":{"id":"q6BXjOOtAioR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# generate some text\n","newtoks = model.generate(tokenizer.encode('I think the world could be better if',return_tensors='pt'),max_length=400,do_sample=True)\n","print('\\n\\n',tokenizer.decode(newtoks[0]))"],"metadata":{"id":"5tYHqZFO79g1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yVGTL0T679eL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initialize counters\n","isnoun = 0\n","isverb = 0\n","\n","# loop over the tokens\n","for t in newtoks[0]:\n","\n","  # get the text and part of speech\n","  txt = tokenizer.decode(t).replace(' ','') # instead of strip()\n","  pos = nlp(txt)[0].pos_\n","\n","  # increment counters and print\n","  if pos=='NOUN':\n","    isnoun += 1\n","    print(f'{txt:>12} -> {pos}')\n","  elif pos=='VERB':\n","    print(f'{txt:>12} -> {pos}')\n","    isverb += 1"],"metadata":{"id":"mHXMy0hhDm4s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# check the counts\n","isnoun,isverb"],"metadata":{"id":"CJV2UJh9Dxj0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Tkn-gUNNBPBL"},"execution_count":null,"outputs":[]}]}