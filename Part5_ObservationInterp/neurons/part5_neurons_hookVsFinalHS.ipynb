{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNIvnHplm4VRWXDYajIICgb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Import a model"],"metadata":{"id":"g-xEkOpU8XRZ"}},{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 5:</h2>|<h1>Observation (non-causal) mech interp<h1>|\n","|<h2>Section:</h2>|<h1>Investigating neurons and dimensions<h1>|\n","|<h2>Lecture:</h2>|<h1><b>Clarification of final hidden_states output<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"_gPy1MwYgrhi"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"6NPsr5B0nv52"},"outputs":[],"source":["from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","import torch\n","\n","model = GPT2LMHeadModel.from_pretrained('gpt2')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","\n","n_layers = model.config.n_layer\n","model.eval()"]},{"cell_type":"code","source":[],"metadata":{"id":"NqZsbWmnyR5v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Implant a hook"],"metadata":{"id":"yzQ825D9unPg"}},{"cell_type":"code","source":["blockOutput = {'data':4.}\n","\n","def hook(module, input, output):\n","  blockOutput['data'] = output[0]\n","\n","model.transformer.h[n_layers-1].register_forward_hook(hook)"],"metadata":{"id":"IEerqWdRZJXq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"w2Xf2Ohg85on"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Forward pass"],"metadata":{"id":"sSbMdJYa9YgC"}},{"cell_type":"code","source":["with torch.no_grad():\n","  out = model(tokenizer.encode('hello',return_tensors='pt'),\n","              output_hidden_states=True\n","              )"],"metadata":{"id":"vgUVkKNounSL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Hooked data are of size',blockOutput['data'].shape)\n","print('Final hidden_state is of size',out.hidden_states[-1].shape)"],"metadata":{"id":"_jVNYwS59Z8N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"j4LT_Bz4-CBr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Compare hidden_state to pre- and post-LN"],"metadata":{"id":"8_zSOiF49ajY"}},{"cell_type":"code","source":["# pre-LN\n","blockOutput['data'][0,-1,:] - out.hidden_states[-1][0,-1,:]"],"metadata":{"id":"gpAaM2Pp9e-O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# post-LN\n","postLayerNorm = model.transformer.ln_f( blockOutput['data'] )\n","postLayerNorm[0,-1,:] - out.hidden_states[-1][0,-1,:]"],"metadata":{"id":"13oz8DN1yhXE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Gh2vNn7785i2"},"execution_count":null,"outputs":[]}]}