{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPjK2OX714O3scL6PbBncCN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 5:</h2>|<h1>Observation (non-causal) mech interp<h1>|\n","|<h2>Section:</h2>|<h1>Identifying latent factors<h1>|\n","|<h2>Lecture:</h2>|<h1><b>Generalized eigendecomposition separates \"him\" from \"her\" in MLP<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">udemy.com/course/dulm_x/?couponCode=202509</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"dVdgcMR4IljT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RuKeB769HOkN"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# for the generalized eigendecomposition\n","import scipy.linalg\n","\n","import torch\n","from transformers import GPT2Model, GPT2Tokenizer\n","\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":["# import model and tokenizer\n","model = GPT2Model.from_pretrained('gpt2')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"],"metadata":{"id":"8LjWkQSxlHJR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jqTjLQ3NrqHj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hook the MLP"],"metadata":{"id":"YI_EkZGRHaXr"}},{"cell_type":"code","source":["# hook the MLP activations\n","activations = {}\n","\n","def mlp_hook(module, input, output):\n","  activations['mlp'] = output.detach().numpy()\n","\n","# pick the middle layer\n","layer2hook = model.config.n_layer//2\n","handle = model.h[layer2hook].mlp.c_fc.register_forward_hook(mlp_hook)"],"metadata":{"id":"3kRaud4VHY6T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"E1IwRC6lI-oM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# generated by Claude.ai\n","sentences = [\n","    \"I saw him at the market.\",\n","    \"She gave him the book.\",\n","    \"They asked him for advice.\",\n","    \"We invited him to dinner.\",\n","    \"The dog followed him home.\",\n","    \"They asked him to join.\",\n","    \"He saw him at the park yesterday.\",\n","    \"Did you give him your address?\",\n","    \"I haven't seen him in ages.\",\n","    \"I told him the truth.\",\n","    \"They congratulated him on his success.\",\n","    \"She recognized him immediately.\",\n","    \"The teacher praised him for his work.\",\n","    \"I met him last summer.\",\n","    \"The child hugged him tightly.\",\n","    \"They warned him about the danger.\",\n","    \"She drove him to the airport.\",\n","    \"We waited for him for hours.\",\n","    \"The cat scratched him accidentally.\",\n","    \"They surprised him with a gift.\",\n","    \"She called him on the phone.\",\n","    \"The jury found him not guilty.\",\n","    \"I remembered him from school.\",\n","    \"They elected him as president.\",\n","    \"She forgave him for his mistake.\",\n","    \"The police questioned him yesterday.\",\n","    \"I helped him with his homework.\",\n","    \"They spotted him in the crowd.\",\n","    \"She visited him in the hospital.\",\n","    \"The manager promoted him last week.\",\n","    \"I trusted him completely.\",\n","    \"They respected him for his honesty.\",\n","    \"She taught him how to swim.\",\n","    \"The bird attacked him suddenly.\",\n","    \"I greeted him warmly.\",\n","    \"They supported him through difficult times.\",\n","    \"She ignored him at the party.\",\n","    \"The judge sentenced him to community service.\",\n","    \"I photographed him during the event.\",\n","    \"They believed him despite the evidence.\",\n","    \"She surprised him on his birthday.\",\n","    \"The guard stopped him at the entrance.\",\n","    \"I missed him terribly.\",\n","    \"They watched him leave the building.\",\n","    \"She accompanied him to the concert.\",\n","    \"The crowd cheered him enthusiastically.\",\n","    \"I described him to the police.\",\n","    \"They thanked him for his help.\",\n","    \"She admired him for his courage.\",\n","    \"The committee nominated him for the award.\",\n","    \"I married him last spring.\",\n","    \"They informed him about the changes.\",\n","    \"She introduced him to the parents.\",\n","    \"The author based the character on him.\",\n","\n","## same sentences but with \"her\"\n","\n","    \"I saw her at the market.\",\n","    \"She gave her the book.\",\n","    \"They asked her for advice.\",\n","    \"We invited her to dinner.\",\n","    \"The dog followed her home.\",\n","    \"They asked her to join.\",\n","    \"He saw her at the park yesterday.\",\n","    \"Did you give her your address?\",\n","    \"I haven't seen her in ages.\",\n","    \"I told her the truth.\",\n","    \"They congratulated her on his success.\",\n","    \"She recognized her immediately.\",\n","    \"The teacher praised her for his work.\",\n","    \"I met her last summer.\",\n","    \"The child hugged her tightly.\",\n","    \"They warned her about the danger.\",\n","    \"She drove her to the airport.\",\n","    \"We waited for her for hours.\",\n","    \"The cat scratched her accidentally.\",\n","    \"They surprised her with a gift.\",\n","    \"She called her on the phone.\",\n","    \"The jury found her not guilty.\",\n","    \"I remembered her from school.\",\n","    \"They elected her as president.\",\n","    \"She forgave her for his mistake.\",\n","    \"The police questioned her yesterday.\",\n","    \"I helped her with his homework.\",\n","    \"They spotted her in the crowd.\",\n","    \"She visited her in the hospital.\",\n","    \"The manager promoted her last week.\",\n","    \"I trusted her completely.\",\n","    \"They respected her for his honesty.\",\n","    \"She taught her how to swim.\",\n","    \"The bird attacked her suddenly.\",\n","    \"I greeted her warmly.\",\n","    \"They supported her through difficult times.\",\n","    \"She ignored her at the party.\",\n","    \"The judge sentenced her to community service.\",\n","    \"I photographed her during the event.\",\n","    \"They believed her despite the evidence.\",\n","    \"She surprised her on his birthday.\",\n","    \"The guard stopped her at the entrance.\",\n","    \"I missed her terribly.\",\n","    \"They watched her leave the building.\",\n","    \"She accompanied her to the concert.\",\n","    \"The crowd cheered her enthusiastically.\",\n","    \"I described her to the police.\",\n","    \"They thanked her for his help.\",\n","    \"She admired her for his courage.\",\n","    \"The committee nominated her for the award.\",\n","    \"I married her last spring.\",\n","    \"They informed her about the changes.\",\n","    \"She introduced her to the parents.\",\n","    \"The author based the character on her.\"\n","]\n","\n","# indices of him/her sentences\n","him_sentences = np.arange(len(sentences)//2)\n","her_sentences = np.arange(len(sentences)//2,len(sentences))\n","\n","print(f'There are {len(sentences)} sentences.')"],"metadata":{"id":"oqdAP54II-ht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# identify the target token\n","target_token_him = tokenizer.encode(' him')\n","target_token_her = tokenizer.encode(' her')\n","print(f'The target token indices are {target_token_him} and {target_token_her}\\n')\n","\n","# need to specify a padding token\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","# tokenize\n","tokens = tokenizer(sentences,padding=True,return_tensors='pt')\n","seqlength = len(tokens['input_ids'][0])\n","\n","# example\n","print(tokens['input_ids'][10])\n","print(tokens['attention_mask'][10])"],"metadata":{"id":"fYPkVigeOv47"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JGs7C-adPhDN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Get activations for all \"him\" and \"her\" targets"],"metadata":{"id":"y-Qvc-PDmPU3"}},{"cell_type":"code","source":["with torch.no_grad():\n","  model(**tokens)"],"metadata":{"id":"YAMzPriHL7SD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nhidden = activations['mlp'].shape[-1]\n","print(f'There are {nhidden} hidden units.')\n","activations['mlp'].shape"],"metadata":{"id":"BD0Wb8YdMBqZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get target activations\n","acts = np.zeros((len(sentences),nhidden))\n","\n","for senti in range(len(sentences)):\n","\n","  # find the index of either of the target tokens\n","  targBool = (tokens['input_ids'][senti].numpy()==target_token_him) | (tokens['input_ids'][senti].numpy()==target_token_her)\n","  targidx = np.where(targBool)[0]\n","\n","  # then get the activation\n","  acts[senti,:] = activations['mlp'][senti,targidx,:]\n","\n","acts.shape"],"metadata":{"id":"_4-qe3_QlHTx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TOqCVnGDm7Kc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Some data visualizations"],"metadata":{"id":"fGB8spt_m7FK"}},{"cell_type":"code","source":["plt.figure(figsize=(12,5))\n","plt.imshow(acts,aspect='auto',vmin=-2,vmax=2)\n","plt.gca().set(xlabel='MLP hidden dimension (\"neurons\")',ylabel='Sentence',title='MLP activations for \"him\" and \"her\"')\n","plt.colorbar(pad=.02)\n","plt.show()"],"metadata":{"id":"Cnnkq42tlHRV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# covariance matrices\n","himcov = np.cov(acts[him_sentences,:].T)\n","hercov = np.cov(acts[her_sentences,:].T)\n","\n","_,axs = plt.subplots(1,3,figsize=(12,5))\n","axs[0].imshow(himcov[::10,::10],extent=[0,nhidden,nhidden,0],vmin=-.1,vmax=.1)\n","axs[0].set(title='Covariance matrix for \"him\"',xlabel='MLP hidden unit',ylabel='MLP hidden unit')\n","\n","axs[1].imshow(hercov[::10,::10],extent=[0,nhidden,nhidden,0],vmin=-.1,vmax=.1)\n","axs[1].set(title='Covariance matrix for \"her\"',xlabel='MLP hidden unit',ylabel='MLP hidden unit')\n","\n","axs[2].imshow(himcov[::10,::10]-hercov[::10,::10],extent=[0,nhidden,nhidden,0],vmin=-.1,vmax=.1)\n","axs[2].set(title='Difference of the matrices',xlabel='MLP hidden unit',ylabel='MLP hidden unit')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"w2vLc0QFlHO_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jArx532wlHMb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Try a GED on the full matrices..."],"metadata":{"id":"-oFgMAmFo3Zl"}},{"cell_type":"code","source":["# evals,evecs = scipy.linalg.eigh(himcov,hercov)"],"metadata":{"id":"gXAlpJ1Do3W2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qbFTNtJNrcOo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Two-stage (PCA->GED)"],"metadata":{"id":"vfwDTgjWrcLq"}},{"cell_type":"code","source":["# PCA of the average covariance\n","d,V = scipy.linalg.eigh( (himcov+hercov)/2 )\n","\n","# sort the values and vectors\n","idx = d.argsort()[::-1]\n","d = d[idx]\n","V = V[:,idx] # sort the columns, not the rows!"],"metadata":{"id":"XdNJjcUrrgwR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# transform the eigenvalues to cumulative % variance explained\n","varExplained = d*100/np.sum(d)\n","cumVarExplained = np.cumsum(varExplained)\n","\n","# how many components to explain 99% of the variability?\n","numComps2keep = np.where(cumVarExplained>99)[0][0]\n","\n","\n","# and visualize\n","_,axs = plt.subplots(1,2,figsize=(11,4))\n","axs[0].plot(varExplained,'ko-',markerfacecolor=[.9,.7,.7])\n","axs[0].axvline(x=numComps2keep,color='k',linestyle='--')\n","axs[0].set(xlim=[-1,numComps2keep+10],xlabel='PC (sorted)',ylabel='Variance explained (%)',title='PCA of covariance average')\n","\n","axs[1].plot(cumVarExplained,'ko-',markerfacecolor=[.9,.7,.9])\n","axs[1].axvline(x=numComps2keep,color='k',linestyle='--')\n","axs[1].set(xlim=[-1,numComps2keep+10],xlabel='PC (sorted)',ylabel='Cumulative variance explained (%)',\n","           title=f'Cumulative variance explained (99% after {numComps2keep} components)')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"rVnV8Pfvrv5o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# project down to numComps2keep dimensions\n","acts_lowD = acts @ V[:,:numComps2keep]\n","acts_lowD.shape"],"metadata":{"id":"af2ROFWxo3UH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# covariance matrices (low-D this time)\n","himLowDcov = np.cov(acts_lowD[him_sentences,:].T)\n","herLowDcov = np.cov(acts_lowD[her_sentences,:].T)\n","\n","_,axs = plt.subplots(1,3,figsize=(12,5))\n","axs[0].imshow(himLowDcov,vmin=-1,vmax=1)\n","axs[0].set(title='Covariance matrix for \"him\"',xlabel='PC dimension',ylabel='PC dimension')\n","\n","axs[1].imshow(herLowDcov,vmin=-1,vmax=1)\n","axs[1].set(title='Covariance matrix for \"her\"',xlabel='PC dimension',ylabel='PC dimension')\n","\n","axs[2].imshow(himLowDcov-herLowDcov,vmin=-1,vmax=1)\n","axs[2].set(title='Difference of the matrices',xlabel='PC dimension',ylabel='PC dimension')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"tj1wwOTaqnK-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# shrinkage regularization\n","\n","# regularization amount\n","regu_gam = .01\n","\n","himLowDcovS = (1-regu_gam)*himLowDcov + regu_gam*np.mean(np.linalg.eig(himLowDcov)[0])*np.eye(numComps2keep)\n","herLowDcovS = (1-regu_gam)*herLowDcov + regu_gam*np.mean(np.linalg.eig(herLowDcov)[0])*np.eye(numComps2keep)\n","\n","# these should be real-valued matrices, but precision errors can propogate complex numbers with 0j\n","himLowDcovS = himLowDcovS.astype(np.float64)\n","herLowDcovS = herLowDcovS.astype(np.float64)\n","\n","\n","# examine the impact\n","print(f'Ranks of original matrices (size: {himLowDcov.shape})')\n","print(f'\"him\": {np.linalg.matrix_rank(himLowDcov)}, \"her\": {np.linalg.matrix_rank(herLowDcov)}\\n')\n","\n","print(f'Ranks of regularized matrices  (size: {himLowDcovS.shape}):')\n","print(f'\"him\": {np.linalg.matrix_rank(himLowDcovS)}, \"her\": {np.linalg.matrix_rank(herLowDcovS)}\\n\\n\\n')"],"metadata":{"id":"45UFx0rjwM3K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oQuR67p_OWGM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# now for the GED\n","\n","# HIM>HER: eig and sort\n","evalsHim,evecsHim = scipy.linalg.eigh(himLowDcov,herLowDcovS)\n","idx = evalsHim.argsort()[::-1]\n","evalsHim = evalsHim[idx]\n","evecsHim = evecsHim[:,idx] # sort the columns, not the rows!\n","\n","# HER>HIM\n","evalsHer,evecsHer = scipy.linalg.eigh(herLowDcov,himLowDcovS)\n","idx = evalsHer.argsort()[::-1]\n","evalsHer = evalsHer[idx]\n","evecsHer = evecsHer[:,idx] # sort the columns, not the rows!\n","\n","\n","# plotting\n","plt.figure(figsize=(7,3))\n","plt.plot(evalsHim/evalsHim.max(),'ko-',markerfacecolor=[.9,.7,.7],label='him > her')\n","plt.plot(np.arange(numComps2keep)+.2,evalsHer/evalsHer.max(),'ks-',markerfacecolor=[.7,.9,.7],label='her > him')\n","plt.legend()\n","plt.gca().set(xlim=[-1,21],xlabel='GED component (sorted)',ylabel='Eigenvalue (max-norm)',\n","              xticks=range(0,20,2),title='GED eigenspectra')\n","plt.show()"],"metadata":{"id":"TysOUVgkKd32"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# project the data onto the top GED vectors\n","ged_proj_him = acts_lowD @ evecsHim[:,0]\n","ged_proj_her = acts_lowD @ evecsHer[:,0]\n","\n","# visualize the token activations\n","_,axs = plt.subplots(1,2,figsize=(10,3))\n","axs[0].plot(him_sentences,ged_proj_him[him_sentences],'ko',markerfacecolor=[.9,.7,.7],label='him')\n","axs[0].plot(her_sentences,ged_proj_him[her_sentences],'ks',markerfacecolor=[.7,.9,.7],label='her')\n","axs[0].set(xlim=[-1,len(sentences)+2],xlabel='Sentence',ylabel='Activation',title='GED of him > her')\n","axs[0].legend()\n","\n","axs[1].plot(him_sentences,ged_proj_her[him_sentences],'ko',markerfacecolor=[.9,.7,.7],label='him')\n","axs[1].plot(her_sentences,ged_proj_her[her_sentences],'ks',markerfacecolor=[.7,.9,.7],label='her')\n","axs[1].set(xlim=[-1,len(sentences)+2],xlabel='Sentence',ylabel='Activation',title='GED of her > him')\n","axs[1].legend()\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"7oyHrp_QwIa8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get the patterns by filtering the covariance matrix\n","#  (pushed through the eigenvectors into MLP space)\n","mlpVect_him = V[:,:numComps2keep] @ himLowDcovS @ evecsHim[:,0]\n","mlpVect_her = V[:,:numComps2keep] @ herLowDcovS @ evecsHer[:,0]\n","\n","plt.figure(figsize=(5,5))\n","plt.plot(mlpVect_him,mlpVect_her,'k.',markerfacecolor=[.9,.9,.7,.4],markersize=7)\n","plt.gca().set(xlabel='\"him\" axis',ylabel='\"her\" axis',\n","              title=f'MLP pattern (r = {np.corrcoef(mlpVect_him,mlpVect_her)[0,1]:.2f})')\n","plt.show()"],"metadata":{"id":"kHSLvAqvwIYI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"e_o4g-quwIVY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Random permutation to explore the statistical validity"],"metadata":{"id":"Qtcii-2HE18a"}},{"cell_type":"code","source":["# randomize the sentence order to create shuffled (fake) sentence labels\n","perm_labels = np.random.permutation(len(sentences))\n","\n","\n","# permuted covariance matrices\n","himProjcovP = np.cov(acts_lowD[perm_labels[:len(sentences)//2],:].T)\n","herProjcovP = np.cov(acts_lowD[perm_labels[len(sentences)//2:],:].T)\n","S = (1-regu_gam)*himProjcovP + regu_gam*np.mean(np.linalg.eig(himProjcovP)[0])*np.eye(numComps2keep)\n","R = (1-regu_gam)*herProjcovP + regu_gam*np.mean(np.linalg.eig(herProjcovP)[0])*np.eye(numComps2keep)\n","\n","# eig and sort\n","evalsP,evecsP = scipy.linalg.eigh(S,R)\n","idx = evalsP.argsort()[::-1]\n","evalsP = evalsP[idx]\n","evecsP = evecsP[:,idx] # sort the columns, not the rows!\n","\n","# project the data onto the top GED vector\n","ged_proj_himP = acts_lowD @ evecsP[:,0]\n","\n","\n","# plotting\n","_,axs = plt.subplots(1,2,figsize=(12,3.5))\n","\n","axs[0].plot(evalsP,'ko-',markerfacecolor=[.9,.7,.7])\n","axs[0].set(xlim=[-1,21],xlabel='GED component (sorted)',ylabel='Eigenvalue',title='Random permutation GED component')\n","\n","# visualize the token activations\n","axs[1].plot(him_sentences,ged_proj_himP[him_sentences],'ko',markerfacecolor=[.9,.7,.7],label='him')\n","axs[1].plot(her_sentences,ged_proj_himP[her_sentences],'ks',markerfacecolor=[.7,.9,.7],label='her')\n","axs[1].set(xlim=[-1,len(sentences)+2],xlabel='Sentence',ylabel='Activation',title='GED of him > her')\n","axs[1].legend()\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"817MfNTsF_Yl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aEqoT0q0mi4X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Per-token activations in HIM and HER components"],"metadata":{"id":"16HZoRCWmiyy"}},{"cell_type":"code","source":["# pick a sentence index between 0 and 53\n","sidx = 2\n","\n","# get the activations for all neurons from this sentence\n","acts4him = activations['mlp'][sidx,:,:]\n","acts4her = activations['mlp'][sidx+54,:,:]\n","\n","# project onto original GED vectors (via PCA projection)\n","loD_projs_him_HimGED = acts4him @ V[:,:numComps2keep] @ evecsHim[:,0]\n","loD_projs_her_HimGED = acts4her @ V[:,:numComps2keep] @ evecsHim[:,0]\n","\n","loD_projs_him_HerGED = acts4him @ V[:,:numComps2keep] @ evecsHer[:,0]\n","loD_projs_her_HerGED = acts4her @ V[:,:numComps2keep] @ evecsHer[:,0]\n","\n","\n","\n","_,axs = plt.subplots(1,2,figsize=(12,3))\n","axs[0].plot(np.arange(seqlength)-.1,loD_projs_him_HimGED,'ko',label='him sentence')\n","axs[0].plot(np.arange(seqlength)+.1,loD_projs_her_HimGED,'rs',label='her sentence')\n","for i in range(seqlength):\n","  axs[0].plot([i-.1,i+.1],[loD_projs_him_HimGED[i],loD_projs_her_HimGED[i]],'k',zorder=-3)\n","\n","axs[0].legend()\n","axs[0].set(xticks=range(8),xticklabels=[tokenizer.decode(t) for t in tokens['input_ids'][sidx]],\n","           title='GED projections for HIM GED')\n","\n","\n","axs[1].plot(np.arange(seqlength)-.1,loD_projs_him_HerGED,'ko',label='him sentence')\n","axs[1].plot(np.arange(seqlength)+.1,loD_projs_her_HerGED,'rs',label='her sentence')\n","for i in range(seqlength):\n","  axs[1].plot([i-.1,i+.1],[loD_projs_him_HerGED[i],loD_projs_her_HerGED[i]],'k',zorder=-3)\n","\n","axs[1].legend()\n","axs[1].set(xticks=range(8),xticklabels=[tokenizer.decode(t) for t in tokens['input_ids'][sidx]],\n","           title='GED projections for HER GED')\n","\n","plt.suptitle('Token-level activations in GED filters',fontweight='bold')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"HMlTPuMOmis8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gfvHe47cmTWl"},"execution_count":null,"outputs":[]}]}