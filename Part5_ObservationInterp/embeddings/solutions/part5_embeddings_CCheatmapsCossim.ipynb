{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":["kIbYVQIk3zUh"],"authorship_tag":"ABX9TyM7yeYXT150I/Iwpjm5/XGq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 5:</h2>|<h1>Observation (non-causal) mech interp<h1>|\n","|<h2>Section:</h2>|<h1>Investigating token embeddings<h1>|\n","|<h2>Lecture:</h2>|<h1><b>CodeChallenge: Coloring cosine similarity<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"LLbhbUm6tEra"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTp8j3TJAqvB"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":["from transformers import BertTokenizer, BertModel\n","\n","# load BERT tokenizer and model\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased')\n","\n","embeddings = model.embeddings.word_embeddings.weight.detach().numpy()"],"metadata":{"id":"IlLTVTpTBS75"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# code to calculate the width of a letter\n","fig,ax = plt.subplots(figsize=(10,2))\n","\n","# draw a text object\n","temp_text = ax.text(0,0,'n',fontsize=12,fontfamily='monospace')\n","\n","# Get its bounding box in display coordinates\n","bbox = temp_text.get_window_extent(renderer=fig.canvas.get_renderer())\n","\n","# convert from display to axis coordinates\n","inv = ax.transAxes.inverted()\n","bbox_axes = inv.transform([[bbox.x0,bbox.y0], [bbox.x1,bbox.y1]])\n","en_width = bbox_axes[1,0] - bbox_axes[0,0] # bbox is [(x0,y0),(x1,y1)]\n","\n","plt.close(fig)\n","en_width"],"metadata":{"id":"jZheCSBKeDkI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XhqraxQWu7te"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **IMPORTANT NOTE**:\n","## The following code cell is for video \"CodeChallenge: Can random embeddings be interpreted?\"\n","\n","## Leave it commented until that video!\n"],"metadata":{"id":"kIbYVQIk3zUh"}},{"cell_type":"code","source":["# ### --- random shuffling, option 1\n","\n","# # in-place shuffling, but only the rows\n","# np.random.shuffle(embeddings)\n","\n","# # transpose and shuffle the columns, then transpose back\n","# embeddings = embeddings.T\n","# np.random.shuffle(embeddings)\n","# embeddings = embeddings.T\n","\n","# ### --- random shuffling, option 2\n","\n","# # get permuted indices\n","# randindices = np.random.permutation(np.prod(embeddings.shape))\n","\n","# # randomize the vectorized matrix\n","# embeddings_flat = embeddings.flatten()[randindices]\n","\n","# # reshape back to 2D\n","# embeddings = embeddings_flat.reshape(embeddings.shape)"],"metadata":{"id":"K16z3pHO3lx2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dfzkMNlI3lvI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Todcc6hs4M-N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 1: Embeddings vector magnitudes"],"metadata":{"id":"-fZJcDTru7qv"}},{"cell_type":"code","source":["# tokenize text\n","# https://en.wikipedia.org/wiki/Tbilisi\n","text = \"Because of its location at the crossroads between Europe and Asia, and its proximity to the lucrative Silk Road, throughout history, Tbilisi has been a point of contention among various global powers. To this day, the city's location ensures its position as an important transit route for energy and trade projects. Tbilisi's history is reflected in its architecture, which is a mix of medieval, neoclassical, Beaux Arts, Art Nouveau, Stalinist, and Modern structures.\"\n","tokens = tokenizer.encode(text)[1:-1]\n","\n","# get all magnitudes\n","magnitudes = np.zeros(len(tokens))\n","for i,token in enumerate(tokens):\n","  magnitudes[i] = np.sqrt( sum(embeddings[token,:]**2) )\n","\n","plt.figure(figsize=(10,3))\n","plt.plot(magnitudes,'ks',markerfacecolor=[.6,.5,.2])\n","plt.gca().set(xlabel='Token index',ylabel='Embedding magnitude')\n","plt.show()"],"metadata":{"id":"YX_iCuBFfKbR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# min-max scale the magnitudes\n","scaled_mags = (magnitudes - min(magnitudes)) / (max(magnitudes)-min(magnitudes))\n","\n","plt.plot(magnitudes,scaled_mags,'ko',markerfacecolor=[.7,.9,.7],markersize=10)\n","plt.gca().set(xlabel='Raw magnitudes',ylabel='Scaled magnitudes')\n","plt.show()"],"metadata":{"id":"Xl8rINhokC5W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokCount = 0\n","\n","x_pos = 0  # starting x position (in axis coordinates)\n","y_pos = 1  # vertical center\n","\n","fig, ax = plt.subplots(figsize=(10,2))\n","ax.axis('off')\n","\n","for toki in range(len(tokens)):\n","\n","  # text of this token\n","  toktext = tokenizer.decode([tokens[toki]])\n","\n","  # width of the token\n","  token_width = en_width*len(toktext)\n","\n","  # text object with background color matching the \"activation\"\n","  ax.text(x_pos+token_width/2, y_pos, toktext, fontsize=12, ha='center', va='center',fontfamily='monospace',\n","          bbox = dict(boxstyle='round,pad=.3', facecolor=mpl.cm.Reds(scaled_mags[toki]), edgecolor='none', alpha=.8))\n","\n","  # update the token counter and x_pos\n","  tokCount += 1\n","  x_pos += token_width + .015 # plus a small gap\n","\n","  # end of the line; reset coordinates and counter\n","  if tokCount>=20:\n","    y_pos -= .2\n","    x_pos = 0\n","    tokCount = 0\n","\n","plt.show()"],"metadata":{"id":"I40tcPV1fb01"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dTy2fMUeqBzZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2: Cosine similarities in sequences"],"metadata":{"id":"GfBVEy6FvAKn"}},{"cell_type":"code","source":["# tokenize text\n","# https://en.wikipedia.org/wiki/Algae_fuel\n","text = \"Algae fuel, algal biofuel, or algal oil is an alternative to liquid fossil fuels that use algae as the source of energy-rich oils. Also, algae fuels are an alternative to commonly known biofuel sources, such as corn and sugarcane. When made from seaweed (macroalgae) it can be known as seaweed fuel or seaweed oil.  These fuels have no practical significance but remain an aspirational target in the biofuels research area.\"\n","tokens = tokenizer.encode(text)[1:-1]\n","\n","# get all similiarities\n","cossims = np.full(len(tokens),np.nan)\n","\n","for i in range(1,len(tokens)):\n","\n","  # previous token embedding\n","  v1 = embeddings[tokens[i-1],:].squeeze()\n","  v1norm = sum(v1**2)\n","\n","  # current token embedding\n","  v2 = embeddings[tokens[i],:]\n","  v2norm = sum(v2**2)\n","  cossims[i] = abs( sum(v1*v2) / np.sqrt( v1norm*v2norm ) )\n","\n","plt.figure(figsize=(10,3))\n","plt.plot(cossims,'ks',markerfacecolor=[.6,.5,.2])\n","plt.gca().set(xlabel='Token index',ylabel='Cosine similarity with previous token')\n","plt.show()"],"metadata":{"id":"Uq1nKuBkvAHf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Do we need to scale after the loop?\n","# Couldn't we incorporate this into the previous for-loop?\n","scaled_cs = (cossims - np.nanmin(cossims)) / (np.nanmax(cossims)-np.nanmin(cossims))\n","print(scaled_cs)\n","scaled_cs[0] = 0"],"metadata":{"id":"zivV7hJ2ooiz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokCount = 0\n","\n","x_pos = 0  # starting x position (in axis coordinates)\n","y_pos = 1  # vertical center\n","\n","fig, ax = plt.subplots(figsize=(10,2))\n","ax.axis('off')\n","\n","for toki in range(len(tokens)):\n","\n","  # text of this token\n","  toktext = tokenizer.decode([tokens[toki]])\n","\n","  # width of the token\n","  token_width = en_width*len(toktext)\n","\n","  # text object with background color matching the \"activation\"\n","  ax.text(x_pos+token_width/2, y_pos, toktext, fontsize=12, ha='center', va='center',fontfamily='monospace',\n","          bbox = dict(boxstyle='round,pad=.3', facecolor=mpl.cm.Reds(scaled_cs[toki]), edgecolor='none', alpha=.8))\n","\n","  # update the token counter and x_pos\n","  tokCount += 1\n","  x_pos += token_width + .015 # plus a small gap\n","\n","  # end of the line; reset coordinates and counter\n","  if tokCount>=20:\n","    y_pos -= .2\n","    x_pos = 0\n","    tokCount = 0\n","\n","plt.show()"],"metadata":{"id":"K1-TRimuvM8U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Bj3iCmbHvAEW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 3: Seeded cosine similarities"],"metadata":{"id":"vxnLJvADqBvw"}},{"cell_type":"code","source":["# tokenize text\n","# https://en.wikipedia.org/wiki/Purple\n","text = \"Purple has long been associated with royalty, originally because Tyrian purple dye—made from the secretions of sea snails—was extremely expensive in antiquity. Purple was the color worn by Roman magistrates; it became the imperial color worn by the rulers of the Byzantine Empire and the Holy Roman Empire, and later by Roman Catholic bishops. Similarly in Japan, the color is traditionally associated with the emperor and aristocracy.\"\n","tokens = tokenizer.encode(text)[1:-1]\n","\n","# the \"seed\" token embedding\n","seedtok = tokenizer.encode('purple')[1:-1]\n","seedvect = embeddings[seedtok,:].squeeze()\n","seednorm = sum(seedvect**2)\n","\n","# stored value is abs(cosine similarity) to seed\n","cossims = np.zeros(len(tokens))\n","for i,token in enumerate(tokens):\n","  targvect = embeddings[token,:]\n","  targnorm = sum(targvect**2)\n","  cossims[i] = abs( sum(seedvect*targvect) / np.sqrt( seednorm*targnorm ) )\n","\n","plt.figure(figsize=(10,3))\n","plt.plot(cossims,'ks',markerfacecolor=[.9,.7,.9])\n","plt.gca().set(xlabel='Token index',ylabel='Sc with \"purple\"')\n","plt.show()"],"metadata":{"id":"pHd_EFsqqBsH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# min-max scale\n","scaled_cs = (cossims - np.nanmin(cossims))/(np.nanmax(cossims)-np.nanmin(cossims))\n","\n","\n","tokCount = 0\n","\n","x_pos = 0  # starting x position (in axis coordinates)\n","y_pos = 1  # vertical center\n","\n","fig, ax = plt.subplots(figsize=(10,2))\n","ax.axis('off')\n","\n","for toki in range(len(tokens)):\n","\n","  # text of this token\n","  toktext = tokenizer.decode([tokens[toki]])\n","\n","  # width of the token\n","  token_width = en_width*len(toktext)\n","\n","  # text object with background color matching the \"activation\"\n","  ax.text(x_pos+token_width/2, y_pos, toktext, fontsize=12, ha='center', va='center',fontfamily='monospace',\n","          bbox = dict(boxstyle='round,pad=.3', facecolor=mpl.cm.Purples(cossims[toki]), edgecolor='none', alpha=.8))\n","\n","  # update the token counter and x_pos\n","  tokCount += 1\n","  x_pos += token_width + .015 # plus a small gap\n","\n","  # end of the line; reset coordinates and counter\n","  if tokCount>=20:\n","    y_pos -= .2\n","    x_pos = 0\n","    tokCount = 0\n","\n","plt.show()"],"metadata":{"id":"x9vSYIo1qBou"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uVZ8DAUefbdg"},"execution_count":null,"outputs":[]}]}