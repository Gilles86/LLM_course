{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNGn4yx5pcWRofM4+9KydJE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 5:</h2>|<h1>Observation (non-causal) mech interp<h1>|\n","|<h2>Section:</h2>|<h1>Investigating token embeddings<h1>|\n","|<h2>Lecture:</h2>|<h1><b>T-SNE projection and DBscan clustering<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"2B1b0m8GpiSw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dUh283u8V78F"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","from sklearn.manifold import TSNE\n","from sklearn.cluster import DBSCAN\n","\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":["from transformers import GPT2Model,GPT2Tokenizer\n","\n","# pretrained GPT-2 model and tokenizer\n","gpt2 = GPT2Model.from_pretrained('gpt2')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"],"metadata":{"id":"Iq4WDlRLWHlo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get the embeddings matrix\n","embedding = gpt2.wte.weight.detach().numpy()"],"metadata":{"id":"o2s2NHrJWHi8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"rsZxVoSjL055"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Gram matrix"],"metadata":{"id":"DG7qr486YWQo"}},{"cell_type":"code","source":["# extract the first N embeddings\n","nToks = 100\n","subEmbed = embedding[:nToks,:]"],"metadata":{"id":"NKodCyqq3ygV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# image for creating a Gram matrix\n","_,axs = plt.subplots(1,3,figsize=(12,4))\n","\n","G = subEmbed @ subEmbed.T\n","\n","axs[0].imshow(subEmbed,vmin=-.2,vmax=.2)\n","axs[0].set(xlabel='Embedding dimension',ylabel='Token',title='Embeddings')\n","\n","axs[1].imshow(subEmbed.T,vmin=-.2,vmax=.2)\n","axs[1].set(ylabel='Embedding dimension',xlabel='Token',title='Embeddings transpose')\n","\n","axs[2].imshow(G,vmin=2,vmax=7)\n","axs[2].set(xlabel='Token',ylabel='Token',title='Gram matrix')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"WmCs2sxkXGRP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cCkP4sZ0YVLt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# TSNE on some embeddings vectors"],"metadata":{"id":"Ke5L43vVL03Y"}},{"cell_type":"code","source":["# reduce to 2D with t-SNE\n","tsne = TSNE(n_components=2,perplexity=5)\n","tsne_result = tsne.fit_transform(subEmbed)\n","\n","# the result is an Nx2 matrix\n","tsne_result.shape"],"metadata":{"id":"OsO4gLLw3yR1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot the results\n","_,axs = plt.subplots(1,2,figsize=(13,5))\n","\n","# show the gram matrix\n","axs[0].imshow(G,origin='lower',vmin=2,vmax=7)\n","axs[0].set(xticks=range(1,nToks,3),xticklabels=[tokenizer.decode(i) for i in np.arange(1,nToks,3)],\n","           yticks=range(0,nToks,3),yticklabels=[tokenizer.decode(i) for i in np.arange(0,nToks,3)],\n","           title=f'Gram matrix, first {nToks} token embeds')\n","\n","axs[1].scatter(tsne_result[:,0], tsne_result[:,1], color=[.7,.7,1],edgecolor='k')\n","\n","\n","# label words\n","yoffset = .02 * np.diff(plt.gca().get_ylim()) # shift words up by x%\n","for i in range(nToks):\n","  axs[1].text(tsne_result[i,0], tsne_result[i,1]+yoffset, tokenizer.decode([i]),  ha='center')\n","\n","axs[1].set(xlabel='TSNE dim 1',ylabel='TSNE dim 2',title='T-SNE visualization of embeddings')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"f_5wn4FQL9Ua"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ABjln1Q0LzMV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# DBscan to find clusters"],"metadata":{"id":"Hc1gH-N7Mxf-"}},{"cell_type":"code","source":["# dbscan\n","clustmodel = DBSCAN(eps=7,min_samples=3).fit(tsne_result)\n","dir(clustmodel)"],"metadata":{"id":"bbvcwqgq3ydi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# cluster assignment labels\n","groupidx = clustmodel.labels_\n","\n","# number of clusters\n","nclust = max(groupidx)+1 # +1 for indexing\n","\n","# calculate the cluster centers\n","cents = np.zeros((nclust,2))\n","for ci in range(nclust):\n","  cents[ci,0] = np.mean(tsne_result[groupidx==ci,0])\n","  cents[ci,1] = np.mean(tsne_result[groupidx==ci,1])"],"metadata":{"id":"69XSPnrTM6Fu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# draw lines from each data point to the centroids of each cluster\n","plt.figure(figsize=(8,6))\n","lineColors = 'rkbgm'\n","\n","# plot each dot according to its cluster (or lack thereof)\n","for i in range(len(tsne_result)):\n","  if groupidx[i]==-1:\n","    plt.plot(tsne_result[i,0],tsne_result[i,1],'k+')\n","  else:\n","    plt.plot([ tsne_result[i,0], cents[groupidx[i],0] ],[ tsne_result[i,1], cents[groupidx[i],1] ],lineColors[groupidx[i]])\n","\n","\n","# now draw the raw data in different colors\n","for i in range(nclust):\n","  plt.plot(tsne_result[groupidx==i,0],tsne_result[groupidx==i,1],'o',markerfacecolor=lineColors[i])\n","\n","# and now plot the centroid locations\n","plt.plot(cents[:,0],cents[:,1],'kd',markerfacecolor=[.8,.7,.1],markersize=10)\n","plt.gca().set(xlabel='tSNE axis 1',ylabel='tSNE axis 2',title=f'Result of dbscan clustering (k={nclust})')\n","\n","plt.show()"],"metadata":{"id":"LpiibE3bM2Pa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["groupidx"],"metadata":{"id":"swhcLY1Jf_uG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for cidx in range(-1,nclust):\n","\n","  # find all the tokens in this group\n","  tokensInGroup = np.where(groupidx==cidx)[0]\n","\n","  # print them out\n","  if cidx==-1:\n","    print(f'\\nUngrouped tokens:')\n","  else:\n","    print(f'\\nTokens in group {cidx}:')\n","  print([ ' '.join(tokenizer.decode([t])) for t in tokensInGroup ])"],"metadata":{"id":"aT0pg5Zc3yau"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XdItNOlQNqWl"},"execution_count":null,"outputs":[]}]}