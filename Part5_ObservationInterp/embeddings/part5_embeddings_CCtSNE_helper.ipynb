{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyP0ekgOwFsobYutkCY2W8l1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 5:</h2>|<h1>Observation (non-causal) mech interp<h1>|\n","|<h2>Section:</h2>|<h1>Investigating token embeddings<h1>|\n","|<h2>Lecture:</h2>|<h1><b>CodeChallenge HELPER: cluster the \"x\" terms<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"2B1b0m8GpiSw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"dUh283u8V78F"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","from sklearn.manifold import TSNE\n","from sklearn.cluster import DBSCAN\n","\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":["from transformers import GPT2Model,GPT2Tokenizer\n","\n","# pretrained GPT-2 model and tokenizer\n","gpt2 = GPT2Model.from_pretrained('gpt2')\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n","embedding = gpt2.wte.weight.detach().numpy()"],"metadata":{"id":"Iq4WDlRLWHlo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"o0oFDMfnaL35"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 1: Find the \"x\" terms"],"metadata":{"id":"LQMTSAec3yXm"}},{"cell_type":"code","source":["# find all tokens that start with x and\n","xToks = []\n","\n","for i in range(tokenizer.vocab_size):\n","\n","  # get the token (ignoring preceding space)\n","  tok =\n","\n","  # add it to the list if it's between 4 and 8 characters\n","  if () & ()\n","    print(tok)\n","    xToks.append(\n","\n","nToks = len(xToks)"],"metadata":{"id":"JSoE1iK13yUz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'There are {} tokens with an \"x\"')"],"metadata":{"id":"JE1DOQuTqCDM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HqJtPbx9M_3m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2: tSNE"],"metadata":{"id":"S83uf8q7aTE0"}},{"cell_type":"code","source":["# extract a submatrix with only the relevant tokens\n","subEmbed = embed\n","\n","\n","# reduce to 2D with t-SNE\n","tsne = TSNE(n_components=2,perplexity=5)\n","tsne_result = tsne.\n","\n","# plot results\n","_,axs = plt.subplots(1,2,figsize=(13,5))\n","\n","axs[0].imshow(\n","axs[0].set(xticks=range(1,nToks,21),\n","           yticks=range(0,nToks,21),yticklabels=[tokenizer.decode(xToks[i]) for i in np.arange(0,nToks,21)],\n","           title=f'Gram matrix of {nToks} token embeds')\n","axs[0].set_xticklabels([tokenizer.decode(xToks[i]) for i in np.arange(1,nToks,21)],rotation=90)\n","\n","axs[1].scatter(\n","\n","\n","# label words\n","yoffset = .02 * np.diff(plt.gca().get_ylim()) # shift words up by x%\n","for i in range(nToks):\n","  axs[1].text(tsne_result[i,0], tsne_result[i,1]+yoffset,)\n","\n"],"metadata":{"id":"7Q7W0Q3e3yPB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Dt0AM2v1NVb1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 3: DBSCAN"],"metadata":{"id":"588PmWidaWeT"}},{"cell_type":"code","source":["## dbscan\n","epsilon = 7\n","minsamples = 3\n","\n","clustmodel = DBSCAN\n","groupidx = clustmodel.labels_\n","\n","# number of clusters\n","nclust =\n","\n","# compute cluster centers\n","cents = np.zeros((nclust,2))\n","for ci in range(nclust):\n","  cents[ci,0] =\n","  cents[ci,1] =\n","\n","# draw lines from each data point to the centroids of each cluster\n","plt.figure(figsize=(8,6))\n","lineColors = 'rkbgm'\n","for i in range(len(tsne_result)):\n","  if groupidx[i]==-1:\n","\n","  else:\n","\n","\n","# now draw the raw data in different colors\n","for i in range(nclust):\n","\n","# and now plot the centroid locations\n","plt.gca().set(xlabel='tSNE axis 1',ylabel='tSNE axis 2',\n","              title=f'DBSCAN ($\\\\epsilon$={epsilon}, minclust={minsamples}) identified {nclust} clusters')\n","\n","plt.show()"],"metadata":{"id":"GwwmogkK3yL0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print the tokens in each cluster\n","\n","for cidx in range(-1,nclust):\n","\n","  # find all the tokens in this group\n","  tokensInGroup =\n","\n","  # print them out\n","  if cidx==-1:\n","    print(f'\\nUngrouped tokens:')\n","  else:\n","    print(f'\\nTokens in group {cidx}:')\n"],"metadata":{"id":"arQoLA1NNqjF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XdItNOlQNqWl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 4: Cluster count by parameter value"],"metadata":{"id":"QgAEEfyZs5eE"}},{"cell_type":"code","source":["# vary the epsilons for a fixed number of samples\n","epsilons = np.linspace(2,20,15)\n","numClusters = np.zeros\n","\n","for i,epi in enumerate(epsilons):\n","  clustmodel =\n","  numClusters[i] =\n","\n","plt.figure(figsize=(10,3))\n","plt.gca().set(xlabel='Epsilon parameter',ylabel='Number of labeled clusters',\n","              title='Minimum sample size fixed to 3')\n","plt.show()"],"metadata":{"id":"UgCWQvVysQ24"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# vary the number of samples for a fixed epsilon\n","minsamples = np.arange(1,20)\n","numClusters = np.zeros(len(\n","\n","for i,nsamp in enumerate(minsamples):\n","\n","plt.figure(figsize=(10,3))\n"],"metadata":{"id":"WS_cdcENsQw6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# vary both!\n","epsilons = np.linspace(2,20,15)\n","minsamples = np.arange(1,20)\n","\n","numClusters = np.zeros((len(epsilons),len(minsamples)))\n","\n","for i,epi in enumerate(epsilons):\n","  for j,nsamp in enumerate(minsamples):\n","\n","\n","# show in an image\n"],"metadata":{"id":"BODGXWVDsQth"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9XkfbPaesQhB"},"execution_count":null,"outputs":[]}]}