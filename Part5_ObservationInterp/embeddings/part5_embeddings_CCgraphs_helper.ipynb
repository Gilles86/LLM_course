{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyMYLTcv/YEZUnNUULYzHBmT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 5:</h2>|<h1>Observation (non-causal) mech interp<h1>|\n","|<h2>Section:</h2>|<h1>Investigating token embeddings<h1>|\n","|<h2>Lecture:</h2>|<h1><b>CodeChallenge HELPER: Graph representation of cosine similarities<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">udemy.com/course/dulm_x/?couponCode=202509</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"R93xSOAiSWbg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTp8j3TJAqvB"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":["# load BERT tokenizer and model\n","from transformers import BertTokenizer, BertModel\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-base-uncased')\n","embeddings = model.embeddings.word_embeddings.weight.detach().numpy()"],"metadata":{"id":"IlLTVTpTBS75"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_oB_uEPlCnEj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 1: Tokenize text"],"metadata":{"id":"tKA23cZ6jTdr"}},{"cell_type":"code","source":["# https://en.wikipedia.org/wiki/Carbonated_water\n","text = \"It is thought that the first person to aerate water with carbon dioxide was William Brownrigg in the 1740s. Joseph Priestley invented carbonated water, independently and by accident, in 1767 when he discovered a method of infusing water with carbon dioxide after having suspended a bowl of water above a beer vat at a brewery in Leeds, Yorkshire. He wrote of the 'peculiar satisfaction' he found in drinking it, and in 1772 he published a paper entitled Impregnating Water with Fixed Air. Priestley's apparatus, almost identical to that used by Henry Cavendish five years earlier, which featured a bladder between the generator and the absorption tank to regulate the flow of carbon dioxide, was soon joined by a wide range of others. However, it was not until 1781 that companies specialized in producing artificial mineral water were established and began producing carbonated water on a large scale. The first factory was built by Thomas Henry of Manchester, England. Henry replaced the bladder in Priestley's system with large bellows.\"\n","\n","# https://en.wikipedia.org/wiki/Small-world_network\n","text = \"A small-world network is a graph characterized by a high clustering coefficient and low distances. In an example of the social network, high clustering implies the high probability that two friends of one person are friends themselves. The low distances, on the other hand, mean that there is a short chain of social connections between any two people (this effect is known as six degrees of separation). Specifically, a small-world network is defined to be a network where the typical distance L between two randomly chosen nodes (the number of steps required) grows proportionally to the logarithm of the number of nodes N in the network,\"\n","\n","# get all the unique tokens\n","tokens =\n","tokens =\n","\n","\n"],"metadata":{"id":"NTBvZ_qCSbsm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cFx-sHmUjgqB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2: Calculate the cosine similarity matrix and threshold"],"metadata":{"id":"9LIBq5WAkq5m"}},{"cell_type":"code","source":["E = embeddings\n","\n","# normalize each vector to its norm (unit length)\n","E_norm =  / norm\n","\n","# cosine similarity matrix\n","csM = @\n","\n","# visualize\n","plt.figure(figsize=(6,6))\n","\n","plt.show()"],"metadata":{"id":"u9qB1ZI4Sboz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get a vector of all unique matrix elements\n","uniqueCS =\n","\n","# here's the threshold!\n","thresh ="],"metadata":{"id":"5yb55k2xfSSN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# show in a historgram\n","plt.figure(figsize=(8,4))\n","\n","plt.legend()\n","plt.gca().set(xlabel='Cosine similarity value',ylabel='Count')\n","plt.show()"],"metadata":{"id":"GaKIrTTRSblK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yjgjyXjMlGM1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 3: Create a masked CS matrix"],"metadata":{"id":"4uPryp0klGKO"}},{"cell_type":"code","source":["# the mask\n","mask =\n","# also remove diagonal (done in-place!)\n","np.fill_diagonal\n","\n","\n","# the masked matrix\n","### Note: I changed my code so I don't actually use this matrix in exercise 4,\n","### but this kind of matrix is used in other graph-theory analyses, so I'll leave the code here :P\n","csMasked = csM.copy()\n","csMasked[csM<thresh] = 0\n","\n","# also remove diagonal (done in-place!)\n","\n","\n","\n","## visualized\n","_,axs = plt.subplots(1,3,figsize=(13,4))\n","\n"],"metadata":{"id":"x3Bd_9uQSbh6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CTVG9L1Wmt_W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 4: The circular similarity graph"],"metadata":{"id":"0QvPJjq2mt8l"}},{"cell_type":"code","source":["# values for theta\n","N = len(tokens)\n","dth = 1/N\n","th = np.linspace(0,2*np.pi-dth,\n","\n","# create a figure\n","plt.figure(figsize=(8,8))\n","\n","# loop over tokens\n","for i in range(N):\n","\n","  # determine dot (marker) size\n","  dotsize =\n","\n","  # continue to next token if this one has weak similarity\n","\n","\n","  # otherwise, plot and continue!\n","  plt.plot(,,'ko',markerfacecolor=[.7,.7,.7],markersize=dotsize)\n","\n","\n","  # annotate the tokens\n","  if i%2==0:\n","    plt.text(np.cos(th[i]),np.sin(th[i]),tokenizer.decode([tokens[i]]),\n","            ha=['right','left'][int(np.cos(th[i])>0)],\n","            va=['top','bottom'][int(np.sin(th[i])>0)], fontweight='bold')\n","\n","  # loop over all the other tokens\n","  for j in range(i+1,N):\n","\n","    # only draw a line if similarity exceeds the threshold\n","    if\n","\n","      # random color\n","      color =\n","\n","      # draw it!\n","      plt.plot()\n","\n","plt.axis('off')\n","plt.show()"],"metadata":{"id":"O2nMQ7c2Sbe5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"DWxIIt-YT5x2"},"execution_count":null,"outputs":[]}]}