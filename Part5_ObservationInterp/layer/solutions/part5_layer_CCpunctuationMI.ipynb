{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPFKHE+jyyoRiEB8DV29Vjf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 5:</h2>|<h1>Observation (non-causal) mech interp<h1>|\n","|<h2>Section:</h2>|<h1>Investigating layers<h1>|\n","|<h2>Lecture:</h2>|<h1><b>CodeChallenge: Clusters in internal vs. terminal punctuation<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"1Jy0D6mE78uS"}},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from matplotlib.gridspec import GridSpec\n","import matplotlib as mpl\n","\n","import requests\n","\n","import torch\n","\n","# vector plots\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"],"metadata":{"id":"aoocnKDi-2RN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"L_5xIvYA--eH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 1: Model and punctuation indices"],"metadata":{"id":"gfLe3fZX9kqm"}},{"cell_type":"code","source":["# load pretrained GPT-2 model and tokenizer\n","from transformers import AutoModelForCausalLM,GPT2Tokenizer\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","gpt2 = AutoModelForCausalLM.from_pretrained('gpt2-medium')\n","gpt2 = gpt2.to(device)\n","gpt2.eval()\n","nEmb = gpt2.config.n_embd\n","\n","tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')"],"metadata":{"id":"bHKfbxSx-B5Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = requests.get('https://www.gutenberg.org/cache/epub/219/pg219.txt').text # Heart of Darkness\n","tokens = tokenizer.encode(text,return_tensors='pt')\n","num_tokens = len(tokens[0])\n","\n","print(f'There are {num_tokens:,} tokens, {len(np.unique(tokens[0].tolist()))} of which are unique.')"],"metadata":{"id":"QqQENLC_8gJ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tokens to match exactly\n","internal_punctuations = [',']#,':',';']\n","terminal_punctuations = ['.']#,'?','!']\n","\n","\n","# initialize vector\n","isPunctuation = np.zeros(num_tokens,dtype=int)\n","\n","# loop over all tokens (ignore starting tokens before the book starts)\n","for ti in range(400,num_tokens):\n","\n","  # current token\n","  currtok = tokenizer.decode(tokens[0,ti]).strip()\n","\n","\n","  # test for punctuation\n","  if currtok in internal_punctuations:\n","      isPunctuation[ti] = 1\n","\n","  # check if it's terminal -- and not a decimal-point number!\n","  elif currtok in terminal_punctuations:\n","    if (tokenizer.decode(tokens[0,ti-1])[-1] not in '0123456789') and (tokenizer.decode(tokens[0,ti+1])[0] not in '0123456789'):\n","      isPunctuation[ti] = 2\n","\n","\n","# report\n","print(f'There are:\\n  {sum(isPunctuation==1):3} internal punctuation marks, and\\n  {sum(isPunctuation==2):3} terminal punctuation marks.')"],"metadata":{"id":"P7EgksOB2Rqi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vb86hzbwgTQQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# find the indices\n","internalIdx = np.where(isPunctuation==1)[0]\n","terminalIdx = np.where(isPunctuation==2)[0]\n","\n","# examine some punctuations\n","context_win = 9\n","for t in terminalIdx[:5]:\n","  print(f'Example {t}:\\n{tokenizer.decode(tokens[0,t-context_win:t+context_win])}\\n')"],"metadata":{"id":"YIzCv9xAxqrg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"KqtdhfcQ9jOF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2: Create batches and get activations"],"metadata":{"id":"tbA-5s4SD9mv"}},{"cell_type":"code","source":["# some data parameters\n","batchsize   = 250\n","context_pre = 20\n","context_pst = 10"],"metadata":{"id":"S1sy2jikiETI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create batches\n","batch_internal = torch.zeros((batchsize,context_pre+context_pst+1),dtype=torch.long)\n","batch_terminal = torch.zeros((batchsize,context_pre+context_pst+1),dtype=torch.long)\n","\n","# loop over sequences to create batches\n","for b in range(batchsize):\n","\n","  # internal punctuations\n","  tokenLoc = internalIdx[b]\n","  batch_internal[b,:] = tokens[0,tokenLoc-context_pre:tokenLoc+context_pst+1]\n","\n","  # terminal punctuations\n","  tokenLoc = terminalIdx[b]\n","  batch_terminal[b,:] = tokens[0,tokenLoc-context_pre:tokenLoc+context_pst+1]\n","\n","\n","batch_terminal.shape"],"metadata":{"id":"-FMLAjEmI1hm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# process the internal tokens\n","with torch.no_grad():\n","  output_internal = gpt2(batch_internal.to(device),output_hidden_states=True)\n","\n","# repeat for terminal tokens\n","with torch.no_grad():\n","  output_terminal = gpt2(batch_terminal.to(device),output_hidden_states=True)"],"metadata":{"id":"KtC8DXBhxqkl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(output_internal.hidden_states[3].shape)\n","len(output_internal.hidden_states)"],"metadata":{"id":"dOFc8S1KAQ_2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for convenience, bring the activations to the CPU in a shorter-named variable\n","hsIntern = []\n","hsTermin = []\n","\n","for i in range(len(output_internal.hidden_states)):\n","  hsIntern.append( output_internal.hidden_states[i].detach().cpu().numpy() )\n","  hsTermin.append( output_terminal.hidden_states[i].detach().cpu().numpy() )"],"metadata":{"id":"48ZJREDcP5Wj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hsIntern[4].shape"],"metadata":{"id":"mB-PEZ91BWWa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize\n","\n","ave_intern = hsIntern[3][:,context_pre,:].mean(axis=0)\n","ave_termin = hsTermin[3][:,context_pre,:].mean(axis=0)\n","\n","_,axs = plt.subplots(1,2,figsize=(10,4))\n","\n","axs[0].plot(ave_intern,'o',label='Internal')\n","axs[0].plot(ave_termin,'s',label='Terminal')\n","axs[0].set(xlabel='Embedding dimension index',ylabel='Hidden state activation',title='Activations')\n","axs[0].legend()\n","\n","axs[1].plot(ave_intern,ave_termin,'ko',markerfacecolor=[.4,.7,.5],alpha=.4)\n","axs[1].set(xlabel='Internal',ylabel='Terminal',title='Scatter plot of activations')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"TsHRDxPdF9t2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PFf_mmw38Oqm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 3: MI and cov in one layer"],"metadata":{"id":"IGTU_e5Z8OhQ"}},{"cell_type":"code","source":["# a function for mutual information\n","def mutInfo_and_cov(x,y,outlierThresh=0):\n","\n","  # remove outliers based on a z-score threshold\n","  if outlierThresh>0:\n","    zx = (x-x.mean())/x.std(ddof=1)\n","    zy = (y-y.mean())/y.std(ddof=1)\n","    outlier = (abs(zx)>outlierThresh) | (abs(zy)>outlierThresh)\n","    x = x[~outlier]\n","    y = y[~outlier]\n","\n","\n","  # histogram and convert to proportion (estimate of probability)\n","  Z  = np.histogram2d(x,y,bins=15)[0]\n","  pZ = Z / Z.sum()\n","  px = pZ.sum(axis=1)\n","  py = pZ.sum(axis=0)\n","\n","  # calculate entropy\n","  eps = 1e-12\n","  Hx = -np.sum( px * np.log2(px+eps) )\n","  Hy = -np.sum( py * np.log2(py+eps) )\n","  HZ = -np.sum( pZ * np.log2(pZ+eps) )\n","\n","  # mutual information\n","  MI = Hx+Hy - HZ\n","\n","  # and covariance\n","  C = sum( (x-x.mean())*(y-y.mean()) ) / (len(x)-1)\n","\n","  return MI,C"],"metadata":{"id":"uJ4OBO06F5ss"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# sanity-check target index ;)\n","tokenizer.decode(batch_terminal[3,context_pre])"],"metadata":{"id":"lCRNLNgwTD4T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# this cell takes ~40 sec\n","whichLayer = 1 # 20\n","\n","mi_in = np.zeros((batchsize,batchsize))\n","mi_tr = np.zeros((batchsize,batchsize))\n","cov_in = np.zeros((batchsize,batchsize))\n","cov_tr = np.zeros((batchsize,batchsize))\n","\n","\n","\n","# double-loop over the token pairs\n","for bi in range(batchsize):\n","  for bj in range(bi+1,batchsize):\n","\n","    ## internal punctuation\n","    # extract the data\n","    x = hsIntern[whichLayer][bi,context_pre,:]\n","    y = hsIntern[whichLayer][bj,context_pre,:]\n","\n","    # pairwise mutual information and covariance\n","    mi_in[bi,bj],cov_in[bi,bj] = mutInfo_and_cov(x,y,5)\n","\n","\n","    ## repeat for terminal punctuation\n","    x = hsTermin[whichLayer][bi,context_pre,:]\n","    y = hsTermin[whichLayer][bj,context_pre,:]\n","    mi_tr[bi,bj],cov_tr[bi,bj] = mutInfo_and_cov(x,y,5)"],"metadata":{"id":"XthpUT_tHcuV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# a variable to extract and vectorize the unique matrix elements\n","uniqueIndices = np.triu_indices(batchsize,1)\n","uniqueIndices"],"metadata":{"id":"lzfBw0DgYXgd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kHKvsELdDAM6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize all pairwise MI from one layer\n","\n","fig = plt.figure(figsize=(8,6))\n","gs = GridSpec(2,2,figure=fig)\n","ax0 = fig.add_subplot(gs[0,0])\n","ax1 = fig.add_subplot(gs[0,1])\n","ax2 = fig.add_subplot(gs[1,:])\n","\n","\n","# show the matrices\n","h = ax0.imshow(mi_in,vmin=.1,vmax=1,origin='lower',aspect='auto')\n","plt.colorbar(h,ax=ax0,fraction=.046,pad=.02)\n","ax0.set(xticks=[],yticks=[],xlabel='Sequence index',ylabel='Sequence index',title='Pairwise MI for INTERNAL')\n","\n","h = ax1.imshow(mi_tr,vmin=.1,vmax=1,origin='lower',aspect='auto')\n","plt.colorbar(h,ax=ax1,fraction=.046,pad=.02)\n","ax1.set(xticks=[],yticks=[],xlabel='Sequence index',ylabel='Sequence index',title='Pairwise MI for TERMINAL')\n","\n","\n","# get histograms from nonzero elements\n","yIntern,xIntern = np.histogram(mi_in[uniqueIndices],bins=60)\n","yTermin,xTermin = np.histogram(mi_tr[uniqueIndices],bins=60)\n","\n","# and show those\n","ax2.plot(xIntern[:-1],yIntern,label='Internal',linewidth=2)\n","ax2.plot(xTermin[:-1],yTermin,label='Terminal',linewidth=2)\n","ax2.set(xlim=[min(xIntern[0],xTermin[0]),max(xIntern[-1],xTermin[-1])],\n","        xlabel='Mutual information',ylabel='Count',title='Distribution of MI values')\n","ax2.legend()\n","\n","\n","plt.tight_layout()\n","plt.suptitle(f'Mutual information in layer {whichLayer}',y=1.05,fontweight='bold',fontsize=16)\n","plt.show()"],"metadata":{"id":"iTU3bFqHIeK0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize all pairwise covariance from one layer\n","\n","fig = plt.figure(figsize=(8,6))\n","gs = GridSpec(2,2,figure=fig)\n","ax0 = fig.add_subplot(gs[0,0])\n","ax1 = fig.add_subplot(gs[0,1])\n","ax2 = fig.add_subplot(gs[1,:])\n","\n","\n","# show the matrices\n","h = ax0.imshow(cov_in,vmin=0,vmax=2,origin='lower')\n","plt.colorbar(h,ax=ax0,fraction=.046,pad=.02)\n","ax0.set(xticks=[],yticks=[],xlabel='Sequence index',ylabel='Sequence index',title='Pairwise MI for INTERNAL')\n","\n","h = ax1.imshow(cov_tr,vmin=0,vmax=2,origin='lower')\n","plt.colorbar(h,ax=ax1,fraction=.046,pad=.02)\n","ax1.set(xticks=[],yticks=[],xlabel='Sequence index',ylabel='Sequence index',title='Pairwise MI for TERMINAL')\n","\n","\n","# get histograms from nonzero elements\n","yIntern,xIntern = np.histogram(cov_in[uniqueIndices],bins=60)\n","yTermin,xTermin = np.histogram(cov_tr[uniqueIndices],bins=60)\n","\n","# and show those\n","ax2.plot(xIntern[:-1],(yIntern),label='Internal',linewidth=2)\n","ax2.plot(xTermin[:-1],(yTermin),label='Terminal',linewidth=2)\n","ax2.set(xlim=[min(xIntern[0],xTermin[0]),max(xIntern[-1],xTermin[-1])],\n","        xlabel='Covariance',ylabel='Log count',title='Distribution of covariance values')\n","ax2.legend()\n","\n","\n","plt.tight_layout()\n","plt.suptitle(f'Covariance in layer {whichLayer}',y=1.05,fontweight='bold',fontsize=16)\n","plt.show()"],"metadata":{"id":"0tQ0K8svSfQ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"clBUHUJdqCtm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## covariance by mutual information\n","\n","_,axs = plt.subplots(1,3,figsize=(12,4))\n","\n","# skip to facilitate plotting\n","pnts2skip = 17\n","\n","# plot the internal punctuations\n","axs[0].plot(cov_in[uniqueIndices][::pnts2skip],mi_in[uniqueIndices][::pnts2skip],'.',markerfacecolor=[.7,.7,.9,.3])\n","axs[0].set(xlabel='Covariance',ylabel='Mutual information',\n","           title=f'Internal punctuation (r = {np.corrcoef(cov_in[uniqueIndices],mi_in[uniqueIndices])[0,1]:.3f})')\n","\n","# plot the terminal punctuations\n","axs[1].plot(cov_tr[uniqueIndices][::pnts2skip],mi_tr[uniqueIndices][::pnts2skip],'.',markerfacecolor=[.9,.7,.7,.3])\n","axs[1].set(xlabel='Covariance',ylabel='Mutual information',\n","           title=f'Terminal punctuation (r = {np.corrcoef(cov_tr[uniqueIndices],mi_tr[uniqueIndices])[0,1]:.3f})')\n","\n","\n","axs[2].plot(cov_in[uniqueIndices][::pnts2skip],mi_in[uniqueIndices][::pnts2skip],'r.',alpha=.3,label='Intermediate')\n","axs[2].plot(cov_tr[uniqueIndices][::pnts2skip],mi_tr[uniqueIndices][::pnts2skip],'k.',alpha=.3,label='Terminal')\n","axs[2].set(xlabel='Covariance',ylabel='Mutual information',title='Both')\n","axs[2].legend()\n","\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"rcM5f_DwX-bf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pcgcUT_C8OVO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 4: MI and cov over all layers"],"metadata":{"id":"4XAhyDBhnyaJ"}},{"cell_type":"code","source":["# initializations\n","mi_in_all = np.zeros((len(hsIntern),batchsize,batchsize))\n","mi_tr_all = np.zeros((len(hsIntern),batchsize,batchsize))\n","cv_in_all = np.zeros((len(hsIntern),batchsize,batchsize))\n","cv_tr_all = np.zeros((len(hsIntern),batchsize,batchsize))\n","\n","\n","# loop over layers\n","for layeri in range(len(hsIntern)):\n","\n","  # double-loop over the token pairs\n","  for bi in range(batchsize):\n","    for bj in range(bi+1,batchsize):\n","\n","      ## internal punctuation\n","      x = hsIntern[layeri][bi,context_pre,:]\n","      y = hsIntern[layeri][bj,context_pre,:]\n","      mi_in_all[layeri,bi,bj],cv_in_all[layeri,bi,bj] = mutInfo_and_cov(x,y,5)\n","\n","      ## repeat for terminal punctuation\n","      x = hsTermin[layeri][bi,context_pre,:]\n","      y = hsTermin[layeri][bj,context_pre,:]\n","      mi_tr_all[layeri,bi,bj],cv_tr_all[layeri,bi,bj] = mutInfo_and_cov(x,y,5)\n","\n","  print(f'Finished layer {layeri+1:2}/{len(hsIntern)}')"],"metadata":{"id":"r-tc1ZUQnyUJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# scatter plots\n","_,axs = plt.subplots(5,5,figsize=(12,11))\n","axs = axs.flatten()\n","\n","\n","# skip to facilitate plotting\n","pnts2skip = 7\n","\n","for layeri in range(len(hsIntern)):\n","\n","  # plot the dots\n","  axs[layeri].plot(cv_in_all[layeri][uniqueIndices][::pnts2skip],mi_in_all[layeri][uniqueIndices][::pnts2skip],'r.',alpha=.2,label='Intermediate')\n","  axs[layeri].plot(cv_tr_all[layeri][uniqueIndices][::pnts2skip],mi_tr_all[layeri][uniqueIndices][::pnts2skip],'k.',alpha=.2,label='Terminal')\n","\n","  # adjust the axis\n","  axs[layeri].set(xticks=[],yticks=[],title=f'Layer {layeri}')\n","\n","axs[20].set(xlabel='Covariance',ylabel='Mutual information')\n","axs[20].legend(fontsize=8)\n","\n","plt.tight_layout()\n","# plt.savefig('ex4.png')\n","plt.show()"],"metadata":{"id":"W_x59ohsyIS8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jnwIJ8GAo1Dv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 5: Distributions and means"],"metadata":{"id":"i4k5k1zqwFDN"}},{"cell_type":"code","source":["fig,axs = plt.subplots(2,2,figsize=(10,6))\n","\n","# normalization function for mapping layer index onto color\n","norm = mpl.colors.Normalize(vmin=0,vmax=len(hsIntern))\n","\n","for layeri in range(len(hsIntern)):\n","\n","  ### covariance: plot the distribution\n","  yy,xx = np.histogram(cv_in_all[layeri][uniqueIndices],bins=np.linspace(-1,105,101),density=True)\n","  axs[0,0].plot(xx[:-1],yy,color=mpl.cm.plasma(norm(layeri)))\n","\n","  # and the mean of the distribution\n","  axs[0,1].plot(layeri,cv_in_all[layeri][uniqueIndices].mean(),'ks',\n","              markersize=10,markerfacecolor=mpl.cm.plasma(norm(layeri)))\n","\n","\n","\n","  ### mutual information\n","  yy,xx = np.histogram(mi_in_all[layeri][uniqueIndices],bins=np.linspace(0,1.5,101),density=True)\n","  axs[1,0].plot(xx[:-1],yy,color=mpl.cm.plasma(norm(layeri)))\n","\n","  # the mean\n","  axs[1,1].plot(layeri,mi_in_all[layeri][uniqueIndices].mean(),'ks',\n","              markersize=10,markerfacecolor=mpl.cm.plasma(norm(layeri)))\n","\n","\n","\n","# add colorbars\n","sm = mpl.cm.ScalarMappable(cmap=mpl.cm.plasma,norm=norm)\n","plt.colorbar(sm,ax=axs[0,0],pad=.01)\n","plt.colorbar(sm,ax=axs[1,0],pad=.01)\n","\n","# labels and titles\n","axs[0,0].set(xlabel='Covariance value',ylabel='Density',title='Covariance distribution')\n","axs[0,1].set(xlabel='Hidden layer',ylabel='Covariance',title='Average covariances')\n","axs[1,0].set(xlabel='Mutual information value',ylabel='Density',title='MI distribution')\n","axs[1,1].set(xlabel='Hidden layer',ylabel='Mutual information',title='Average MI values')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"t8OYqQx9o1Ao"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sE-SD4Ea45Z_"},"execution_count":null,"outputs":[]}]}