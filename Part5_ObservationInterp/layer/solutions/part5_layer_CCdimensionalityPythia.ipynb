{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyOgTRpV975xXhisretncdGH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 5:</h2>|<h1>Observation (non-causal) mech interp<h1>|\n","|<h2>Section:</h2>|<h1>Investigating layers<h1>|\n","|<h2>Lecture:</h2>|<h1><b>CodeChallenge: Dimensionalities in Pythia 2.3B<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"tL45trWPK0av"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"5BvQj17hzqwM"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","import matplotlib.gridspec as gridspec\n","\n","import requests\n","\n","import torch\n","\n","# vector plots\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":[],"metadata":{"id":"PeSYiLO2s2ag"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 1: Import and inspect Pythia-2.8b"],"metadata":{"id":"S9juHdZrs2YN"}},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","# Eleuther's tokenizer\n","tokenizer = AutoTokenizer.from_pretrained('EleutherAI/pythia-2.8b')\n","\n","# and their pythia model\n","model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-2.8b\")\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","model.eval()"],"metadata":{"id":"vEwYHoqWz0nB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Alice in Wonderland\n","text = requests.get('https://www.gutenberg.org/cache/epub/11/pg11.txt').text\n","text = requests.get('https://pigeonsarentreal.co.uk/').text # a funny website\n","\n","allTokens = tokenizer.encode(text,return_tensors='pt')\n","tokens = allTokens[:,10000:11000]\n","\n","print(tokenizer.decode(tokens[0]))"],"metadata":{"id":"1QCtJSG8LRVO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokensShuffle = tokens[0,torch.randperm(len(tokens[0]))].unsqueeze(0)\n","print(tokenizer.decode(tokensShuffle[0]))"],"metadata":{"id":"_KEpro9XLRDg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tjJsEaWGOKuI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# push through the model\n","with torch.no_grad():\n","  outputs_real = model(tokens.to(device),output_hidden_states=True)\n","  outputs_shuf = model(tokensShuffle.to(device),output_hidden_states=True)\n","\n","print(f'There are {len(outputs_real.hidden_states)} hidden layers.')\n","print(f'Each layer has size {outputs_real.hidden_states[0].shape}')"],"metadata":{"id":"DfiAwJNxLRSe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["numHidden = len(outputs_real.hidden_states)"],"metadata":{"id":"Gjb7zo1lp7gz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dChFlHM-cncR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2: Calculate dimensionality matrices"],"metadata":{"id":"OGChP-83s_ad"}},{"cell_type":"code","source":["# initialize\n","cumVarExplained = np.zeros((numHidden,outputs_real.hidden_states[4].shape[1],2))\n","effectiveCompCount = np.zeros((numHidden,2,2),dtype=int)\n","\n","\n","# loop over layers\n","for layeri in range(numHidden):\n","\n","  # extract all the activations from this layer (assuming no batches)\n","  acts = outputs_real.hidden_states[layeri].squeeze().cpu().numpy()\n","\n","  # mean-center the activations\n","  acts -= acts.mean(axis=0,keepdims=True)\n","\n","  # get singular values\n","  s = np.linalg.svd(acts)[1]\n","\n","  # percent explained (cumulative)\n","  pctExplained = 100 * s**2 / np.sum(s**2)\n","  cumVarExplained[layeri,:,0] = np.cumsum(pctExplained) # cumulative\n","\n","  # count the components until 95% or 99% variance is explained\n","  effectiveCompCount[layeri,0,0] = np.where(cumVarExplained[layeri,:,0]>95)[0][0]+1\n","  effectiveCompCount[layeri,0,1] = np.where(cumVarExplained[layeri,:,0]>99)[0][0]+1\n","\n","\n","  ### repeat for shuffled tokens\n","  acts = outputs_shuf.hidden_states[layeri].squeeze().cpu().numpy()\n","  acts -= acts.mean(axis=0,keepdims=True)\n","  s = np.linalg.svd(acts)[1] # get singular values\n","  pctExplained = 100 * s**2 / np.sum(s**2) # percent explained\n","  cumVarExplained[layeri,:,1] = np.cumsum(pctExplained) # cumulative\n","  effectiveCompCount[layeri,1,0] = np.where(cumVarExplained[layeri,:,1]>95)[0][0]+1\n","  effectiveCompCount[layeri,1,1] = np.where(cumVarExplained[layeri,:,1]>99)[0][0]+1"],"metadata":{"id":"R8VSmM2OLRPx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OoIRS2pDXXGr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 3: Visualizations"],"metadata":{"id":"q5rD5sniZXJg"}},{"cell_type":"code","source":["# setup the figure and axes\n","_,axs = plt.subplots(1,2,figsize=(12,4))\n","\n","# normalization function for mapping layer index onto color\n","norm = mpl.colors.Normalize(vmin=0,vmax=numHidden)\n","\n","# plt the cumulative variance explained\n","for layeri in range(numHidden):\n","  axs[0].plot(cumVarExplained[layeri,:,0],color=mpl.cm.plasma(norm(layeri)))\n","  axs[1].plot(cumVarExplained[layeri,:,1],color=mpl.cm.plasma(norm(layeri)))\n","\n","for i in range(2):\n","  axs[i].axhline(95,linestyle='--',color='gray')\n","  axs[i].axhline(99,linestyle='--',color='gray')\n","\n","# add colorbars\n","sm = mpl.cm.ScalarMappable(cmap=mpl.cm.plasma,norm=norm)\n","cbar = plt.colorbar(sm,ax=axs[0])\n","cbar.set_label(r'Hidden layer')\n","cbar = plt.colorbar(sm,ax=axs[1])\n","cbar.set_label(r'Hidden layer')\n","\n","# make it look nicer\n","axs[0].set(xlabel='Component number',ylabel='% explained (cumulative)',ylim=[80,100.5],xlim=[-2,900],title='(Real) variance explained')\n","axs[1].set(xlabel='Component number',ylabel='% explained (cumulative)',ylim=[80,100.5],xlim=[-2,900],title='(Shuffled) variance explained')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"N331K6QhSMbN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_9sIWSjqheZj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# convert to percent of total possible dimensionality\n","effectiveCompCountP = 100*effectiveCompCount / len(s)\n","\n","_,axs = plt.subplots(1,2,figsize=(12,4))\n","\n","## plot the \"effective subspace dimensionality\" of the hidden layers\n","for i in range(2):\n","  axs[i].plot(effectiveCompCountP[:,1,i],'ks',markerfacecolor=[.9,.7,.7,.5],markersize=10,label='Shuffled tokens')\n","  axs[i].plot(effectiveCompCountP[:,0,i],'ko',markerfacecolor=[.7,.9,.7],markersize=10,label='Real tokens')\n","  axs[i].legend()\n","  axs[i].set(xlabel='Hidden layer (including embedding)',ylabel='% max dimensionality',\n","             title=f'\"Effective dimensionality\" to reach {[95,99][i]}% total',\n","             ylim=[-1,effectiveCompCountP.max()*1.1],xlim=[-1,numHidden])\n","\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"ECtKGQUlg5zt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"M9RdHCJQkfJD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 4: Other texts"],"metadata":{"id":"Qyzf9-mClHXX"}},{"cell_type":"code","source":["# replace the \"alice\" text in exercise 1 with the following, and then re-run the code\n","\n","# text = requests.get('https://www.gutenberg.org/cache/epub/219/pg219.txt').text # Heart of Darkness\n","# text = requests.get('https://pigeonsarentreal.co.uk/').text # a funny website"],"metadata":{"id":"Sfa2prtglJb6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xUh5H02olHUh"},"execution_count":null,"outputs":[]}]}