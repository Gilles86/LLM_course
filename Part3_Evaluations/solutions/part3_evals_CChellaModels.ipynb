{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyOwy6sRhbZkqS9JnlSTWBcA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 3:</h2>|<h1>Evaluating LLMs<h1>|\n","|<h2>Section:</h2>|<h1>Quantitative evaluations<h1>|\n","|<h2>Lecture:</h2>|<h1><b>CodeChallenge: HellaSwag evals in several models<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"0GM088xUvAc2"}},{"cell_type":"code","source":["# run first to install and then restart\n","# !pip install bitsandbytes\n","# !pip install -U datasets huggingface_hub fsspec"],"metadata":{"id":"17eiuiHHRQFM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jJwR4KcRPF4"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn.functional as F\n","\n","from datasets import load_dataset\n","from tqdm import tqdm # progress bar for for-loops\n","from transformers import AutoTokenizer,AutoModelForCausalLM, BitsAndBytesConfig\n","\n","# vector plots\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","source":[],"metadata":{"id":"bIneion3w4it"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 1: Import and inspect the Zephyr model"],"metadata":{"id":"PBy15L8k1NyK"}},{"cell_type":"code","source":["# tokenizer\n","zephyr_tokenizer = AutoTokenizer.from_pretrained('HuggingFaceH4/zephyr-7b-alpha')\n","\n","# need a BitsAndBytesConfig object\n","quantization_config = BitsAndBytesConfig(\n","    load_in_4bit = True,\n","    bnb_4bit_compute_dtype = 'float16', # multiplication at higher precision\n","    bnb_4bit_use_double_quant = True,   # help preserves accuracy\n",")\n","\n","# import the model\n","zephyr_model = AutoModelForCausalLM.from_pretrained('HuggingFaceH4/zephyr-7b-alpha',\n","    quantization_config = quantization_config)"],"metadata":{"id":"A3tTkzq_Zs7Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["zephyr_model.eval()\n","zephyr_model.to(device)"],"metadata":{"id":"e571MX2pFmtw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6SKHUcW2RJuB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# counting parameters via numel\n","param_total = sum(p.numel() for p in zephyr_model.parameters())\n","param_trainable = sum(p.numel() for p in zephyr_model.parameters() if p.requires_grad)\n","\n","# and manually based on the model description\n","emb   = 32000*4096\n","attn  = 4096**2 + 4096*1024 + 4096*1024 + 4096**2\n","mlp   = 4096*14336*3 + 4096 + 4096\n","unemb = 4096*32000\n","man_total = emb + 32*(attn+mlp) + unemb\n","\n","# print the results\n","print(f'Total parameters: {param_total:13,} ({param_total/1e9:.2f}B)')\n","print(f'Trainable params: {param_trainable:13,}')\n","print(f'Non-trainable   : {param_total-param_trainable:13,}')\n","print(f'Manual counting : {man_total:,} ({man_total/1e9:.2f}B)')"],"metadata":{"id":"h2HvXtuLxwgw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# example\n","zephyr_model.model.layers[4].self_attn.q_proj#.weight.shape[0]/(4096*4096)"],"metadata":{"id":"EWQyn02xXsEl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"NPOOOW6-1jXH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2: A function to test one HellaSwag sample"],"metadata":{"id":"5uObQc2pTKDK"}},{"cell_type":"code","source":["# a function to calculate accuracy on one sample\n","def oneHellaSample(sample,model,tokenizer):\n","\n","  # find context length\n","  context = sample['ctx']\n","  context_len = len( tokenizer.encode(context) )\n","\n","  smSeqs = np.zeros(len(sample['endings']))\n","\n","  # loop over candidate endings, create prompts, get logits, and sum prob scores\n","  for opti in range(len(sample['endings'])):\n","\n","    # prompts and their lengths\n","    prompt = f'{context} {sample[\"endings\"][opti]}'\n","    prompt_tox = tokenizer.encode(prompt,return_tensors='pt')\n","    prompt_len = len( prompt_tox[0] )\n","\n","    # forward pass through the model\n","    with torch.no_grad():\n","      logits = model(prompt_tox.to(device)).logits\n","\n","    # convert to log probabilities\n","    log_probs = F.log_softmax(logits,dim=-1)\n","\n","    # get the predicting log-probs for each token\n","    smSeq = np.array([ log_probs[0,i,prompt_tox[0][i+1]].item() for i in range(0,prompt_len-1)])\n","\n","    # sum log-probabilities to get the total log-likelihood\n","    smSeqs[opti] = np.sum(smSeq)\n","\n","  return smSeqs,int(sample['label'])"],"metadata":{"id":"WooU1ZxfACbf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import the HellaSwag validation set\n","dataset = load_dataset('hellaswag',split='validation',trust_remote_code=True)\n","dataset"],"metadata":{"id":"FC-r6Gzt1N8M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test it with one sample\n","loglikelihoods,answer = oneHellaSample(dataset[42],zephyr_model,zephyr_tokenizer)\n","\n","if np.argmax(loglikelihoods)==answer:\n","  print('Model was correct!')\n","else:\n","  print('Model needs more training ;)')"],"metadata":{"id":"DiyeLM4kACYq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XsvM03i21l86"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 3: Evaluate Zephyr and GPT2-small"],"metadata":{"id":"V2z7eFse1l5O"}},{"cell_type":"code","source":["# import GPT2 and disable normalizations\n","gpt2_model = AutoModelForCausalLM.from_pretrained('gpt2').to(device)\n","gpt2_model.eval()\n","\n","gpt2_tokenizer = AutoTokenizer.from_pretrained('gpt2')"],"metadata":{"id":"Ym93MqZ0wAuj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_samples = 500\n","\n","accuracies = np.zeros((2,num_samples))\n","\n","\n","# loop over data samples with progress bar\n","for datai in tqdm(range(num_samples),desc='Evaluating on HellaSwag'):\n","\n","  # extract one sample from the data\n","  example = dataset[datai]\n","\n","  # ZEPHYR: calculate the loglikelihoods\n","  loglikelihoods,answer = oneHellaSample(example,zephyr_model,zephyr_tokenizer)\n","\n","  if np.argmax(loglikelihoods)==answer:\n","    accuracies[0,datai] = 1\n","  # -------------------------------------\n","\n","\n","  # repeat for GPT2\n","  loglikelihoods,answer = oneHellaSample(example,gpt2_model,gpt2_tokenizer)\n","  if np.argmax(loglikelihoods)==answer:\n","    accuracies[1,datai] = 1\n"],"metadata":{"id":"395s15djF-Ib"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# report the average accuracy\n","print(f'Zepher had {np.mean(accuracies[0,:])*100:.1f}% accuracy.')\n","print(f'  GPT2 had {np.mean(accuracies[1,:])*100:.1f}% accuracy.')"],"metadata":{"id":"p1vqOcLP7K9q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize\n","plt.figure(figsize=(12,3))\n","\n","plt.plot(accuracies[0,:]/2+.03,'ks',markerfacecolor=[.7,.9,.7],alpha=.4,label='Zephyr')\n","plt.plot(accuracies[1,:]/2-.03,'ko',markerfacecolor=[.7,.7,.9],alpha=.4,label='GPT2')\n","\n","plt.legend()\n","plt.gca().set(ylim=[-.2,.75],xlim=[-2,num_samples+1],xlabel='Swag item (index)',\n","              yticks=[0,.5],yticklabels=['Error','Correct'])\n","plt.show()"],"metadata":{"id":"IgGfnvtcw4Zn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3FVeKJlv2SO_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example that Zephyr got and GPT2 missed"],"metadata":{"id":"Y2jAYX2M2SL4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["z_not_g = np.where( (accuracies[0,:]==1) & (accuracies[1,:]==0) )[0]\n","\n","# all the cases\n","z_not_g"],"metadata":{"id":"xiLbclA39DCI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# one particular example\n","dataset[int(z_not_g[-1])]"],"metadata":{"id":"qt6oLr4ZIGGf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2oAkhBv59pmT"},"execution_count":null,"outputs":[]}]}