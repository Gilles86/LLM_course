{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyMK77BmuSWeAKnVMpEqReTt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 3:</h2>|<h1>Evaluating LLMs<h1>|\n","|<h2>Section:</h2>|<h1>Quantitative evaluations<h1>|\n","|<h2>Lecture:</h2>|<h1><b>MAUVE<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"G1fXAKFsIKdK"}},{"cell_type":"code","source":["# run this code, then restart the python session (and then comment it out)\n","# !pip install -U datasets huggingface_hub fsspec"],"metadata":{"id":"8_Y-AmtdIUcC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import requests\n","\n","import torch\n","from transformers import AutoTokenizer,AutoModelForCausalLM\n","\n","from datasets import load_dataset\n","import textwrap\n","\n","# vector plots\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"],"metadata":{"id":"ocJNThBZtJDJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"IyoQSJCCtJAA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import GPT2 and disable normalizations\n","model = AutoModelForCausalLM.from_pretrained('gpt2-large')\n","model.eval()\n","model.to(device)\n","\n","tokenizer = AutoTokenizer.from_pretrained('gpt2')\n","tokenizer.pad_token_id = tokenizer.eos_token_id"],"metadata":{"id":"cHK58CUctI85"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"e06OXJGuim4c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Aggregate human data"],"metadata":{"id":"6RL3lq1rim18"}},{"cell_type":"code","source":["# reference dataset\n","dataset = load_dataset('wikitext','wikitext-2-raw-v1',split='train')\n","dataset"],"metadata":{"id":"n-WhIv0WtOdv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["human_data = []\n","i = 0\n","\n","while len(human_data)<100:\n","\n","  # tokenize this text sample\n","  toks = tokenizer.encode(dataset[i]['text'], return_tensors='pt')[0]\n","\n","  # append the text if there are >200 tokens (but only the first 200)\n","  if len(toks)>200:\n","      human_data.append(tokenizer.decode(toks[:200]))\n","  i += 1 # increment counter\n","\n","human_data"],"metadata":{"id":"AwKIYLb0tOa5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lFKNJp8xAiWB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model data"],"metadata":{"id":"wXVk3voqipg8"}},{"cell_type":"code","source":["model_data = []\n","\n","# 100 samples of 200 tokens each\n","for _ in range(100):\n","  out = model.generate(\n","      torch.tensor([[tokenizer.bos_token_id]]).to(device),\n","      pad_token_id = tokenizer.eos_token_id,\n","      min_length = 200,\n","      max_length = 200,\n","      do_sample  = True,\n","      top_k      = 50,\n","      top_p      = .95,\n","  )\n","  model_data.append(tokenizer.decode(out[0][1:]))"],"metadata":{"id":"Eiqg1hcgxtYN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_data"],"metadata":{"id":"I1YfDPEvipeP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"F_tdSL5oWNEN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MAUVE"],"metadata":{"id":"qNMNSrS5tU1j"}},{"cell_type":"code","source":["!pip install mauve-text\n","import mauve"],"metadata":{"id":"Dl4uPpDLtUyt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dir(mauve)"],"metadata":{"id":"XmRd8pEjtUv0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-l4iSDVzenEX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# calculate MAUVE score\n","mauve_output  = mauve.compute_mauve(\n","    p_text    = model_data, # p is the model's output\n","    q_text    = human_data, # q is human-written text\n","    verbose   = True,\n","    device_id = 0\n",")\n","mauve_output.mauve"],"metadata":{"id":"TAVekFRatdG8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dir(mauve_output)"],"metadata":{"id":"eHm4f-VyvLaZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xl3kBFDU9jO4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_,axs = plt.subplots(1,2,figsize=(10,4))\n","\n","xvals4bar = np.arange(len(mauve_output.p_hist))\n","\n","axs[0].bar(xvals4bar-.15,mauve_output.p_hist,width=.5,label='Human-generated text')\n","axs[0].bar(xvals4bar+.15,mauve_output.q_hist,width=.5,label='Model-generated text')\n","axs[0].set(xlabel='Value (au)',ylabel='Proportion',title='Histograms of quantized distributions',xlim=[-1,len(mauve_output.p_hist)])\n","axs[0].legend()\n","\n","\n","# the divergence curve and the area\n","x = mauve_output.divergence_curve[:,0]\n","y = mauve_output.divergence_curve[:,1]\n","\n","axs[1].plot(x,y,'ko-',markersize=7,markerfacecolor=[.9,.7,.7])\n","axs[1].fill_between(x,y,color=[.7,.7,.9,.5],label=f'AUC = {mauve_output.mauve:.2f}')\n","axs[1].set(title='Divergence curve',xlabel='Model | Human',ylabel='Human | Model',\n","           xlim=[0,1.02],ylim=[0,1.02])\n","axs[1].legend()\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"K55CnhqRvLWw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uVaZNoXf2d-8"},"execution_count":null,"outputs":[]}]}