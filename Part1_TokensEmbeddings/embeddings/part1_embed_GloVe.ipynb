{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNdrMjnXI6oEIuDoPx1a90O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 1:</h2>|<h1>Tokenizations and embeddings<h1>|\n","|<h2>Section:</h2>|<h1>Embedding spaces<h1>|\n","|<h2>Lecture:</h2>|<h1><b>Pretrained embeddings (GloVe)<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"xhhbJ87Vy7yJ"}},{"cell_type":"code","source":["# download a small GloVe model (Wikipedia + Gigaword, 50D)\n","\n","# NOTE: If you get errors importing, run the following !pip... line,\n","# then restart your session (from Runtime menu) and comment out the pip line.\n","# !pip install gensim\n","\n","import gensim.downloader as api\n","glove = api.load('glove-wiki-gigaword-50')"],"metadata":{"id":"Io0sCTA0WcfI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KSKxAmbEWVEn"},"outputs":[],"source":["import numpy as np\n","import scipy\n","import matplotlib.pyplot as plt\n","from matplotlib.gridspec import GridSpec\n","\n","# svg plots\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":[],"metadata":{"id":"Pa2CRvtAwZPa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Explore the glove variable"],"metadata":{"id":"yAtIwgk0wZMh"}},{"cell_type":"code","source":["# check the properties and methods\n","dir(glove)"],"metadata":{"id":"dPa6pXYiWccV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'The dictionary contains {len( glove.key_to_index.keys())} items.' )\n","list(glove.key_to_index.keys())[:50]"],"metadata":{"id":"NhguzmDAW-0n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1FQk8vBxwc3C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Explore the vocab"],"metadata":{"id":"F0QK-KDgwcz_"}},{"cell_type":"code","source":["# print 10 words at random\n","for idx in np.random.randint(0,len(glove.key_to_index),10):\n","  print(f'Index {idx:>6} is \"{glove.index_to_key[idx]}\"')"],"metadata":{"id":"AYV074NVWcWi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# distribution of token character lengths\n","token_lengths = np.zeros(len( glove.key_to_index.keys()),dtype=int)\n","for idx,word in enumerate( glove.key_to_index.keys() ):\n","  token_lengths[idx] = len(word)\n","\n","# counts for the bar plot\n","uniqVals,uniqCounts = np.unique(token_lengths,return_counts=True)\n","\n","\n","# visualize the distribution of lengths\n","plt.figure(figsize=(12,4))\n","plt.bar(uniqVals,np.log(uniqCounts),width=uniqVals[1]-uniqVals[0],facecolor=[.9,.7,.9],edgecolor='k')\n","plt.gca().set(xlabel='Word length (num characters)',ylabel='Count')\n","\n","plt.show()"],"metadata":{"id":"JBZgKWuDzdkY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"HuEsbKyWwfHX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Explore the embeddings matrix"],"metadata":{"id":"uVhblyyOwfCK"}},{"cell_type":"code","source":["# size of the embeddings matrix\n","print(f'The embeddings matrix is {glove.vectors.shape}')\n","\n","print(f'The word \"apple\" has index #{glove.key_to_index[\"apple\"]}')\n","\n","# can also access it this way:\n","glove.get_index('apple')"],"metadata":{"id":"68hqmN0eWcZX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(12,4))\n","plt.imshow(glove.vectors.T,vmin=-1,vmax=1,aspect='auto')\n","plt.gca().set(ylabel='Dimension',xlabel='Word index',title='Embeddings matrix')\n","plt.colorbar(pad=.01)\n","plt.show()"],"metadata":{"id":"-jxiXdr-dpIv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# mean and std across each embedding dim\n","emb_mean = glove.vectors.mean(axis=1)\n","emb_std  = glove.vectors.std(axis=1)\n","\n","\n","# seaborn has nice visualization routines\n","import seaborn as sns\n","import pandas as pd # though seaborn only works on pandas dataframes :/\n","\n","df = pd.DataFrame(np.vstack((emb_mean,emb_std)).T,columns=['Mean','std'])\n","\n","sns.jointplot(x='Mean',y='std',data=df,alpha=.2)\n","plt.show()"],"metadata":{"id":"fzUIGrphv4gA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QV-YabMNWcTl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Explore individual embeddings vectors"],"metadata":{"id":"v3Bb8KAsWcQf"}},{"cell_type":"code","source":["# pick a word\n","word = 'banana'\n","\n","# get its index in the embeddings matrix\n","wordidx = glove.key_to_index[word]\n","\n","# get the embedding vector\n","thisWordVector = glove.vectors[wordidx,:]\n","\n","# inspect the vector\n","print(f'The embedding vector for \"{word}\" is\\n {thisWordVector}')"],"metadata":{"id":"dQsjvRxtZO1T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# even easier ;)\n","thisWordVector = glove[word]\n","\n","print(f'The embedding vector for \"{word}\" is\\n {thisWordVector}')"],"metadata":{"id":"wmXGYRRi3RdZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize it\n","plt.figure(figsize=(10,4))\n","plt.plot(glove.vectors[wordidx,:],'ks',markersize=10,markerfacecolor=[.7,.7,.9])\n","\n","plt.xlabel('Dimension')\n","plt.title(f'Embedding vector for \"{word}\"')\n","plt.show()"],"metadata":{"id":"hOQl-RVFfBOr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fLhZxCHLfCJs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Relationships across embedding vectors"],"metadata":{"id":"edzBOFigfCG9"}},{"cell_type":"code","source":["# pick three words\n","word1 = 'banana'\n","word2 = 'apple'\n","word3 = 'cosmic'\n","\n","\n","# setup the figure subplot geometry\n","fig = plt.figure(figsize=(10,7))\n","gs = GridSpec(2,2)\n","ax0 = fig.add_subplot(gs[0,:])\n","ax1 = fig.add_subplot(gs[1,0])\n","ax2 = fig.add_subplot(gs[1,1])\n","\n","# plot the embeddings by dimension\n","for idx,word in enumerate([word1,word2,word3]):\n","  ax0.plot(glove[word],'s-',label=word)\n","\n","ax0.set(xlabel='Dimension',title='Embeddings',xlim=[-1,glove.vectors.shape[1]+1])\n","ax0.legend()\n","\n","\n","# plot the embeddings by each other\n","cossim = glove.similarity(word1,word2)\n","ax1.plot(glove[word1],glove[word2],'ko',markerfacecolor=[.9,.7,.7])\n","ax1.set(xlabel=word1,ylabel=word2,title=f'Cosine similarity = {cossim:.3f}')\n","\n","cossim = glove.similarity(word1,word3)\n","ax2.plot(glove[word1],glove[word3],'ko',markerfacecolor=[.7,.9,.7])\n","ax2.set(xlabel=word1,ylabel=word3,title=f'Cosine similarity = {cossim:.3f}')\n","\n","# final touches\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"cVLhs2G4WcNq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-wQRZJbeWcKz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Methods to identify similar and dissimilar words"],"metadata":{"id":"PJ3-CHMDsx-b"}},{"cell_type":"code","source":["# most similar words (\"similar\" is high cosine similarity)\n","glove.most_similar('fashion',topn=9)"],"metadata":{"id":"FJFoUIovsx7r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# One these things is not like the others...\n","lists = [ [ 'apple','banana','pirate','peach' ],\n","          [ 'apple','banana','peach','kiwi','starfruit' ],\n","          [ 'apple','banana','pirate','peach','kiwi','starfruit' ],\n","          [ 'apple','banana','orange','kiwi' ]\n","        ]\n","\n","for l in lists:\n","  print(f'In the word list {l}:')\n","  print(f'  The most similar word is \"{glove.most_similar(l,topn=1)[0][0]}\"')\n","  print(f'  and the non-matching word is \"{glove.doesnt_match(l)}\"\\n')"],"metadata":{"id":"JCm3OfJJsx40"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3XqLJMk5sxzi"},"execution_count":null,"outputs":[]}]}