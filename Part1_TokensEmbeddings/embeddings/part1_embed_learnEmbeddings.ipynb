{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyP6AyqYHl0Qqs2G8IPwSAgh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 1:</h2>|<h1>Tokenizations and embeddings<h1>|\n","|<h2>Section:</h2>|<h1>Embedding spaces<h1>|\n","|<h2>Lecture:</h2>|<h1><b>Multiple videos on learning embeddings<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">udemy.com/course/dulm_x/?couponCode=202509</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"4UImGHr167rz"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"M4yt0kA6wtGu"},"outputs":[],"source":["# typical libraries...\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","\n","# for importing and working with texts\n","import requests\n","import re\n","import string\n","\n","# pytorch stuff\n","from torch.utils.data import Dataset, DataLoader\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","!pip install torchinfo # not installed by default in colab\n","from torchinfo import summary\n","\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":[],"metadata":{"id":"F0_NnImhx-Tx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Code below is for video \"Create a data loader to train a model\"**"],"metadata":{"id":"Cj0Z4gaX04p7"}},{"cell_type":"code","source":[],"metadata":{"id":"MBfV3Iaq082j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Import text and create dictionary"],"metadata":{"id":"tNMIerWSxqQU"}},{"cell_type":"code","source":["# get raw text from internet (The Time Machine... yeah I use it a lot :P  )\n","text = requests.get('https://www.gutenberg.org/files/35/35-0.txt').text\n","# character strings to replace with space\n","strings2replace = [ '\\r\\n\\r\\nâ\\x80\\x9c','â\\x80\\x9c','â\\x80\\x9d','\\r\\n','â\\x80\\x94','â\\x80\\x99','â\\x80\\x98','_', ]\n","\n","# use regular expression (re) to replace those strings with space\n","for str2match in strings2replace:\n","  text = re.compile(r'%s'%str2match).sub(' ',text)\n","\n","# remove non-ASCII characters and numbers, and make lower-case\n","text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n","text = re.sub('\\d+','',text).lower()\n","\n","# split into words with >1 letter\n","words = re.split(f'[{string.punctuation}\\s]+',text)\n","words = [item.strip() for item in words if item.strip()]\n","words = [item for item in words if len(item)>1]\n","\n","# create the vocabulary (lexicon)\n","vocab  = sorted(set(words))\n","nWords = len(words)\n","nVocab = len(vocab)\n","\n","# encoder/decoder look-up-tables (as python dictionaries)\n","word2idx = {w:i for i,w in enumerate(vocab)}\n","idx2word = {i:w for i,w in enumerate(vocab)}\n","\n","# show a few keys in the dictionary\n","print(f'The book contains {nWords:,} words, {nVocab:,} of which are unique and comprise the vocab.')\n","print(f'\\n\\nFirst 10 vocab words:\\n',list(word2idx.keys())[:10])"],"metadata":{"id":"EPRfkKgHLEsE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9_TCDyH2yCkb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# parameters for dataset\n","context_length = 8 # context length\n","stride = 2 # skipping\n","\n","# initialize\n","inputs  = []\n","targets = []\n","\n","# overlapping sequences of context_length\n","for i in range(0,nWords-context_length,stride):\n","\n","  # get a few words\n","  in_seq   = words[i  : i+context_length  ]\n","  targ_seq = words[i+1: i+context_length+1]\n","\n","  # append to the lists\n","  inputs.append([word2idx[w] for w in in_seq])\n","  targets.append([word2idx[w] for w in targ_seq])\n","\n","print(inputs[123])\n","print(targets[123])"],"metadata":{"id":"ra0shrASyCgg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# a closer look:\n","print('Inputs: ',inputs[4])\n","print('Targets:',targets[4])\n","print('')\n","print('Inputs :',inputs[5])\n","print('Targets:',targets[5])\n","# this is what we need, although we need it in torch Dataset/DataLoader format"],"metadata":{"id":"gwuxQsr8yCc5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# we need each list to be a tensor\n","torch.tensor(inputs[4])"],"metadata":{"id":"neAkNSsXyCZe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"j8T-gDu-ymvo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Create a class for a dataset object"],"metadata":{"id":"x6leLgJyymzV"}},{"cell_type":"code","source":["# create a class for a dataset\n","class WordDataset(Dataset):\n","  def __init__(self, text, word2idx, context_length=8, stride=4):\n","\n","    # initialize\n","    self.inputs  = []\n","    self.targets = []\n","    self.word2idx = word2idx  # stored locally in the object\n","\n","    # overlapping sequences of context_length\n","    for i in range(0,len(text)-context_length,stride):\n","\n","      # get a few words\n","      in_seq   = text[i : i+context_length]\n","      targ_seq = text[i+1 : i+context_length+1]\n","\n","      # append to the lists\n","      self.inputs.append(torch.tensor([word2idx[w] for w in in_seq]))\n","      self.targets.append(torch.tensor([word2idx[w] for w in targ_seq]))\n","\n","  def __len__(self):\n","    return len(self.inputs)\n","\n","  def __getitem__(self, idx):\n","    return self.inputs[idx], self.targets[idx]\n","\n","\n","# create an instance!\n","context_length = 6 # context length\n","stride = 3 # skipping over tokens\n","text_dataset = WordDataset(words,word2idx,context_length,stride)\n","\n","text_dataset[4]"],"metadata":{"id":"J4NctFIlGyhK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"m5UdAWBRz4BA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## And a dataloader for training"],"metadata":{"id":"0UlFizlrz3-A"}},{"cell_type":"code","source":["# also need a dataloader\n","dataloader = DataLoader(\n","                text_dataset,\n","                batch_size = 32, # 2 for looking; 32 for training\n","                shuffle    = True,\n","                drop_last  = True\n","            )\n","\n","# let's have a look at the indices\n","X,y = next(iter(dataloader))\n","print('Inputs:')\n","print(X), print('')\n","\n","print('Targets:')\n","print(y), print('\\n\\n\\n')\n","\n","# and the words\n","print('Inputs in words (first batch):')\n","print([idx2word[item.item()] for item in X[0]])\n","print('')\n","\n","print('Targets in words (first batch):')\n","print([idx2word[item.item()] for item in y[0]])"],"metadata":{"id":"tfRohf_XGykQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"euxnrW7Vym2m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Code below is for video \"Build a model to learn the embeddings\"**"],"metadata":{"id":"5GX24waQyCVz"}},{"cell_type":"code","source":["# exploring dimensionality based on vocab sizes\n","\n","# vocab sizes\n","N = np.logspace(np.log10(1000),np.log10(100000),23)\n","\n","# heuristic for non-LLM models like word2vec or glove:\n","embdim = np.sqrt(N)\n","\n","# parameters for GPT2\n","gpt2dims = [ 50257,768 ]\n","\n","plt.figure(figsize=(8,4))\n","\n","# heuristic line\n","plt.plot(N,embdim,'ks-',markersize=8,markerfacecolor=[.9,.7,.7],label=r'$s = \\sqrt{N}$')\n","\n","# expected embedding dim for GPT2\n","plt.plot([gpt2dims[0],gpt2dims[0]],[0,np.sqrt(gpt2dims[0])],'k--',linewidth=1,label='Expected GPT2')\n","plt.plot([0,gpt2dims[0]],[np.sqrt(gpt2dims[0]),np.sqrt(gpt2dims[0])],'k--',linewidth=1)\n","\n","# actual GPT2 embedding\n","plt.plot([gpt2dims[0],gpt2dims[0]],[0,gpt2dims[1]],'b:',linewidth=1,label='Actual GPT2')\n","plt.plot([0,gpt2dims[0]],[gpt2dims[1],gpt2dims[1]],'b:',linewidth=1)\n","\n","plt.gca().set(xlabel='Vocab size',ylabel='Embeddings dimensions',\n","              xlim=[-100,N[-1]+2000],ylim=[0,None])\n","plt.legend()\n","plt.show()"],"metadata":{"id":"4fJdqoMgHrV6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"l9_wXkjWHrQE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Create and explore an embedding layer"],"metadata":{"id":"mDvqf1Ttd3Uw"}},{"cell_type":"code","source":["# dimensionality of embedding space (arbitrarily set to 100)\n","embeddingDimension = 100\n","\n","# create a random embedding\n","embedding_layer = nn.Embedding(nVocab,embeddingDimension)\n","\n","# let's see its size\n","embedding_layer.weight.shape"],"metadata":{"id":"NOImevDUd5hk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# what does it look like?\n","\n","_,axs = plt.subplots(1,2,figsize=(12,4))\n","axs[0].imshow(embedding_layer.weight.detach().T,aspect='auto',vmin=-1,vmax=1)\n","axs[0].set(ylabel='Embedding dimension',xlabel='Token index',title='Entire embedding matrix')\n","\n","# pick a word at random\n","aRandomWord = np.random.choice(vocab)\n","\n","# plot its embedding\n","axs[1].plot(embedding_layer.weight.detach()[word2idx[aRandomWord],:],'ks',markerfacecolor=[.7,.9,.7])\n","axs[0].axvline(word2idx[aRandomWord],color='w',linestyle='--')\n","axs[1].set(xlabel='Embedding dimension',ylabel='Weight value',title=f'Embedding for \"{aRandomWord}\" (idx = {word2idx[aRandomWord]})')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"KX77I315d3XZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"og0TEkjPReRs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# embeddings for closely related words\n","word1 = 'time'\n","word2 = 'machine'\n","\n","# their embeddings\n","embed1 = embedding_layer.weight.detach()[word2idx[word1],:]\n","embed2 = embedding_layer.weight.detach()[word2idx[word2],:]\n","\n","# cosine similiarity between them\n","cosSim = torch.dot(embed1,embed2)/(torch.norm(embed1)*torch.norm(embed2))\n","\n","# vizualize\n","plt.plot(embed1,embed2,'ks',markerfacecolor=[.7,.9,.7],alpha=.6)\n","plt.gca().set(xlabel=f'Embedding for \"{word1}\"',ylabel=f'Embedding for \"{word2}\"',\n","              title=f'Cosine similarity: {cosSim:.3f}')\n","plt.show()"],"metadata":{"id":"IMv9FiDAiKBO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"g-1l0hJL0-nn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Build the model"],"metadata":{"id":"tfIHOi-KHXMS"}},{"cell_type":"code","source":["class EmbeddingModel(nn.Module):\n","  def __init__(self, vocab_size, embedding_dim, context_size):\n","    super(EmbeddingModel, self).__init__()\n","\n","    # embedding layer\n","    self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n","\n","    # linear layers\n","    self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n","    self.linear2 = nn.Linear(128, vocab_size)\n","\n","  def forward(self, inputs):\n","\n","    # extract and flatten embeddings [batch_size, context_size * embedding_dim]\n","    embeds = self.embeddings(inputs).view(inputs.shape[0],-1)\n","\n","    # fully connected layers\n","    out = F.relu(self.linear1(embeds))\n","    out = self.linear2(out)\n","\n","    # log softmax for classification (note: NLLLoss expects logprobs as inputs)\n","    log_probs = F.log_softmax(out, dim=1)\n","    return log_probs\n","\n","\n","# create a model instance!\n","model = EmbeddingModel(vocab_size=nVocab, embedding_dim=embeddingDimension, context_size=context_length)\n","print(model)\n","\n","# apply Xavier weight distribution\n","for param in model.parameters():\n","  if param.dim()>1: # also excludes biases\n","    nn.init.xavier_normal_(param)"],"metadata":{"id":"--fKDPmYns8P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# let's test the model\n","\n","X,y = next(iter(dataloader))\n","modelOut = model(X)\n","\n","print('Input to model:')\n","print(X), print('')\n","\n","print(f'Output from model (size: {list(modelOut.detach().shape)}):')\n","print(modelOut)"],"metadata":{"id":"xjQ34R6Lskc2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# log soft-max output:\n","print(modelOut.detach()[0])\n","print('')\n","\n","# shouldn't the sum be 1?\n","print(f'Log softmax sum = {modelOut.detach()[0].sum():.3f}')\n","\n","# ah, it's *log* softmax :D\n","print(f'exp(log(softmax)) sum = {torch.exp(modelOut.detach()[0]).sum():.3f}')"],"metadata":{"id":"hXgPuzyFsvdG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# find the word with the highest probability\n","print('Model input:')\n","print([idx2word[w.item()] for w in X[0]])\n","print('')\n","\n","print('Model output:')\n","print(idx2word[modelOut[0].argmax().item()])"],"metadata":{"id":"bgOriLFHt3vb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(modelOut[0].detach(),'o');"],"metadata":{"id":"W8E_NyL98Jcz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Have the model generate text"],"metadata":{"id":"fSpQM4vn8Jzk"}},{"cell_type":"code","source":["# grab some data from the loader\n","X,y = next(iter(dataloader))\n","\n","print('First input:')\n","print(' '.join([idx2word[w.item()] for w in X[0]]))\n","print('\\nSubsequent inputs:')\n","\n","# text generation\n","for _ in range(context_length):\n","\n","  # get output for this input\n","  Y = model(X)\n","\n","  # pick the most likely next word\n","  nextWord = Y[0].argmax().item()\n","\n","  # create new input for the next iteration (word)\n","  X[0] = torch.concatenate((X[0][1:],torch.tensor([nextWord])))\n","\n","  # print out the generated text so far\n","  print(' '.join([idx2word[w.item()] for w in X[0]]))"],"metadata":{"id":"RrBSScdw3RQN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uWl8IMwA3RKB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## How big is our model?"],"metadata":{"id":"0LmtGo2q8_gi"}},{"cell_type":"code","source":["# summary of model and parameters\n","summary(model, input_data=X, col_names=['input_size','output_size','num_params'])"],"metadata":{"id":"7Ct2HcS0HYNK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vJ1wUpj00-ko"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Adz4XYKW0-hg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Code below is for video \"Train and evaluate the model\"**"],"metadata":{"id":"7a54n_yx9S_k"}},{"cell_type":"code","source":["# we'll use the GPU for speed\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f'Using device: {device}')"],"metadata":{"id":"c4Vvuq-p0-b8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a fresh model instance\n","model = EmbeddingModel(vocab_size=nVocab, embedding_dim=embeddingDimension, context_size=context_length)\n","\n","# with Xavier weight distribution\n","for param in model.parameters():\n","  if param.dim()>1: nn.init.xavier_normal_(param)\n","\n","\n","# and move it to the GPU\n","model = model.to(device)"],"metadata":{"id":"O1Ulfu-N53Wp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create the loss and optimizer functions\n","loss_function = nn.NLLLoss().to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=.001, weight_decay=.01)"],"metadata":{"id":"3hlpVjic6oVa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# quick test for errors and sanity-check the output matrix sizes\n","X,y = next(iter(dataloader))\n","X,y = X.to(device), y.to(device)\n","\n","# forward pass\n","modelOutput = model(X)\n","\n","# check the sizes\n","print(f'Model input is of size: {X.shape}')\n","print(f'Target output is of size: {y.shape}')\n","print(f'Model output is of size: {modelOutput.shape}')\n","\n","# loss function\n","loss = loss_function(modelOutput,y[:,-1])\n","print(f'\\nLoss:')\n","loss"],"metadata":{"id":"-B-QSF6xzY8t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# extract the pretrained embedding weights for comparison later\n","pretrained_embeddings = model.embeddings.weight.detach().cpu()"],"metadata":{"id":"jzlgZNND_sgs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# reminder: use batchsize=32 in data loader ;)"],"metadata":{"id":"_uGwrosX-s_W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"C-XuGYYZ0oBy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Now train the model!"],"metadata":{"id":"gICE2otK-s89"}},{"cell_type":"code","source":["def trainTheModel(model,num_epochs=25):\n","\n","  # initialize losses\n","  total_loss = np.zeros(num_epochs)\n","\n","  for epoch in range(num_epochs):\n","\n","    # initialize\n","    epoch_loss = 0\n","\n","    # loop over batches in the data loader\n","    for X,y in dataloader:\n","\n","      # move data to GPU\n","      X,y = X.to(device), y.to(device)\n","\n","      # clear previous gradients\n","      model.zero_grad()\n","\n","      # forward pass\n","      log_probs = model(X)\n","\n","      # calculate the losses from the final target word\n","      loss = loss_function(log_probs,y[:,-1])\n","\n","      # backprop\n","      loss.backward()\n","      optimizer.step()\n","\n","      # sum the per-epoch losses\n","      epoch_loss += loss.item()\n","\n","    # scale by the number of tokens in this dataloader\n","    total_loss[epoch] = epoch_loss / len(dataloader.dataset)\n","\n","    # update our progress :)\n","    print(f'  Finished epoch {epoch+1} with loss {epoch_loss / len(dataloader.dataset):.4f}')\n","\n","  # output the model and the losses\n","  return model,total_loss"],"metadata":{"id":"WUYuqpThHZL5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train the model!\n","model,total_loss = trainTheModel(model) # using default 25 epochs\n","\n","# plot the losses\n","plt.figure(figsize=(10,3))\n","plt.plot(total_loss,'ks-',markerfacecolor='w',markersize=8)\n","plt.gca().set(xlabel='Epoch',ylabel='Loss')\n","plt.show()"],"metadata":{"id":"5XdjwacoHZOi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get the trained weights\n","postrained_embeddings = model.embeddings.weight.detach().cpu()"],"metadata":{"id":"VqWnA1sj_pJ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3ov_EOYK014t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7DWGuVGoWmue"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"95pu02kuWmq3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zjm2u2uqWmlI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yDwHQPFFWmiM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iVP5sz_SWmfS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plenty of empty space so you won't look by accident :P"],"metadata":{"id":"xmsjk7-BWgMF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gDZpLzQZWgJX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1MeICytWWgGr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AEVUOJoyWgEB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bilpY5XwWgBc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"CItqR8UGWf-b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8o-ytlcAWf5U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vzy0HzK9Wf2h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"w9lvsWKPDgrS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Code below is for video \"CodeChallenge: How the embeddings change\"**"],"metadata":{"id":"jXIcg6-WDjyt"}},{"cell_type":"markdown","source":["## Exercise 1: distributions of embeddings"],"metadata":{"id":"c3g-359cEEjc"}},{"cell_type":"code","source":["# histograms via numpy\n","yPre,xPre = np.histogram(pretrained_embeddings.flatten(),bins=50)\n","yPst,xPst = np.histogram(postrained_embeddings.flatten(),bins=50)\n","\n","# recalculate x values as bin centers\n","xPre = (xPre[1:]+xPre[:-1]) / 2\n","xPst = (xPst[1:]+xPst[:-1]) / 2\n","\n","# and plot\n","plt.figure(figsize=(12,5))\n","plt.bar(xPst,yPst,width=xPst[1]-xPst[0],color=[.7,.9,.7,.7],edgecolor=[.3,.6,0,.4],label='POSTtrain')\n","plt.bar(xPre,yPre,width=xPre[1]-xPre[0],color=[.9,.7,.7,.3],edgecolor=[.6,0,.3,.4],label='PREtrain')\n","\n","plt.gca().set(xlabel='Weight value',ylabel='Count',title='Distributions of embedding weights')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"tUg89F5iEFaX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GRWkVmfJEFX7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Exercise 2: Embeddings vectors for a random word"],"metadata":{"id":"Pe1U-JRpHZnX"}},{"cell_type":"code","source":["# pick a word at random\n","aRandomWord = np.random.choice(vocab)\n","randWord_idx = word2idx[aRandomWord]\n","\n","# extract its embeddings vectors\n","pre_ev = pretrained_embeddings[randWord_idx,:]\n","pst_ev = postrained_embeddings[randWord_idx,:]\n","\n","\n","\n","_,axs = plt.subplots(2,2,figsize=(10,7))\n","\n","# the pretrainined embeddings\n","axs[0,0].imshow(pretrained_embeddings.T,aspect='auto',vmin=-.2,vmax=.2)\n","axs[0,0].set(ylabel='Embedding dimension',xlabel='Token index',title='PREtrain embedding matrix')\n","\n","# the post-trainined embeddings\n","axs[0,1].imshow(postrained_embeddings.T,aspect='auto',vmin=-.2,vmax=.2)\n","axs[0,1].set(ylabel='Embedding dimension',xlabel='Token index',title='POSTtrain embedding matrix')\n","\n","\n","axs[0,0].axvline(randWord_idx,linestyle='--',color=[.8,.8,.8])\n","axs[0,1].axvline(randWord_idx,linestyle='--',color=[.8,.8,.8])\n","\n","# plot its embedding\n","axs[1,0].plot(pre_ev,'ks-',markerfacecolor=[.7,.9,.7],label='PREtrain')\n","axs[1,0].plot(pst_ev,'ko-',markerfacecolor=[.9,.7,.7],label='POSTtrain')\n","axs[1,0].set(xlabel='Embedding dimension',ylabel='Weight value',title=f'\"{aRandomWord}\" embedding (idx={randWord_idx})')\n","axs[1,0].legend(fontsize=8)\n","\n","# how it changed\n","axlim = max(abs(pre_ev).max(),abs(pst_ev).max()) * 1.1 # equal axis limits\n","axs[1,1].plot(pre_ev,pst_ev,'ks',markerfacecolor=[.9,.7,.9])\n","axs[1,1].set(xlim=[-axlim,axlim],ylim=[-axlim,axlim],xlabel='PREtrain embedding',\n","             ylabel='POSTtrain embedding',title='Change in embedding')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"6dc3qZeSGyq_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lVduMOm8CroI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Exercise 3: Time Machine embeddings"],"metadata":{"id":"lUZbdF41Creo"}},{"cell_type":"code","source":["# embeddings for closely related words\n","word1 = 'time'\n","word2 = 'machine'\n","\n","# their embeddings\n","embed1pre = pretrained_embeddings[word2idx[word1],:]\n","embed2pre = pretrained_embeddings[word2idx[word2],:]\n","embed1pst = postrained_embeddings[word2idx[word1],:]\n","embed2pst = postrained_embeddings[word2idx[word2],:]\n","\n","# cosine similarity between them\n","cosSim_pre = F.cosine_similarity(embed1pre.unsqueeze(dim=0),embed2pre.view(1,-1))\n","cosSim_pst = nn.functional.cosine_similarity(embed1pst.unsqueeze(dim=0),embed2pst.view(1,-1))\n","\n","\n","# vizualize\n","_,axs = plt.subplots(1,2,figsize=(10,4))\n","\n","axlim = torch.cat((abs(embed1pre),abs(embed2pre),abs(embed1pst),abs(embed2pst))).max() * 1.1\n","axs[0].plot(embed1pre,embed2pre,'ks',markerfacecolor=[.9,.7,.7],alpha=.6)\n","axs[0].set(xlim=[-axlim,axlim],ylim=[-axlim,axlim],xlabel=f'\"{word1}\" embedding',\n","           ylabel=f'\"{word2}\" embedding',title=f'Cosine similarity PREtrain: {cosSim_pre.item():.3f}')\n","\n","axs[1].plot(embed1pst,embed2pst,'ko',markerfacecolor=[.7,.9,.7])\n","axs[1].set(xlim=[-axlim,axlim],ylim=[-axlim,axlim],xlabel=f'\"{word1}\" embedding',\n","           ylabel=f'\"{word2}\" embedding',title=f'Cosine similarity POSTtrain: {cosSim_pst.item():.3f}')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"V9BQM5ZOGyuW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# cosine similarity manually\n","num = torch.dot(embed1pst,embed2pst)\n","den = torch.norm(embed1pst)*torch.norm(embed2pst)\n","cs_man = num / den\n","\n","# and via pytorch\n","cs_pyt = F.cosine_similarity(embed2pst.unsqueeze(dim=0),embed1pst.view(1,-1))\n","\n","print(f'Cosine similarity from numpy: {cs_man:.4f}')\n","print(f'Cosine similarity from torch: {cs_pyt.item():.4f}')"],"metadata":{"id":"KGGhvH2aJUQM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"R_CHZ4j4hAzt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vuxujljI9XoA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Code below is for video \"CodeChallenge: How stable are embeddings?\"**"],"metadata":{"id":"ePq4WtnDTxhN"}},{"cell_type":"markdown","source":["## Exercise 1: New training, different weights"],"metadata":{"id":"ntf01OMW9XlR"}},{"cell_type":"code","source":["# number of repetitions (new models) and epochs\n","numRepetitions = 10\n","numEpochs = 16\n","\n","# initializations\n","lossesMatrix = np.zeros((numRepetitions,numEpochs))\n","embeddingsMats = []\n","\n","# loop over repetitions\n","for repi in range(numRepetitions):\n","\n","  # create a new model\n","  model = EmbeddingModel(vocab_size=nVocab, embedding_dim=embeddingDimension, context_size=context_length)\n","  model = model.to(device)\n","  for param in model.parameters():\n","    if param.dim()>1: nn.init.xavier_normal_(param)\n","\n","  # need to recreate the optimizer b/c it retains gradient/overhead info\n","  optimizer = torch.optim.AdamW(model.parameters(), lr=.001, weight_decay=.01)\n","\n","  # train the model\n","  print(f'** Running repetition {repi+1}/{numRepetitions} **')\n","  model,total_loss = trainTheModel(model,numEpochs)\n","  print('\\n')\n","\n","  # get its losses\n","  lossesMatrix[repi,:] = total_loss\n","\n","  # extract the embedding matrix\n","  embeddingsMats.append( model.embeddings.weight.detach().cpu() )"],"metadata":{"id":"96wla6_U9XiT","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6sbv03nlsRx9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot the losses\n","plt.figure(figsize=(10,4))\n","\n","# in a for-loop to get different colors\n","for i in range(numRepetitions):\n","  plt.plot(lossesMatrix[i,:],'s-',linewidth=2,color=mpl.cm.plasma(i/numRepetitions),label=f'Rep. {i+1}')\n","\n","plt.legend()\n","plt.gca().set(xticks=range(numEpochs),xlabel='Training epochs',ylabel='Losses')\n","plt.show()"],"metadata":{"id":"U82fpG6o9XcS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Xfv5zY3igtFd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Exercise 2: Consistency of embedding vectors"],"metadata":{"id":"9ErfcPCrkQd4"}},{"cell_type":"code","source":["_,axs = plt.subplots(3,2,figsize=(14,8))\n","\n","# random words\n","randWords = np.random.choice(vocab,size=np.prod(axs.shape))\n","\n","# but what do individual embeddings look like?\n","for wordi,ax in enumerate(axs.flatten()):\n","\n","  # index of this random word\n","  randWord_idx = word2idx[randWords[wordi]]\n","\n","  # loop over the repetitions\n","  for repi in range(numRepetitions):\n","\n","    # draw lines for embeddings in each repetition\n","    ax.plot(embeddingsMats[repi][randWord_idx,:])\n","\n","  # title of this subplot\n","  ax.set_title(f'\"{randWords[wordi]}\" embedding',fontsize=14)\n","\n","\n","# final adjustments\n","for a in axs.flatten(): a.set(xticks=[],yticks=[],xlim=[-1,embeddingDimension])\n","ax.set(xlabel='Embedding dimension',ylabel='Weight value')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"4EIevtQ19XTw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8LfgU3voiisf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Exercise 3: Cosine similarity for selected word pairs"],"metadata":{"id":"-fHmrYfBiipo"}},{"cell_type":"code","source":["# pick three words\n","word1 = 'time'\n","word2 = 'machine'\n","word3 = 'she'\n","\n","# vector of cosine similarity for each repetition\n","cossim = np.zeros((numRepetitions,3))\n","\n","# and the for-loop!\n","for repi in range(numRepetitions):\n","\n","  # their embeddings\n","  e1 = embeddingsMats[repi][word2idx[word1],:]\n","  e2 = embeddingsMats[repi][word2idx[word2],:]\n","  e3 = embeddingsMats[repi][word2idx[word3],:]\n","\n","  # cosine similarity between each pair\n","  cossim[repi,0] = nn.functional.cosine_similarity(e1,e2.view(1,-1)).item()\n","  cossim[repi,1] = nn.functional.cosine_similarity(e1,e3.view(1,-1)).item()\n","  cossim[repi,2] = nn.functional.cosine_similarity(e2,e3.view(1,-1)).item()\n","\n","\n","# the plot\n","plt.figure(figsize=(10,4))\n","plt.plot(cossim[:,0],'ks',markerfacecolor=[.9,.7,.7],markersize=12,label=f'\"{word1}\" and \"{word2}\"')\n","plt.plot(cossim[:,1],'ko',markerfacecolor=[.7,.8,.7],markersize=12,label=f'\"{word1}\" and \"{word3}\"')\n","plt.plot(cossim[:,2],'k^',markerfacecolor=[.7,.7,.8],markersize=12,label=f'\"{word2}\" and \"{word3}\"')\n","\n","plt.axhline(0,color=[.7,.7,.7],linestyle='--',zorder=-10)\n","plt.gca().set(xticks=range(numRepetitions),ylim=[-.4,.6],\n","              xlabel='Training repetition',ylabel='Cosine similarity',title='Cosine similarities')\n","plt.legend()\n","\n","plt.show()"],"metadata":{"id":"wumkmXBp9XWh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_0VV__Hd9XQn"},"execution_count":null,"outputs":[]}]}