{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPwKoz3VbpXkhz7QeKBiTON"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 1:</h2>|<h1>Tokenizations and embeddings<h1>|\n","|<h2>Section:</h2>|<h1>Embedding spaces<h1>|\n","|<h2>Lecture:</h2>|<h1><b>CodeChallenge: Exploring position embeddings</b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"3UI_HsUuYM7E"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qliPUVxwuvWm"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":[],"metadata":{"id":"mmR6IaAwvI_T"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import GPT-2 model and extract its position embedding matrix"],"metadata":{"id":"P9S0TmkovI8n"}},{"cell_type":"code","source":["from transformers import GPT2Model\n","\n","# get the Word Position Embeddings matrix\n","gpt2 = GPT2Model.from_pretrained('gpt2')\n","positions = gpt2.wpe.weight.detach().numpy()"],"metadata":{"id":"B7PftXi1u5nh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_TRPFIc1alGb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 1: Histogram of embeddings cosine similarities"],"metadata":{"id":"QJzppiz6YRH_"}},{"cell_type":"code","source":["# copied from \"embed_positionEmbeddings.ipynb\"\n","\n","# cosine similarities for \"time series\" (token index)\n","Pnorm1 = positions / np.linalg.norm(positions,axis=1,keepdims=True)\n","cossim_tokens = Pnorm1 @ Pnorm1.T\n","\n","# cosine similarities across embedding dimensions\n","Pnorm0 = positions / np.linalg.norm(positions,axis=0,keepdims=True)\n","cossim_embeds = Pnorm0.T @ Pnorm0"],"metadata":{"id":"70q51F4ealD9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# draw the images (also copied from previous code file)\n","fig,axs = plt.subplots(1,2,figsize=(12,5))\n","\n","h = axs[0].imshow(cossim_tokens,vmin=-1,vmax=1)\n","axs[0].set(xlabel='Token index (\"time\")',ylabel='Token index (\"time\")',title='$S_c$ over \"time\"')\n","ch = fig.colorbar(h,ax=axs[0],pad=.02,fraction=.046)\n","ch.ax.tick_params(labelsize=10)\n","ch.ax.set_yticks(np.arange(-1,1.1,.5))\n","\n","h = axs[1].imshow(cossim_embeds,vmin=-1,vmax=1)\n","axs[1].set(xlabel='Embedding index',ylabel='Embedding index',title='$S_c$ across embeddings')\n","ch = fig.colorbar(h,ax=axs[1],pad=.02,fraction=.046)\n","ch.ax.tick_params(labelsize=10)\n","ch.ax.set_yticks(np.arange(-1,1.1,.5))\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"IJmYwVal_uYC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# small demo about triu:\n","A = np.random.randint(0,9,(4,4))\n","print(A)\n","print('')\n","A[np.nonzero(np.triu(A,1))]"],"metadata":{"id":"30sEROCu8h0l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get the unique cosine similarity values from the upper-triangle\n","unique_cs_embeds = cossim_embeds[np.nonzero(np.triu(cossim_embeds,1))] # note the \",1\" to avoid the trivial diagonal\n","unique_cs_tokens = cossim_tokens[np.nonzero(np.triu(cossim_tokens,1))]\n","\n","# get their distributions\n","embed_hy,embed_hx = np.histogram(unique_cs_embeds,100)\n","token_hy,token_hx = np.histogram(unique_cs_tokens,100)\n","\n","# visualize!\n","plt.figure(figsize=(12,4))\n","plt.bar(embed_hx[:-1],embed_hy,width=np.diff(embed_hx[:2]),alpha=.4,label='$S_c$ across embeddings')\n","plt.bar(token_hx[:-1],token_hy,width=np.diff(token_hx[:2]),alpha=.4,label='$S_c$ across \"time\"')\n","plt.plot(embed_hx[:-1],embed_hy)\n","plt.plot(token_hx[:-1],token_hy)\n","\n","plt.legend()\n","plt.gca().set(xlim=[-1,1],xlabel='Cosine similarity',ylabel='Count',title='Distributions of $S_c$ in the positional embeddings matrix')\n","plt.show()"],"metadata":{"id":"aZTzpWfHmvCi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9zEvfw_DYRFI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2: Create a shuffled cosine similarity distribution"],"metadata":{"id":"VYXSv_Ihl1cU"}},{"cell_type":"code","source":["# vectorize and copy the positions\n","randomEmbeds = positions.flatten()\n","\n","# randomly shuffle them\n","np.random.shuffle(randomEmbeds)\n","\n","# reshape back to the matrix\n","randomEmbeds = randomEmbeds.reshape(positions.shape)\n"],"metadata":{"id":"rwOzpkngqTAI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["_,axs = plt.subplots(2,1,figsize=(8,7))\n","\n","axs[0].imshow(positions.T,aspect='auto',vmin=-.1,vmax=.1)\n","axs[0].set(xlabel='Token position',ylabel='Dimensions',title='GPT-2 position embeddings matrix')\n","\n","axs[1].imshow(randomEmbeds.T,aspect='auto',vmin=-.1,vmax=.1)\n","axs[1].set(xlabel='Token position',ylabel='Dimensions',title='Shuffled embeddings matrix')\n","\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"yuRYgDiwPxpv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# calculate cosine similarity\n","Rnorm0 = randomEmbeds / np.linalg.norm(randomEmbeds,axis=0,keepdims=True)\n","cossim_random = Rnorm0.T @ Rnorm0"],"metadata":{"id":"lcMBM2dNPxEs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get the unique cosine similarity values from the upper-triangle\n","unique_cs_random = cossim_random[np.nonzero(np.triu(cossim_random,1))]\n","\n","# get their distribution\n","random_hy,random_hx = np.histogram(unique_cs_random,100)\n","\n","# visualize!\n","plt.figure(figsize=(12,4))\n","plt.bar(embed_hx[:-1],embed_hy,width=np.diff(embed_hx[:2]),alpha=.4,label='$S_c$ across embeddings')\n","plt.bar(random_hx[:-1],random_hy,width=np.diff(random_hx[:2]),alpha=.4,label='$S_c$ in shuffled vectors')\n","plt.plot(embed_hx[:-1],embed_hy)\n","plt.plot(random_hx[:-1],random_hy)\n","\n","plt.legend()\n","plt.gca().set(xlim=[-1,1],xlabel='Cosine similarity',ylabel='Count',title='Distributions of $S_c$ in the positional embeddings matrix')\n","plt.show()"],"metadata":{"id":"vNbqLJNHl1X9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IFFEkA30l1Rm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 3: Find similar pairs"],"metadata":{"id":"ppOIlNECl1O5"}},{"cell_type":"code","source":["# reminder: positions matrix is size [index,embedding]\n","\n","sortidx = np.argsort(np.triu(cossim_embeds,1).flatten())[::-1]\n","xx,yy = np.unravel_index(sortidx,cossim_embeds.shape)\n","\n","for i in np.linspace(0,200,10).astype(int):\n","\n","  # get and print the pairs\n","  pairname = f'({xx[i]},{yy[i]})'\n","  print(f'Cossim of {cossim_embeds[xx[i],yy[i]]:.3f} in pair {pairname}')\n","\n","  # plot them\n","  plt.plot(positions[:,xx[i]],positions[:,yy[i]],'.-',alpha=.5,label=pairname)\n","\n","# adjustments\n","plt.gca().set(xlabel='Embedding dimension \"x\"',ylabel='Embedding dimension \"y\"')\n","plt.legend(fontsize=9)\n","plt.show()"],"metadata":{"id":"6sOA_3mw_mK2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"On3w83Bpl1MJ"},"execution_count":null,"outputs":[]}]}