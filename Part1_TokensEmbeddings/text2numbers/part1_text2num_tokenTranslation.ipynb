{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyN+6BPwzSfqO4pcbrsz5ArA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 1:</h2>|<h1>Tokenizations and embeddings<h1>|\n","|<h2>Section:</h2>|<h1>Words to tokens and embeddings<h1>|\n","|<h2>Lecture:</h2>|<h1><b>Translating between tokenizers<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">udemy.com/course/dulm_x/?couponCode=202509</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"232N0bmJYzDv"}},{"cell_type":"code","source":[],"metadata":{"id":"Tc_Ga6hAYy1c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import two tokenizers"],"metadata":{"id":"1XnNp0fLuqyh"}},{"cell_type":"code","source":["# GPT4\n","!pip install tiktoken\n","import tiktoken\n","gpt4Tokenizer = tiktoken.get_encoding('cl100k_base')\n","\n","# BERT\n","from transformers import BertTokenizer\n","bertTokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"metadata":{"id":"wJfxECXYusgP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"d_gvDTW-uqvf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Attempting a direct translation from GPT4 to BERT and back"],"metadata":{"id":"lvlXr72BaHG_"}},{"cell_type":"code","source":["# issue is that they have different tokenizers, so needs to be translated into text and re-tokenized\n","startingtext = 'Hello, my name is Mike and I like purple.'\n","\n","# GPT4's tokens:\n","gpt4Toks = gpt4Tokenizer.encode(startingtext)\n","\n","# bert's tokens\n","bertToks = bertTokenizer.encode(startingtext)\n","\n","print(f'Starting text:\\n{startingtext}')\n","print(f'\\n\\nGPT4 tokens:\\n{gpt4Toks}')\n","print(f\"\\nDecoded using GPT4:\\n{gpt4Tokenizer.decode(gpt4Toks)}\")\n","print(f\"\\nDecoded using BERT:\\n{bertTokenizer.decode(gpt4Toks)}\")\n","\n","print(f'\\n\\nBERT tokens:\\n{bertToks}')\n","print(f\"\\nDecoded using BERT:\\n{bertTokenizer.decode(bertToks)}\")\n","print(f\"\\nDecoded using GPT4:\\n{gpt4Tokenizer.decode(bertToks)}\")"],"metadata":{"id":"MVAkfwC6aMFW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zT0HB-xH4PVP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# The right way to translate (numbers to text)"],"metadata":{"id":"T3zbVO5XadpI"}},{"cell_type":"code","source":["# text -> GPT4 tokens -> text -> BERT tokens\n","\n","# 1) to GPT4 tokens\n","startingtext = 'Hello, my name is Mike and I like purple.'\n","gpt4Toks = gpt4Tokenizer.encode(startingtext)\n","\n","# 2) back to text\n","gpt4ReconText = gpt4Tokenizer.decode(gpt4Toks)\n","\n","# 3) then to bert tokens\n","bertToks = bertTokenizer.encode(gpt4ReconText)\n","\n","# 4) show the reconstruction\n","bertTokenizer.decode(bertToks)"],"metadata":{"id":"NuScEgeVay4C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"E9RXStDEej1J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Possible annoyances and confusion in translations"],"metadata":{"id":"eiuVkoJWakGa"}},{"cell_type":"code","source":["# warning about sizes:\n","txt = 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.'\n","print(f'Text contains {len(txt)} characters,')\n","print(f'              {len(gpt4Tokenizer.encode(txt))} GPT4 tokens, and')\n","print(f'              {len(bertTokenizer.encode(txt))} Bert tokens.')"],"metadata":{"id":"-UxCgmWAzL9C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# another source of confusion:\n","txt = 'start\\r\\n\\r\\n\\r\\n\\n\\r\\n\\r\\n\\t\\t\\t\\n\\r\\n\\rend'\n","# txt = 'start\\t\\t\\t\\t\\t\\t\\tend'\n","# txt = 'start                    end'\n","\n","bertToks = bertTokenizer.encode(txt)\n","gpt4Toks = gpt4Tokenizer.encode(txt)\n","\n","print(f'Reconstruction in BERT:\\n  {bertToks}\\n  {bertTokenizer.decode(bertToks)}\\n')\n","print(f'Reconstruction in GPT4:\\n  {gpt4Toks}\\n  {gpt4Tokenizer.decode(gpt4Toks)}')"],"metadata":{"id":"2FZNon12Y3UT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"309X7W4O33Bi"},"execution_count":null,"outputs":[]}]}