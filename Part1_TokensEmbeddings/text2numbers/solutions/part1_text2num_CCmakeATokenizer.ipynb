{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n",
        "|-|:-:|\n",
        "|<h2>Part 1:</h2>|<h1>Tokenizations and embeddings<h1>|\n",
        "|<h2>Section:</h2>|<h1>Words to tokens to numbers<h1>|\n",
        "|<h2>Lecture:</h2>|<h1><b>CodeChallenge: Create and visualize tokens<b></h1>|\n",
        "\n",
        "<br>\n",
        "\n",
        "<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n",
        "<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n",
        "<i>Using the code without the course may lead to confusion or errors.</i>"
      ],
      "metadata": {
        "id": "dBsNRoJ8HpGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# adjust matplotlib defaults to personal preferences\n",
        "import matplotlib_inline.backend_inline\n",
        "matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"
      ],
      "metadata": {
        "id": "KDVo9UpRHuaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l9qRt7lt2mNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1: Make encoder and decoder functions"
      ],
      "metadata": {
        "id": "CDrUKPlaUk1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list of sentences\n",
        "text = [ 'All that we are is the result of what we have thought',\n",
        "         'To be or not to be that is the question',\n",
        "         'Be yourself everyone else is already taken' ]\n",
        "\n",
        "# create a vocab of unique words\n",
        "allwords = re.split(r'\\s',' '.join(text).lower())\n",
        "vocab = sorted(set(allwords))"
      ],
      "metadata": {
        "id": "RmFWYsyFHuXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create an encoder and decoder dictionaries\n",
        "word2idx = { word:i for i,word in enumerate(vocab) }\n",
        "idx2word = { i:word for i,word in enumerate(vocab) }\n",
        "word2idx"
      ],
      "metadata": {
        "id": "RQk8dGyBHuEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YO8mrz0wlfJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2: Wrap the encoder/decoder into functions"
      ],
      "metadata": {
        "id": "o6ueQLtilfG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### the encoder function\n",
        "def encoder(text):\n",
        "\n",
        "  # parse the text into words\n",
        "  words = re.split(' ',text.lower())\n",
        "\n",
        "  # return the vector of indices\n",
        "  return [ word2idx[w] for w in words ]\n",
        "\n",
        "\n",
        "### now for the decoder\n",
        "def decoder(indices):\n",
        "\n",
        "  # find the words for these indices, and join into one string\n",
        "  return ' '.join([ idx2word[i] for i in indices ])"
      ],
      "metadata": {
        "id": "YmbprxiJUkyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reminder of the available words\n",
        "print(vocab)"
      ],
      "metadata": {
        "id": "hrYdndiMVKhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new sentence using the vocab\n",
        "newtext = 'we already are the result of what ' \\\n",
        "          'everyone else already thought'\n",
        "\n",
        "newtext_tokenIDs = encoder(newtext)\n",
        "decoded_text = decoder(newtext_tokenIDs)\n",
        "\n",
        "print('Original text:')\n",
        "print(f'\\t{newtext}')\n",
        "\n",
        "print(f'\\nToken IDs:')\n",
        "print(f'\\t{newtext_tokenIDs}')\n",
        "\n",
        "print(f'\\nDecoded text:')\n",
        "print(f'\\t{decoded_text}')"
      ],
      "metadata": {
        "id": "FjfDDTCLVNhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WWHC4OhqUp9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3: Visualize the tokens"
      ],
      "metadata": {
        "id": "9TXuhX6RUpuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get all the text and all the tokens\n",
        "alltext = ' '.join(text)\n",
        "tokens = encoder(alltext)\n",
        "\n",
        "# create a figure\n",
        "_,ax = plt.subplots(1,figsize=(12,5))\n",
        "\n",
        "# plot the tokens\n",
        "ax.plot(tokens,'ks',markersize=12,markerfacecolor=[.7,.7,.9])\n",
        "ax.set(xlabel='Word index',yticks=range(len(vocab)))\n",
        "ax.grid(linestyle='--',axis='y')\n",
        "\n",
        "# invisible axis for right-hand-side labels\n",
        "ax2 = ax.twinx()\n",
        "ax2.plot(tokens,alpha=0)\n",
        "ax2.set(yticks=range(len(vocab)),yticklabels=vocab)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IgTGDrPlL5pG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xGMSRkdJL5d2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4: Explore context surrounding target tokens"
      ],
      "metadata": {
        "id": "zMYlLp4BWsZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what words are in the context of \"to\"\n",
        "\n",
        "targetWord = 'to'\n",
        "targetIdx = word2idx[targetWord]\n",
        "\n",
        "# find indices\n",
        "targetLocs = np.where(np.array(allwords) == targetWord)[0]\n",
        "print(f'\"{targetWord}\" appears at indices {targetLocs}\\n\\n')\n",
        "\n",
        "# print context\n",
        "for t in targetLocs:\n",
        "  print(tokens[t-1:t+2])\n",
        "  print(' '.join(allwords[t-1:t+2]),'\\n')"
      ],
      "metadata": {
        "id": "AkQsfbsRKgOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1qjqrlI0KgLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 5: One-hot encoding"
      ],
      "metadata": {
        "id": "saDflJN8KgIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_matrix = np.zeros((len(allwords),len(vocab)),dtype=int)\n",
        "\n",
        "# create the matrix\n",
        "for i,word in enumerate(allwords):\n",
        "  word_matrix[i,word2idx[word]] = 1\n",
        "\n",
        "# show the results\n",
        "print(f'One-hot encoding matrix is of size {word_matrix.shape}\\n')\n",
        "print(word_matrix)"
      ],
      "metadata": {
        "id": "T3rgXEP0OyDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the image of the one-hot encoding matrix is the same as in Exercise 2\n",
        "_,ax = plt.subplots(1,figsize=(10,5))\n",
        "\n",
        "plt.imshow(1-word_matrix.T,cmap='gray',origin='lower',aspect='auto')\n",
        "ax.set(xlabel='Word index',yticks=range(len(vocab)))\n",
        "ax.grid(linestyle='--',axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "beWoY-qYOyLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DFXQWrMA36re"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}