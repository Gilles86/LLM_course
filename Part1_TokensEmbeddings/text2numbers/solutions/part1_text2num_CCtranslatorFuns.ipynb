{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPXLJ4iuwPdDsUeu5SlatTT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 1:</h2>|<h1>Tokenizations and embeddings<h1>|\n","|<h2>Section:</h2>|<h1>Words to tokens to numbers<h1>|\n","|<h2>Lecture:</h2>|<h1><b>CodeChallenge: More on token translation<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dullms_x/?couponCode=202508\" target=\"_blank\">udemy.com/course/dullms_x/?couponCode=202508</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"cPXS7dDYcImb"}},{"cell_type":"code","source":[],"metadata":{"id":"qqTos9Wpuq1-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import two tokenizers"],"metadata":{"id":"1XnNp0fLuqyh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QnBjS3LAujoq"},"outputs":[],"source":["!pip install tiktoken\n","import tiktoken\n","from transformers import BertTokenizer"]},{"cell_type":"code","source":["bertTokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","gpt4Tokenizer = tiktoken.get_encoding('cl100k_base')"],"metadata":{"id":"wJfxECXYusgP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"T7DbSkSquqp5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 1: Write translation functions"],"metadata":{"id":"ur-eP9j7uqm8"}},{"cell_type":"code","source":["# translation functions\n","def bert2gpt4(bertToks):\n","  b = bertTokenizer.decode(bertToks)\n","  g = gpt4Tokenizer.encode(b)\n","  return g\n","\n","def gpt42bert(gpt4Toks):\n","  g = gpt4Tokenizer.decode(gpt4Toks)\n","  b = bertTokenizer.encode(g)\n","  return b[1:-1] # bert auto-adds [CLS] ... [SEP]"],"metadata":{"id":"PjXLN6TTwcQ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# just checking that it gives no errors\n","text = 'I wish chocolate were purple.'\n","\n","print(bert2gpt4(bertTokenizer.encode(text)))\n","print(gpt42bert(gpt4Tokenizer.encode(text)))"],"metadata":{"id":"MXpmFE3cBfPP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"txY-ShywAJ_S"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2: BERT --> GPT4 --> BERT"],"metadata":{"id":"L4Du3JPXAJ6p"}},{"cell_type":"code","source":["# sample text\n","text = \"I wanted to paste in a thought-provoking quote here, but I didn't.\"\n","print(f'Original text\\n  {text}\\n')\n","\n","# initial encoding\n","bertTox = bertTokenizer.encode(text)\n","print(f'BERT tokens:\\n  {bertTox}\\n')\n","\n","# translate to GPT4\n","b2g = bert2gpt4(bertTox)\n","print(f'BERT to GPT4:\\n  {gpt4Tokenizer.decode(b2g)}\\n')\n","\n","# back-translate to BERT\n","back2bert = gpt42bert(b2g)\n","print(f'Back to BERT:\\n  {bertTokenizer.decode(back2bert)}')"],"metadata":{"id":"lkf2RFVk76xH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"-WumOSErA5pJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 3: GPT4 --> BERT --> GPT4"],"metadata":{"id":"ipwIs91jA5mB"}},{"cell_type":"code","source":["# sample text\n","text = \"I still don't have a good quote here. Now it's too late.\"\n","print(f'Original text\\n  {text}\\n')\n","\n","# initial encoding\n","gpt4Tox = gpt4Tokenizer.encode(text)\n","print(f'GPT4 tokens:\\n  {gpt4Tox}\\n')\n","\n","# translate to BERT\n","g2b = gpt42bert(gpt4Tox)\n","print(f'GPT4 to BERT:\\n  {bertTokenizer.decode(g2b)}\\n')\n","\n","# back-translate to GPT4\n","back2gpt4 = bert2gpt4(g2b)\n","print(f'Back to GPT4:\\n  {gpt4Tokenizer.decode(back2gpt4)}')"],"metadata":{"id":"G1bpWEnT33Es"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"309X7W4O33Bi"},"execution_count":null,"outputs":[]}]}