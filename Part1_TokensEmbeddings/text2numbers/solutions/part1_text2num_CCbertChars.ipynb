{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNi4mQi6LibcZoNE9ZhQzQ8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["|<h2>Course:</h2>|<h1><a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">A deep understanding of AI language model mechanisms</a></h1>|\n","|-|:-:|\n","|<h2>Part 1:</h2>|<h1>Tokenizations and embeddings<h1>|\n","|<h2>Section:</h2>|<h1>Words to tokens to numbers<h1>|\n","|<h2>Lecture:</h2>|<h1><b>CodeChallenge: Character counts in BERT tokens<b></h1>|\n","\n","<br>\n","\n","<h5><b>Teacher:</b> Mike X Cohen, <a href=\"https://sincxpress.com\" target=\"_blank\">sincxpress.com</a></h5>\n","<h5><b>Course URL:</b> <a href=\"https://udemy.com/course/dulm_x/?couponCode=202509\" target=\"_blank\">udemy.com/course/dulm_x/?couponCode=202509</a></h5>\n","<i>Using the code without the course may lead to confusion or errors.</i>"],"metadata":{"id":"n1LB6Jsc-8o-"}},{"cell_type":"code","source":[],"metadata":{"id":"fcZuEIvjV3dC"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WTp8j3TJAqvB"},"outputs":[],"source":["import numpy as np\n","import string\n","\n","import matplotlib.pyplot as plt\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type":"code","source":["# load BERT tokenizer\n","from transformers import BertTokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"metadata":{"id":"STH_qxPP3BtK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4uQ1UO6G-PAB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 1: Character counts in BERT tokens"],"metadata":{"id":"MiXKcTVd-OfF"}},{"cell_type":"code","source":["# set of digits and letters\n","digitsLetters = string.digits + string.ascii_lowercase\n","\n","# initialize results vector\n","charCount = np.zeros(len(digitsLetters),dtype=int)\n","\n","# count the appearances (excluding \"unused\")\n","for i,c in enumerate(digitsLetters):\n","  charCount[i] = np.sum([ c in tok for tok in tokenizer.vocab.keys() if not 'unused' in tok ])"],"metadata":{"id":"-kqSP7GI3FDr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# and plot\n","plt.figure(figsize=(12,3))\n","plt.bar(range(len(charCount)),charCount,color=[.7,.7,.7],edgecolor='k')\n","\n","plt.gca().set(xticks=range(len(charCount)),xticklabels=list(digitsLetters),\n","              xlim=[-.6,len(charCount)-.4],xlabel='Character',ylabel='Count',\n","              title='Frequency of characters in BERT tokens')\n","\n","plt.show()"],"metadata":{"id":"H7byXz2-3FAg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"B_nfU71u-Tv1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Exercise 2: Report the sorted characters"],"metadata":{"id":"7kP1eYYS-Ttb"}},{"cell_type":"code","source":["charOrder = np.argsort(charCount)[::-1]\n","\n","for i in charOrder:\n","  print(f'\"{digitsLetters[i]}\" appears in {charCount[i]:6,} tokens.')"],"metadata":{"id":"CH_A-Ya13E9Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"jNxC2r28_MVy"},"execution_count":null,"outputs":[]}]}